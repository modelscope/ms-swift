import os
import shutil
import subprocess
import time
from typing import List

os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'

from swift.utils import get_device_count

# NOTE: this script supports at most 8 GPUS in a node, if using multi node, please use custom logic.

# Paste conda env
# conda_prefix = 'source /root/miniconda3/etc/profile.d/conda.sh && conda activate py311 && '
conda_prefix = ''


def do_sample(model: str, model_type: str, dataset: List[str], iter: int):  # 采样入口函数，按设备并行生成样本
    device_count = get_device_count()  # 获取可用 GPU 数量
    print(f'[INFO] device_count: {device_count}')
    handlers = []  # 存放子进程句柄
    datasets = []  # 存放采样结果文件路径
    # Sampling cache, to avoid lmdeploy & PRM run at the same time
    # Why lmdeploy not vllm? we found that the responses generated by lmdeploy are more similar than ones of vllm.
    for device in range(device_count):  # 遍历每张 GPU，逐卡启动采样
        sample_cmd = (f'{conda_prefix} USE_OPENCOMPASS_EVALUATOR=True CUDA_VISIBLE_DEVICES={device} swift sample '  # 基础命令前缀
                      f'--model {model} --model_type {model_type} '  # 指定模型与模型类型
                      f'--dataset {" ".join(dataset)} '  # 指定数据集（多项用空格拼接）
                      f'--data_range {device} {device_count} '  # 指定数据切分范围（第 device 份，共 device_count 份）
                      f'--max_length 2048 '  # 最长输入长度
                      f'--system "You are a math model, you should **think step by step** carefully, '  # 系统提示词
                      f'and always consider the basic math principles to avoid making calculating mistakes.'
                      f'Give the final answer wrapped with \\boxed{{}}" '
                      f'--load_args false '  # 不从 ckpt 加载历史参数
                      f'--sampler_engine vllm '  # 采样后端选择 vLLM
                      f'--max_new_tokens 768 '  # 最多生成 token 数
                      f'--override_exist_file true '  # 覆盖已存在输出文件
                      f'--num_sampling_per_gpu_batch_size 1 '  # 单卡采样 batch size
                      f'--num_return_sequences 64 '  # 返回样本条数
                      f'--cache_files sample_output/iter_{iter}_proc_{device}_cache.jsonl '  # 缓存文件路径
                      f'--output_file iter_{iter}_proc_{device}_cache.jsonl '  # 输出文件路径
                      f'--top_p 1.0 '  # nucleus sampling 参数 top_p
                      f'--temperature 1.0 ')  # 采样温度
        print(f'Sampling caches of iter {iter}, part {device}.', flush=True)  # 打印当前迭代与分片信息
        
        env = os.environ.copy() # 复制当前进程环境变量，生成可修改副本
        env['CUDA_VISIBLE_DEVICES'] = str(device)   # 在子进程环境中限定使用的 GPU
        # 启动子进程执行采样命令
        handler = subprocess.Popen(
            f'{sample_cmd}' + f' > logs/sample_iter_{iter}_proc_{device}_cache.log 2>&1',  # 标准输出和错误重定向到日志文件
            # env=os.environ.copy(),  # 传入子进程环境（此处未使用上面的 env）
            env=env,  # 传入子进程环境（此处未使用上面的 env）
            shell=True,  # 使用 shell 解析命令（支持重定向等语法）
            executable='/bin/bash')  # 指定 /bin/bash 作为 shell 解释器
        handlers.append(handler)  # 保存子进程句柄，便于后续管理

    for proc, handler in enumerate(handlers):  # 遍历所有子进程
        handler.wait()  # 等待子进程结束
        assert os.path.exists(os.path.join('sample_output', f'iter_{iter}_proc_{proc}_cache.jsonl'))  # 校验缓存文件存在

    handlers = []
    # Sample again, this time to filter with ORM & PRM
    # Provide your PRM model or PRM name(add PRM in plugin/prm.py first)
    # You can define your custom PRM logic in the plugin
    # (like, split your steps, use the worst score/last score/avg score)
    for device in range(device_count):  # 第二轮：按卡并行进行 ORM/PRM 过滤采样
        sample_cmd = (
            f'{conda_prefix} USE_OPENCOMPASS_EVALUATOR=True CUDA_VISIBLE_DEVICES={device} swift sample '
            f'--model {model} --model_type {model_type} '
            f'--dataset {" ".join(dataset)} '
            f'--data_range {device} {device_count} '
            f'--max_length 2048 ' 
            f'--system "You are a math model, you should **think step by step** carefully, '
            f'and always consider the basic math principles to avoid making calculating mistakes.'
            f'Give the final answer wrapped with \\boxed{{}}" '
            f'--load_args false '
            f'--sampler_engine no '  # 关闭采样引擎（由 ORM/PRM 过滤）
            f'--orm_model math '  # math defines in plugin/orm.py
            f'--prm_model Qwen/Qwen2.5-Math-PRM-7B '  # 指定 PRM 模型
            f'--prm_threshold {min(0.7 + 0.1*iter, 0.9)} '  # PRM 过滤阈值
            f'--max_new_tokens 768 '  # 最多生成 token 数
            f'--override_exist_file true '  # no not override the existing sample files
            f'--num_sampling_per_gpu_batch_size 1 '  # 单卡 batch size
            f'--num_return_sequences 64 '  # 返回样本条数
            f'--cache_files sample_output/iter_{iter}_proc_{device}_cache.jsonl '   # 读取第一轮缓存
            f'--output_file iter_{iter}_proc_{device}_sampling.jsonl '  # 采样输出文件
        )  
        print(f'Sampling iter {iter}, part {device}.', flush=True)  # 打印进度信息
        env = os.environ.copy()  # 复制当前进程环境变量副本
        env['CUDA_VISIBLE_DEVICES'] = str(device)  # 限定子进程使用的 GPU
        handler = subprocess.Popen(  # 启动第二轮采样子进程
            f'{sample_cmd}' + f' > logs/sample_iter_{iter}_proc_{device}.log 2>&1',  # 输出与错误重定向到日志
            # env=os.environ.copy(),  # 传入子进程环境（此处未使用上面的 env）
            env=env,  # 传入子进程环境（此处未使用上面的 env）
            shell=True,  # 通过 shell 执行命令
            executable='/bin/bash')  # 指定 shell 解释器
        handlers.append(handler)  # 记录子进程句柄

    for proc, handler in enumerate(handlers):  # 遍历并等待所有过滤采样子进程
        handler.wait()  # 等待子进程结束
        assert os.path.exists(os.path.join('sample_output', f'iter_{iter}_proc_{proc}_sampling.jsonl')), (  # 校验输出文件
            f'{os.path.join("sample_output", f"iter_{iter}_proc_{proc}_sampling.jsonl")} not exists, '
            'please check the sample logs to get the detail error.')
        datasets.append(os.path.join('sample_output', f'iter_{iter}_proc_{proc}_sampling.jsonl'))  # 记录输出文件路径
    print(f'Sampling done, files:{datasets}', flush=True)  # 打印完成信息和文件列表
    return datasets  # 返回采样得到的数据文件路径列表


def do_train(model: str, model_type: str, datasets: List[str], iter, cmd='sft'):  # 训练入口函数（支持 sft/rlhf）
    gpu_prefix = ''  # 多卡场景下为每节点进程数前缀
    ds_config = ''  # DeepSpeed 配置片段（追加到命令行）
    if get_device_count() > 1:  # 若检测到多张可见 GPU
        gpu_prefix = f'NPROC_PER_NODE={get_device_count()} '  # 设定每节点进程数=N(GPU)
        ds_config = '--deepspeed zero3 '  # 启用 DeepSpeed ZeRO-3 优化
    extra_args = ''  # 额外参数占位
    if cmd == 'rlhf':  # 当选择 RLHF 训练模式
        extra_args = '--rlhf_type dpo --beta 0.3 '  # use another reinforce learning method supported by swift
    ga = 128 // get_device_count() // 2  # 按设备数动态计算梯度累积步数
    train_cmd = (f'{conda_prefix} {gpu_prefix} swift {cmd} '  # 训练命令前缀
                 f'--model {model} --model_type {model_type} '  # 指定模型与模型类型
                 f'--dataset {" ".join(datasets)} '  # 训练数据集（多文件用空格连接）
                 f'--max_length 2048 '  # 最长序列长度
                 f'--num_train_epochs 1 '  # 训练轮数
                 f'--load_args false '  # 不从 ckpt 加载历史参数
                 f'--train_type full '  # 全量微调
                 f'{extra_args} '  # 追加 RLHF 等额外参数
                 f'--eval_strategy no '  # 训练中不执行评估
                 f'--split_dataset_ratio 0 '  # 不划分验证集
                 f'--per_device_train_batch_size 2 '  # 单卡 batch size
                 f'--gradient_accumulation_steps {ga} '  # 梯度累积步数
                 f'--save_steps 1 '  # 每步保存
                 f'--save_strategy epoch '  # 保存策略按 epoch
                 f'{ds_config} '  # 追加 DeepSpeed 配置
                 f'--learning_rate 4e-6 ')  # 学习率

    print(f'Training iter {iter}.', flush=True)  # 打印当前迭代训练开始信息
    handler = subprocess.Popen(  # 启动训练子进程并将日志重定向到文件
        f'{train_cmd}' + f' > logs/train_iter_{iter}.log 2>&1',
        shell=True,  # 通过 shell 执行以支持重定向
        env=os.environ.copy(),  # 继承当前环境变量
        executable='/bin/bash')  # 使用 bash 解析命令
    handler.wait()  # 阻塞等待训练进程结束
    ckpt = None  # 最终 checkpoint 路径占位
    with open(f'logs/train_iter_{iter}.log', 'r') as f:  # 从日志中解析最后保存的 ckpt
        for line in f.readlines():  # 逐行扫描日志
            if 'last_model_checkpoint: ' in line:  # 匹配包含 ckpt 的标志行
                ckpt = line.split('last_model_checkpoint: ')[1]  # 提取 ckpt 路径
                break  # 找到后退出扫描
    assert ckpt is not None  # 确保成功解析到 ckpt
    print(f'Training done, ckpt: {ckpt.strip()}.', flush=True)  # 打印训练完成与 ckpt
    return ckpt.strip()  # 返回 ckpt 路径（去除空白）


def do_eval(model, model_type: str, iter):  # 评测入口函数
    # 构建评测命令
    eval_cmd = (
        f'{conda_prefix} swift eval '  # 命令前缀与可选环境前缀
        '--eval_dataset competition_math '  # eval another dataset
        '--infer_backend vllm --eval_limit 500 '  # 使用 vLLM 推理并限制评测样本数
        f'--model {model} --model_type {model_type} '  # 指定评测模型与模型类型
        '--system "You are a math model, you should **think step by step** carefully, '  # 设置系统提示词（评测指令）
        'and always consider the basic math principles to avoid making calculating mistakes. '
        'Give the final answer wrapped with \\boxed{}"')
    print('Evaluating.', flush=True)  # 打印评测开始提示
    # Replace the original dataset to the math.json, this is for test, comment this if not need
    # replace_math_dataset()  # 覆盖评测数据（仅测试用途）

    if iter is None:  # 若未提供迭代标识
        iter = 'origin'  # 设定默认标识
    env = os.environ.copy()  # 复制当前环境变量
    env['CUDA_VISIBLE_DEVICES'] = '0'  # 评测固定使用 GPU0（可按需修改）
    handler = subprocess.Popen(  # 启动评测子进程
        f'{eval_cmd}' + f' > logs/eval_iter_{iter}.log 2>&1', shell=True, env=env, executable='/bin/bash')  # 重定向日志并使用 bash
    handler.wait()  # 等待评测完成

    acc = None  # 初始化准确率
    # | math | 393424 | accuracy | gen | 39.00 |
    with open(f'logs/eval_iter_{iter}.log', 'r') as f:  # 打开评测日志文件
        for line in f.readlines():  # 逐行扫描日志
            if 'Level 5' in line and 'AveragePass@1' in line:  # 定位包含指标的行
                parts = [p for p in line.split('|') if p.strip()]  # 按竖线切分并过滤空列
                acc = float(parts[-2])  # 解析倒数第二列为准确率
                break  # 找到后退出

    print(f'Iter {iter} eval done with acc: {acc}.', flush=True)  # 打印评测完成与准确率
    return acc  # 返回准确率


def replace_math_dataset():
    # Note: This may run failed because this is special for math test,
    # and one must run swift eval --eval_dataset math first to make sure opencompass has created
    # the folder.
    # You can use original math dataset either. just comment this call.
    user_dir = os.path.expanduser('~')
    if os.path.exists(os.path.join(user_dir, '.cache', 'opencompass', 'data', 'math', 'math.json')):
        os.remove(os.path.join(user_dir, '.cache', 'opencompass', 'data', 'math', 'math.json'))
    shutil.copy(
        # os.path.join('examples', 'train', 'rft', 'math.json'),
        os.path.join('./math.json'),
        os.path.join(user_dir, '.cache', 'opencompass', 'data', 'math', 'math.json'))


def main():
    os.makedirs('logs', exist_ok=True)
    max_acc = 0.
    first_model = '/data/joey.wang/llm/models/pretrained/llm/Qwen2.5-Math-1.5B-Instruct'
    model_type = 'qwen2_5_math'

    if False:
        # eval the original model
        do_eval(first_model, None)

    model = first_model
    # for i in range(5):
    for i in range(1):
        ts = time.time()
        print(f'[INFO] do sample {i} start')
        is_complete_sample = True
        if not is_complete_sample:
            # datasets = do_sample(model, model_type, ['tastelikefeet/competition_math'], i)
            datasets = do_sample(model, model_type, ['./data/tastelikefeet/competition_math'], i)
        else:
            # 已经完成采样，直接读取
            datasets = []
            for device in range(4):
                datasets.append(os.path.join('sample_output', f'iter_{i}_proc_{device}_sampling.jsonl'))  # 记录输出文件路径
        # add custom data filter here, for example: length or diversity control
        print(f'do sample cost: {(time.time()-ts) / 60:.1f} minutes.', flush=True)

        ts = time.time()
        # if want to train the original dataset with datasets, add the original dataset here
        # if want to train the original model everytime, change to first_model
        is_complete_train = True
        if not is_complete_train:
            ckpt = do_train(model, model_type, datasets, i)
        else:
            ckpt = './output/Qwen2.5-Math-1.5B-Instruct/v0-20250825-103218/checkpoint-378'
        print(f'do train cost: {(time.time() - ts) / 60:.1f} minutes.', flush=True)

        ts = time.time()
        acc = do_eval(ckpt, model_type, i)
        print(f'do eval cost: {(time.time() - ts) / 60:.1f} minutes.', flush=True)
        if acc > max_acc:
            max_acc = acc
        model = ckpt
        print(f'acc: {acc}, upgrade model to : {model}', flush=True)


if __name__ == '__main__':
    main()
