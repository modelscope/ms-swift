{
  "use_ray": true,
  "ray_exp_name": null,
  "device_groups": {
    "nproc_per_node": 4,
    "sample_group": {
      "device": "GPU",
      "ranks": "list(range(0, 2))",
      "workers": [
        "sampler"
      ]
    },
    "rm_group": {
      "device": "GPU",
      "ranks": "list(range(2, 4))",
      "workers": [
        "prm",
        "orm"
      ]
    }
  },
  "model": "Qwen/Qwen2.5-VL-3B-Instruct",
  "model_type": "qwen2_5_vl",
  "model_revision": null,
  "task_type": "causal_lm",
  "torch_dtype": "bfloat16",
  "attn_impl": null,
  "new_special_tokens": [],
  "num_labels": null,
  "problem_type": null,
  "rope_scaling": null,
  "device_map": null,
  "max_memory": {},
  "max_model_len": null,
  "local_repo_path": null,
  "init_strategy": null,
  "template": "qwen2_5_vl",
  "system": "You are a math model, you should **think step by step** carefully, and always consider the basic math principles to avoid making calculating mistakes. Give the final answer wrapped with \\boxed{{}}",
  "max_length": 2048,
  "truncation_strategy": "delete",
  "max_pixels": null,
  "agent_template": null,
  "norm_bbox": null,
  "use_chat_template": true,
  "padding_free": false,
  "padding_side": "left",
  "loss_scale": "default",
  "sequence_parallel_size": 1,
  "response_prefix": null,
  "template_backend": "swift",
  "dataset": [
    "tastelikefeet/competition_math#16"
  ],
  "val_dataset": [],
  "split_dataset_ratio": 0.0,
  "data_seed": 42,
  "dataset_num_proc": 1,
  "load_from_cache_file": false,
  "dataset_shuffle": true,
  "val_dataset_shuffle": false,
  "streaming": false,
  "interleave_prob": null,
  "stopping_strategy": "first_exhausted",
  "shuffle_buffer_size": 1000,
  "download_mode": "reuse_dataset_if_exists",
  "columns": {},
  "strict": false,
  "remove_unused_columns": true,
  "model_name": null,
  "model_author": null,
  "custom_dataset_info": [],
  "quant_method": null,
  "quant_bits": null,
  "hqq_axis": null,
  "bnb_4bit_compute_dtype": "bfloat16",
  "bnb_4bit_quant_type": "nf4",
  "bnb_4bit_use_double_quant": true,
  "bnb_4bit_quant_storage": null,
  "max_new_tokens": 768,
  "temperature": 1.0,
  "top_k": null,
  "top_p": 1.0,
  "repetition_penalty": null,
  "num_beams": 1,
  "stream": false,
  "stop_words": [],
  "logprobs": false,
  "top_logprobs": null,
  "ckpt_dir": null,
  "lora_modules": [],
  "tuner_backend": "peft",
  "train_type": "lora",
  "adapters": [],
  "external_plugins": [],
  "seed": 42,
  "model_kwargs": {},
  "load_args": false,
  "load_data_args": false,
  "packing": false,
  "packing_length": null,
  "lazy_tokenize": true,
  "cached_dataset": [],
  "custom_register_path": [],
  "use_hf": false,
  "hub_token": null,
  "ddp_timeout": 18000000,
  "ddp_backend": null,
  "ignore_args_error": false,
  "use_swift_lora": false,
  "prm_model": "Qwen/Qwen2.5-Math-PRM-7B",
  "orm_model": "math",
  "sampler_type": "sample",
  "sampler_engine": "vllm",
  "output_dir": "sample_output",
  "output_file": "sampling.jsonl",
  "resume": false,
  "override_exist_file": true,
  "num_return_sequences": 4,
  "num_sampling_batch_size": 4,
  "num_sampling_batches": null,
  "n_best_to_keep": 5,
  "data_range": [],
  "prm_threshold": 0.8,
  "easy_query_threshold": null,
  "engine_kwargs": {},
  "cache_files": [],
  "rank": -1,
  "local_rank": -1,
  "global_world_size": 1,
  "local_world_size": 1,
  "model_suffix": "Qwen2.5-VL-3B-Instruct",
  "model_info": "ModelInfo(model_type='qwen2_5_vl', model_dir='/mnt/workspace/.cache/modelscope/hub/models/Qwen/Qwen2___5-VL-3B-Instruct', torch_dtype=torch.bfloat16, max_model_len=128000, quant_method=None, quant_bits=None, rope_scaling={'type': 'default', 'mrope_section': [16, 24, 24], 'rope_type': 'default'}, is_moe_model=False, config=None, task_type='causal_lm', num_labels=None)",
  "model_meta": "ModelMeta(model_type='qwen2_5_vl', model_groups=[ModelGroup(models=[Model(ms_model_id='Qwen/Qwen2.5-VL-3B-Instruct', hf_model_id='Qwen/Qwen2.5-VL-3B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen2.5-VL-7B-Instruct', hf_model_id='Qwen/Qwen2.5-VL-7B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen2.5-VL-32B-Instruct', hf_model_id='Qwen/Qwen2.5-VL-32B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen2.5-VL-72B-Instruct', hf_model_id='Qwen/Qwen2.5-VL-72B-Instruct', model_path=None, ms_revision=None, hf_revision=None)], ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='Qwen/Qwen2.5-VL-3B-Instruct-AWQ', hf_model_id='Qwen/Qwen2.5-VL-3B-Instruct-AWQ', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen2.5-VL-7B-Instruct-AWQ', hf_model_id='Qwen/Qwen2.5-VL-7B-Instruct-AWQ', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen2.5-VL-32B-Instruct-AWQ', hf_model_id='Qwen/Qwen2.5-VL-32B-Instruct-AWQ', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', hf_model_id='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', model_path=None, ms_revision=None, hf_revision=None)], ignore_patterns=None, requires=None, tags=[])], template='qwen2_5_vl', get_function=<function get_model_tokenizer_qwen2_5_vl at 0x7fc6db481440>, model_arch=MultiModelKeys(arch_name='qwen2_vl', embedding=None, module_list=None, lm_head=None, q_proj=None, k_proj=None, v_proj=None, o_proj=None, attention=None, mlp=None, down_proj=None, qkv_proj=None, qk_proj=None, qa_proj=None, qb_proj=None, kv_proj=None, kva_proj=None, kvb_proj=None, language_model=['model.language_model'], aligner=['model.visual.merger'], vision_tower=['model.visual'], generator=[]), architectures=['Qwen2_5_VLForConditionalGeneration'], additional_saved_files=[], torch_dtype=None, is_multimodal=True, is_reward=False, task_type=None, ignore_patterns=None, requires=['transformers>=4.49', 'qwen_vl_utils>=0.0.6', 'decord'], tags=['vision', 'video'])",
  "model_dir": "/mnt/workspace/.cache/modelscope/hub/models/Qwen/Qwen2___5-VL-3B-Instruct",
  "hub": "<class 'swift.hub.hub.MSHub'>",
  "system_message": [
    {
      "role": "system",
      "content": "You are a math model, you should **think step by step** carefully, and always consider the basic math principles to avoid making calculating mistakes. Give the final answer wrapped with \\boxed{{}}"
    }
  ]
}