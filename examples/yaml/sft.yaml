model: Qwen/Qwen2.5-7B-Instruct
split_dataset_ratio: 0.0
train_type: lora
torch_dtype: bfloat16
attn_impl: flash_attn
num_train_epochs: 5
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
learning_rate: 1e-4
dataset: swift/self-cognition#1000
gradient_accumulation_steps: 8
eval_steps: 1000
save_steps: 1000
save_total_limit: 5
logging_steps: 5
warmup_ratio: 0.05
dataloader_num_workers: 0
dataset_num_proc: 8
deepspeed: zero3
model_name: swift-bot
model_author: swift
