{
  "use_ray": false,
  "ray_exp_name": null,
  "device_groups": null,
  "model": "LLM-Research/Meta-Llama-3.1-8B-Instruct",
  "model_type": "llama",
  "model_revision": null,
  "task_type": "causal_lm",
  "torch_dtype": "bfloat16",
  "attn_impl": null,
  "new_special_tokens": [],
  "num_labels": null,
  "problem_type": null,
  "rope_scaling": null,
  "device_map": null,
  "max_memory": {},
  "max_model_len": null,
  "local_repo_path": null,
  "init_strategy": null,
  "template": "llama3_2",
  "system": null,
  "max_length": 131072,
  "truncation_strategy": "delete",
  "max_pixels": null,
  "agent_template": null,
  "norm_bbox": null,
  "use_chat_template": true,
  "padding_side": "left",
  "padding_free": false,
  "loss_scale": "default",
  "sequence_parallel_size": 1,
  "template_backend": "swift",
  "response_prefix": null,
  "enable_thinking": null,
  "add_non_thinking_prefix": true,
  "dataset": "AI-ModelScope/alpaca-gpt4-data-zh#5",
  "val_dataset": [],
  "cached_dataset": [],
  "cached_val_dataset": [],
  "split_dataset_ratio": 0.0,
  "data_seed": 42,
  "dataset_num_proc": 1,
  "load_from_cache_file": false,
  "dataset_shuffle": true,
  "val_dataset_shuffle": false,
  "streaming": false,
  "interleave_prob": null,
  "stopping_strategy": "first_exhausted",
  "shuffle_buffer_size": 1000,
  "download_mode": "reuse_dataset_if_exists",
  "columns": {},
  "strict": false,
  "remove_unused_columns": true,
  "model_name": null,
  "model_author": null,
  "custom_dataset_info": [],
  "quant_method": null,
  "quant_bits": null,
  "hqq_axis": null,
  "bnb_4bit_compute_dtype": "bfloat16",
  "bnb_4bit_quant_type": "nf4",
  "bnb_4bit_use_double_quant": true,
  "bnb_4bit_quant_storage": null,
  "max_new_tokens": null,
  "temperature": 1.0,
  "top_k": null,
  "top_p": null,
  "repetition_penalty": null,
  "num_beams": 1,
  "stream": false,
  "stop_words": [],
  "logprobs": false,
  "top_logprobs": null,
  "structured_outputs_regex": null,
  "ckpt_dir": null,
  "lora_modules": [],
  "tuner_backend": "peft",
  "train_type": "lora",
  "adapters": [],
  "external_plugins": [],
  "custom_register_path": [],
  "seed": 42,
  "model_kwargs": {},
  "load_args": true,
  "load_data_args": false,
  "packing": false,
  "packing_length": null,
  "packing_num_proc": 1,
  "lazy_tokenize": false,
  "use_hf": false,
  "hub_token": null,
  "ddp_timeout": 18000000,
  "ddp_backend": null,
  "ignore_args_error": false,
  "use_swift_lora": false,
  "prm_model": null,
  "orm_model": null,
  "sampler_type": "sample",
  "sampler_engine": "transformers",
  "output_dir": "sample_output",
  "output_file": "2026-01-14-13-27-39.jsonl",
  "resume": false,
  "override_exist_file": false,
  "num_return_sequences": 5,
  "num_sampling_batch_size": 1,
  "num_sampling_batches": null,
  "n_best_to_keep": 5,
  "data_range": [],
  "prm_threshold": 0.0,
  "easy_query_threshold": null,
  "engine_kwargs": {},
  "cache_files": [],
  "swift_version": "4.0.0.dev0",
  "rank": -1,
  "local_rank": -1,
  "global_world_size": 1,
  "local_world_size": 1,
  "model_suffix": "Meta-Llama-3.1-8B-Instruct",
  "model_info": "ModelInfo(model_type='llama', model_dir='/root/.cache/modelscope/models/LLM-Research/Meta-Llama-3___1-8B-Instruct', torch_dtype=torch.bfloat16, max_model_len=131072, quant_method=None, quant_bits=None, rope_scaling={'factor': 8.0, 'low_freq_factor': 1.0, 'high_freq_factor': 4.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, is_moe_model=False, is_multimodal=False, config=None, task_type='causal_lm', num_labels=None)",
  "model_meta": "ModelMeta(model_type='llama', model_groups=[ModelGroup(models=[Model(ms_model_id='modelscope/Llama-2-7b-ms', hf_model_id='meta-llama/Llama-2-7b-hf', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='modelscope/Llama-2-13b-ms', hf_model_id='meta-llama/Llama-2-13b-hf', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='modelscope/Llama-2-70b-ms', hf_model_id='meta-llama/Llama-2-70b-hf', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='modelscope/Llama-2-7b-chat-ms', hf_model_id='meta-llama/Llama-2-7b-chat-hf', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='modelscope/Llama-2-13b-chat-ms', hf_model_id='meta-llama/Llama-2-13b-chat-hf', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='modelscope/Llama-2-70b-chat-ms', hf_model_id='meta-llama/Llama-2-70b-chat-hf', model_path=None, ms_revision=None, hf_revision=None)], template='llama', ignore_patterns=['.+\\\\.bin$'], requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='AI-ModelScope/chinese-llama-2-1.3b', hf_model_id='hfl/chinese-llama-2-1.3b', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-llama-2-7b', hf_model_id='hfl/chinese-llama-2-7b', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-llama-2-7b-16k', hf_model_id='hfl/chinese-llama-2-7b-16k', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-llama-2-7b-64k', hf_model_id='hfl/chinese-llama-2-7b-64k', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-llama-2-13b', hf_model_id='hfl/chinese-llama-2-13b', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-llama-2-13b-16k', hf_model_id='hfl/chinese-llama-2-13b-16k', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-alpaca-2-1.3b', hf_model_id='hfl/chinese-alpaca-2-1.3b', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-alpaca-2-7b', hf_model_id='hfl/chinese-alpaca-2-7b', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-alpaca-2-7b-16k', hf_model_id='hfl/chinese-alpaca-2-7b-16k', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-alpaca-2-7b-64k', hf_model_id='hfl/chinese-alpaca-2-7b-64k', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-alpaca-2-13b', hf_model_id='hfl/chinese-alpaca-2-13b', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='AI-ModelScope/chinese-alpaca-2-13b-16k', hf_model_id='hfl/chinese-alpaca-2-13b-16k', model_path=None, ms_revision=None, hf_revision=None)], template='llama', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='AI-ModelScope/Llama-2-7b-AQLM-2Bit-1x16-hf', hf_model_id='ISTA-DASLab/Llama-2-7b-AQLM-2Bit-1x16-hf', model_path=None, ms_revision=None, hf_revision=None)], template='llama', ignore_patterns=None, requires=['transformers>=4.38', 'aqlm', 'torch>=2.2.0'], tags=[]), ModelGroup(models=[Model(ms_model_id='FlagAlpha/Atom-7B', hf_model_id='FlagAlpha/Atom-7B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='FlagAlpha/Atom-7B-Chat', hf_model_id='FlagAlpha/Atom-7B-Chat', model_path=None, ms_revision=None, hf_revision=None)], template='atom', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='langboat/Mengzi3-13B-Base', hf_model_id='Langboat/Mengzi3-13B-Base', model_path=None, ms_revision=None, hf_revision=None)], template='mengzi', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='AI-ModelScope/NuminaMath-7B-TIR', hf_model_id='AI-MO/NuminaMath-7B-TIR', model_path=None, ms_revision=None, hf_revision=None)], template='numina', ignore_patterns=None, requires=None, tags=['math']), ModelGroup(models=[Model(ms_model_id='Fengshenbang/Ziya2-13B-Base', hf_model_id='IDEA-CCNL/Ziya2-13B-Base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Fengshenbang/Ziya2-13B-Chat', hf_model_id='IDEA-CCNL/Ziya2-13B-Chat', model_path=None, ms_revision=None, hf_revision=None)], template='ziya', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='InfiniAI/Megrez-3b-Instruct', hf_model_id='Infinigence/Megrez-3B-Instruct', model_path=None, ms_revision=None, hf_revision=None)], template='megrez', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='deepseek-ai/deepseek-llm-7b-base', hf_model_id='deepseek-ai/deepseek-llm-7b-base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-llm-7b-chat', hf_model_id='deepseek-ai/deepseek-llm-7b-chat', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-llm-67b-base', hf_model_id='deepseek-ai/deepseek-llm-67b-base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-llm-67b-chat', hf_model_id='deepseek-ai/deepseek-llm-67b-chat', model_path=None, ms_revision=None, hf_revision=None)], template='deepseek', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='deepseek-ai/deepseek-math-7b-base', hf_model_id='deepseek-ai/deepseek-math-7b-base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-math-7b-instruct', hf_model_id='deepseek-ai/deepseek-math-7b-instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-math-7b-rl', hf_model_id='deepseek-ai/deepseek-math-7b-rl', model_path=None, ms_revision=None, hf_revision=None)], template='deepseek', ignore_patterns=None, requires=None, tags=['math']), ModelGroup(models=[Model(ms_model_id='deepseek-ai/deepseek-coder-1.3b-base', hf_model_id='deepseek-ai/deepseek-coder-1.3b-base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-coder-1.3b-instruct', hf_model_id='deepseek-ai/deepseek-coder-1.3b-instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-coder-6.7b-base', hf_model_id='deepseek-ai/deepseek-coder-6.7b-base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-coder-6.7b-instruct', hf_model_id='deepseek-ai/deepseek-coder-6.7b-instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-coder-33b-base', hf_model_id='deepseek-ai/deepseek-coder-33b-base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/deepseek-coder-33b-instruct', hf_model_id='deepseek-ai/deepseek-coder-33b-instruct', model_path=None, ms_revision=None, hf_revision=None)], template='deepseek', ignore_patterns=None, requires=None, tags=['coding']), ModelGroup(models=[Model(ms_model_id='gongjy/MiniMind2', hf_model_id='jingyaogong/MiniMind2', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id=None, hf_model_id='jingyaogong/MiniMind2-Small', model_path=None, ms_revision=None, hf_revision=None)], template='minimind', ignore_patterns=None, requires=['transformers>=4.57.1'], tags=[]), ModelGroup(models=[Model(ms_model_id='LLM-Research/Meta-Llama-3-8B-Instruct', hf_model_id='meta-llama/Meta-Llama-3-8B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3-70B-Instruct', hf_model_id='meta-llama/Meta-Llama-3-70B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3-8B', hf_model_id='meta-llama/Meta-Llama-3-8B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3-70B', hf_model_id='meta-llama/Meta-Llama-3-70B', model_path=None, ms_revision=None, hf_revision=None)], template='llama3', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='swift/Meta-Llama-3-8B-Instruct-GPTQ-Int4', hf_model_id='study-hjt/Meta-Llama-3-8B-Instruct-GPTQ-Int4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='swift/Meta-Llama-3-8B-Instruct-GPTQ-Int8', hf_model_id='study-hjt/Meta-Llama-3-8B-Instruct-GPTQ-Int8', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='swift/Meta-Llama-3-8B-Instruct-AWQ', hf_model_id='study-hjt/Meta-Llama-3-8B-Instruct-AWQ', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='swift/Meta-Llama-3-70B-Instruct-GPTQ-Int4', hf_model_id='study-hjt/Meta-Llama-3-70B-Instruct-GPTQ-Int4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='swift/Meta-Llama-3-70B-Instruct-GPTQ-Int8', hf_model_id='study-hjt/Meta-Llama-3-70B-Instruct-GPTQ-Int8', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='swift/Meta-Llama-3-70B-Instruct-AWQ', hf_model_id='study-hjt/Meta-Llama-3-70B-Instruct-AWQ', model_path=None, ms_revision=None, hf_revision=None)], template='llama3', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='ChineseAlpacaGroup/llama-3-chinese-8b-instruct', hf_model_id='hfl/llama-3-chinese-8b-instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='ChineseAlpacaGroup/llama-3-chinese-8b', hf_model_id='hfl/llama-3-chinese-8b', model_path=None, ms_revision=None, hf_revision=None)], template='llama3', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='LLM-Research/Meta-Llama-3.1-8B-Instruct', hf_model_id='meta-llama/Meta-Llama-3.1-8B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-70B-Instruct', hf_model_id='meta-llama/Meta-Llama-3.1-70B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-405B-Instruct', hf_model_id='meta-llama/Meta-Llama-3.1-405B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-8B', hf_model_id='meta-llama/Meta-Llama-3.1-8B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-70B', hf_model_id='meta-llama/Meta-Llama-3.1-70B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-405B', hf_model_id='meta-llama/Meta-Llama-3.1-405B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-70B-Instruct-FP8', hf_model_id='meta-llama/Meta-Llama-3.1-70B-Instruct-FP8', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-405B-Instruct-FP8', hf_model_id='meta-llama/Meta-Llama-3.1-405B-Instruct-FP8', model_path=None, ms_revision=None, hf_revision=None)], template='llama3_2', ignore_patterns=None, requires=['transformers>=4.43'], tags=[]), ModelGroup(models=[Model(ms_model_id='LLM-Research/Meta-Llama-3.1-8B-Instruct-BNB-NF4', hf_model_id='hugging-quants/Meta-Llama-3.1-8B-Instruct-BNB-NF4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-70B-Instruct-bnb-4bit', hf_model_id='unsloth/Meta-Llama-3.1-70B-Instruct-bnb-4bit', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-405B-Instruct-BNB-NF4', hf_model_id='hugging-quants/Meta-Llama-3.1-405B-Instruct-BNB-NF4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4', hf_model_id='hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-70B-Instruct-GPTQ-INT4', hf_model_id='hugging-quants/Meta-Llama-3.1-70B-Instruct-GPTQ-INT4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-405B-Instruct-GPTQ-INT4', hf_model_id='hugging-quants/Meta-Llama-3.1-405B-Instruct-GPTQ-INT4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-8B-Instruct-AWQ-INT4', hf_model_id='hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-70B-Instruct-AWQ-INT4', hf_model_id='hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Meta-Llama-3.1-405B-Instruct-AWQ-INT4', hf_model_id='hugging-quants/Meta-Llama-3.1-405B-Instruct-AWQ-INT4', model_path=None, ms_revision=None, hf_revision=None)], template='llama3_2', ignore_patterns=None, requires=['transformers>=4.43'], tags=[]), ModelGroup(models=[Model(ms_model_id='AI-ModelScope/Llama-3.1-Nemotron-70B-Instruct-HF', hf_model_id='nvidia/Llama-3.1-Nemotron-70B-Instruct-HF', model_path=None, ms_revision=None, hf_revision=None)], template='llama3_2', ignore_patterns=None, requires=['transformers>=4.43'], tags=[]), ModelGroup(models=[Model(ms_model_id='AI-ModelScope/Skywork-o1-Open-Llama-3.1-8B', hf_model_id='Skywork/Skywork-o1-Open-Llama-3.1-8B', model_path=None, ms_revision=None, hf_revision=None)], template='skywork_o1', ignore_patterns=None, requires=['transformers>=4.43'], tags=[]), ModelGroup(models=[Model(ms_model_id='LLM-Research/Llama-3.2-1B', hf_model_id='meta-llama/Llama-3.2-1B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Llama-3.2-3B', hf_model_id='meta-llama/Llama-3.2-3B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Llama-3.2-1B-Instruct', hf_model_id='meta-llama/Llama-3.2-1B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='LLM-Research/Llama-3.2-3B-Instruct', hf_model_id='meta-llama/Llama-3.2-3B-Instruct', model_path=None, ms_revision=None, hf_revision=None)], template='llama3_2', ignore_patterns=None, requires=['transformers>=4.43'], tags=[]), ModelGroup(models=[Model(ms_model_id='LLM-Research/Llama-3.3-70B-Instruct', hf_model_id='meta-llama/Llama-3.3-70B-Instruct', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='unsloth/Llama-3.3-70B-Instruct-bnb-4bit', hf_model_id='unsloth/Llama-3.3-70B-Instruct-bnb-4bit', model_path=None, ms_revision=None, hf_revision=None)], template='llama3_2', ignore_patterns=None, requires=['transformers>=4.43'], tags=[]), ModelGroup(models=[Model(ms_model_id='ZhipuAI/LongWriter-llama3.1-8b', hf_model_id='zai-org/LongWriter-llama3.1-8b', model_path=None, ms_revision=None, hf_revision=None)], template='longwriter_llama', ignore_patterns=None, requires=['transformers>=4.43'], tags=[]), ModelGroup(models=[Model(ms_model_id='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', hf_model_id='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', hf_model_id='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', model_path=None, ms_revision=None, hf_revision=None)], template='deepseek_r1', ignore_patterns=None, requires=None, tags=[]), ModelGroup(models=[Model(ms_model_id='LLM-Research/Reflection-Llama-3.1-70B', hf_model_id='mattshumer/Reflection-Llama-3.1-70B', model_path=None, ms_revision=None, hf_revision=None)], template='reflection', ignore_patterns=None, requires=['transformers>=4.43'], tags=[])], loader=<class 'swift.model.models.llama.LlamaLoader'>, template='llama3_2', model_arch=ModelKeys(arch_name='llama', embedding='model.embed_tokens', module_list='model.layers', lm_head='lm_head', q_proj='model.layers.{}.self_attn.q_proj', k_proj='model.layers.{}.self_attn.k_proj', v_proj='model.layers.{}.self_attn.v_proj', o_proj='model.layers.{}.self_attn.o_proj', attention='model.layers.{}.self_attn', mlp='model.layers.{}.mlp', down_proj='model.layers.{}.mlp.down_proj', qkv_proj=None, qk_proj=None, qa_proj=None, qb_proj=None, kv_proj=None, kva_proj=None, kvb_proj=None), architectures=['LlamaForCausalLM'], additional_saved_files=[], torch_dtype=None, is_multimodal=False, is_reward=False, task_type=None, ignore_patterns=None, requires=['transformers>=4.43'], tags=[])",
  "model_dir": "/root/.cache/modelscope/models/LLM-Research/Meta-Llama-3___1-8B-Instruct",
  "_val_dataset_exists": [],
  "hub": "<class 'swift.hub.hub.MSHub'>",
  "system_message": []
}