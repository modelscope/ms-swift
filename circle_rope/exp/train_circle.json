{
  "model": "/home/ckpt/Qwen2.5-VL-7B-Instruct",
  "model_type": "qwen2_5_vl",
  "custom_register_path": "circle_rope/register.py",

  "model_config_override": {
    "architectures": [
        "Qwen2_5_VLForConditionalGeneration_CircleRoPE"
    ],
    "circle_rope": {
      "alpha": 0.5,
      "radius": 10,
      "method": "circle",
      "AGE_mode": "strategy_4",
      "move_to_origin": true
    }
  },

  "dataset": "/home/dataset/coco#20000",
  "train_type": "full",
  "torch_dtype": "bfloat16",

  "attn_impl": "flash_attention_2",
  "packing": true,
  "padding_free": true,
  "use_liger_kernel": true,

  "num_train_epochs": 1,
  "per_device_train_batch_size": 2,
  "gradient_accumulation_steps": 1,
  "learning_rate": 1e-5,
  "warmup_ratio": 0.05,

  "freeze_vit": true,

  "max_length": 4096,
  "output_dir": "output",

  "save_steps": 1000,
  "save_total_limit": 200,
  "logging_steps": 5,

  "load_from_cache_file": true,
  "split_dataset_ratio": 0.01,
  "dataloader_num_workers": 32,
  "dataset_num_proc": 64
}
