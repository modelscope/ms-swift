# Circle-RoPE Full SFT Training with DeepSpeed ZeRO-2
# Optimized for Qwen2.5-VL multi-GPU full parameter training
# Recommended for: 4-8 GPUs with 40GB+ VRAM each (e.g., A100, A800)

# ==================== Model Configuration ====================
# Replace with your actual model path
model: /path/to/Qwen2.5-VL-7B-Instruct
# Use the registered Circle-RoPE model type
model_type: qwen2_5_vl_circle_rope

# ==================== Training Type ====================
train_type: full  # Full parameter fine-tuning
torch_dtype: bfloat16  # Use bfloat16 for better numerical stability
attn_impl: flash_attn  # Flash Attention 2 for speed and memory efficiency

# ==================== Circle-RoPE Configuration ====================
# Optional: Override default Circle-RoPE settings
model_config_override: |
  {
    "circle_rope": {
      "alpha": 0.5,
      "radius": 10,
      "method": "circle",
      "AGE_mode": "strategy_4",
      "move_to_origin": true
    }
  }

# ==================== Dataset Configuration ====================
dataset: your-dataset-name  # Replace with your dataset
# For multiple datasets:
# dataset: [dataset1, dataset2, dataset3]
split_dataset_ratio: 0.05  # 5% for validation
max_length: 8192  # Maximum sequence length (adjust based on your GPU memory)
truncation_strategy: delete  # delete or truncate

# ==================== Training Hyperparameters ====================
num_train_epochs: 3
per_device_train_batch_size: 1  # Batch size per GPU
per_device_eval_batch_size: 1
gradient_accumulation_steps: 16  # Effective batch size = batch_size * num_gpus * grad_accum_steps

learning_rate: 2e-5  # Lower LR for full fine-tuning
weight_decay: 0.01
max_grad_norm: 1.0  # Gradient clipping

# ==================== Learning Rate Schedule ====================
lr_scheduler_type: cosine
warmup_ratio: 0.03  # 3% warmup

# ==================== Vision Transformer Specific ====================
# Different learning rate for vision encoder (usually lower)
vit_lr: 1e-5  # Lower LR for vision tower
freeze_vit: false  # Set to true to freeze vision tower
freeze_aligner: false  # Set to true to freeze vision-language aligner

# ==================== Optimizer Configuration ====================
optim: adamw_torch
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-8

# ==================== Memory Optimization ====================
gradient_checkpointing: true  # Enable gradient checkpointing to save memory
max_length: 8192
# For larger models or longer sequences, consider reducing max_length or batch_size

# ==================== DeepSpeed ZeRO-2 Configuration ====================
deepspeed: zero2
# ZeRO-2: Optimizer state partitioning + gradient partitioning
# Good balance between memory and communication overhead
# Recommended for 4-8 GPUs

# ==================== Evaluation Configuration ====================
eval_strategy: steps
eval_steps: 500
save_strategy: steps
save_steps: 500
save_total_limit: 5  # Keep only last 5 checkpoints
save_only_model: false  # Save optimizer states for resuming

# ==================== Logging ====================
logging_steps: 10
logging_first_step: true
report_to: tensorboard  # or wandb, mlflow

# ==================== Data Loading ====================
dataloader_num_workers: 4  # Number of workers for data loading
dataset_num_proc: 16  # Number of processes for dataset preprocessing
dataloader_pin_memory: true
remove_unused_columns: false  # Important for multimodal models

# ==================== Mixed Precision Training ====================
fp16: false
bf16: true  # Use bfloat16 for better training stability
bf16_full_eval: true

# ==================== Distributed Training ====================
# These are set automatically by torchrun/deepspeed launcher
# No need to set manually
# ddp_backend: nccl
# ddp_find_unused_parameters: false

# ==================== Checkpointing ====================
save_safetensors: true  # Use safetensors format
output_dir: output/qwen2_5_vl_circle_rope_full_zero2
resume_from_checkpoint: null  # Set to checkpoint path to resume

# ==================== Advanced Settings ====================
# Gradient checkpointing for vision tower (saves more memory)
use_reentrant: false  # For gradient checkpointing

# Packing (for efficiency with variable-length sequences)
# packing: true  # Uncomment if your dataset supports it

# Metrics
metric_for_best_model: eval_loss
greater_is_better: false
load_best_model_at_end: true

# ==================== Custom Settings ====================
# Model name for chat template
model_name: qwen2.5-vl-circle-rope
model_author: your-name

# ==================== Usage ====================
# Run with torchrun (recommended):
# CUDA_VISIBLE_DEVICES=0,1,2,3 \
# NPROC_PER_NODE=4 \
# swift sft --config examples/circle_rope/full_sft_zero2.yaml

# Or with deepspeed launcher:
# deepspeed --num_gpus=4 --master_port=29500 \
# $(which swift) sft --config examples/circle_rope/full_sft_zero2.yaml
