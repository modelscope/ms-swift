"""
æ¨¡å—åŠŸèƒ½
-------
æœ¬æ¨¡å—é›†ä¸­å®šä¹‰ LLM è®­ç»ƒ/å¾®è°ƒå¸¸ç”¨å…¬å¼€æ•°æ®é›†çš„é¢„å¤„ç†å™¨ï¼ˆPreprocessorï¼‰ä¸æ•°æ®é›†æ³¨å†Œï¼ˆregister_datasetï¼‰é€»è¾‘ï¼Œ
æ¶µç›–é€šç”¨å¯¹è¯ã€é•¿æ–‡æœ¬ã€æ•°å­¦ã€æ£€ç´¢é‡æ’ã€å‡½æ•°è°ƒç”¨ã€åˆ†ç±»ã€æ³•åŠ¡ã€ç¼–ç¨‹ç­‰å¤šç±»å‹åœºæ™¯ã€‚æ¯ä¸ªæ•°æ®é›†é€šè¿‡
`DatasetMeta` æè¿°ï¼Œç»“åˆå¯¹åº” `Preprocessor` å°†åŸå§‹æ ·æœ¬è½¬æ¢ä¸ºç»Ÿä¸€è®­ç»ƒæ‰€éœ€çš„ `messages/query/response` ç­‰å­—æ®µã€‚

å…¸å‹ç”¨æ³•
-------
1. å¯¼å…¥æœ¬æ¨¡å—åï¼Œè°ƒç”¨æ–¹ä¼šåœ¨å†…éƒ¨æ³¨å†Œè¡¨ä¸­æŸ¥è¯¢ `ms_dataset_id/hf_dataset_id/subsets/split` å¯¹åº”çš„æ•°æ®é›†ï¼›
2. Trainer æˆ–æ•°æ®ç®¡é“è¯»å– `DatasetMeta` ä¸ `Preprocessor`ï¼Œæ®æ­¤æ„å»ºæ ‡å‡†åŒ–æ ·æœ¬ï¼›
3. é¢„å¤„ç†å™¨å¯é€‰æ‹©æ€§åœ°ä¿®è¡¥ï¼ˆrepairï¼‰æˆ–è£å‰ªæ¶ˆæ¯å†å²ï¼Œä¿è¯æ ·æœ¬è´¨é‡ä¸æ ¼å¼ä¸€è‡´æ€§ã€‚

è¯´æ˜ï¼šä¸ºä¾¿äºé˜…è¯»ä¸ç»´æŠ¤ï¼Œæœ¬æ–‡ä»¶ä¸ºæ¯ä¸€è¡Œä»£ç æ·»åŠ äº†ä¸­æ–‡æ³¨é‡Šï¼ˆå«æ¨¡å—/ç±»/å‡½æ•°æ–‡æ¡£æ³¨é‡Šä¸è¡Œå†…æ³¨é‡Šï¼‰ã€‚
"""

# Copyright (c) Alibaba, Inc. and its affiliates.  # ç‰ˆæƒå£°æ˜ï¼Œè¡¨æ˜ä»£ç å½’å±ä¸æˆæƒä¿¡æ¯
import ast  # æŠ½è±¡è¯­æ³•æ ‘å·¥å…·ï¼Œç”¨äºå®‰å…¨åœ°ä»å­—ç¬¦ä¸²è§£æ Python å­—é¢é‡
import re  # æ­£åˆ™è¡¨è¾¾å¼åº“ï¼Œç”¨äºæ–‡æœ¬æ¨¡å¼åŒ¹é…ä¸æ›¿æ¢
from functools import partial  # åå‡½æ•°å·¥å…·ï¼Œç”¨äºä¸ºå›è°ƒå‡½æ•°é¢„å…ˆç»‘å®šå‚æ•°
from typing import Any, Dict, List, Optional, Tuple, Union  # ç±»å‹æ³¨è§£ï¼šé€šç”¨å­—å…¸/åˆ—è¡¨/å¯é€‰/å…ƒç»„/å¹¶é›†ç±»å‹

import json  # JSON åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼Œç”¨äºå¤„ç†å·¥å…·è°ƒç”¨ç­‰ç»“æ„åŒ–å­—æ®µ
import numpy as np  # æ•°å€¼è®¡ç®—åº“ï¼Œè¿™é‡Œç”¨äºéšæœºé€‰æ‹©ç­‰è½»é‡æ“ä½œ

from ...template import split_str_parts_by  # å­—ç¬¦ä¸²åˆ‡åˆ†è¾…åŠ©å‡½æ•°ï¼ŒæŒ‰å…³é”®æ ‡è®°åˆ†æ®µ
from ..preprocessor import (AlpacaPreprocessor, ClsGenerationPreprocessor, ClsPreprocessor, MessagesPreprocessor,  # å¯¼å…¥å„ç±»é¢„å¤„ç†å™¨
                            ResponsePreprocessor, RowPreprocessor, TextGenerationPreprocessor)  # ç»Ÿä¸€å°†åŸå§‹æ•°æ®è½¬ä¸ºæ ‡å‡†æ ¼å¼
from ..register import DatasetMeta, SubsetDataset, register_dataset  # æ•°æ®é›†å…ƒä¿¡æ¯æè¿°ã€å­é›†å°è£…ä¸æ³¨å†Œå…¥å£


class AlpacaZhPreprocessor(AlpacaPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    åŸºäº `AlpacaPreprocessor` çš„ä¸­æ–‡é€‚é…ç‰ˆæœ¬ã€‚é’ˆå¯¹ä¸­æ–‡æ ·æœ¬ä¸­å¸¸è§çš„å‰ç¼€â€œè¾“å…¥ï¼šâ€è¿›è¡Œè£å‰ªï¼Œ
    å†æ²¿ç”¨çˆ¶ç±»çš„æ‹¼æ¥é€»è¾‘ï¼Œç¡®ä¿ `instruction + input` çš„åˆæˆç»“æœç¬¦åˆè®­ç»ƒæ¨¡æ¿ã€‚

    ç»§æ‰¿å…³ç³»
    -------
    - AlpacaPreprocessor: æä¾›é€šç”¨çš„ alpaca é£æ ¼æ ·æœ¬æ‹¼æ¥ä¸å­—æ®µå½’ä¸€åŒ–èƒ½åŠ›ã€‚
    """

    @classmethod
    def concat_inst_input(cls, instruction, input_):
        """
        å°†æŒ‡ä»¤ä¸è¾“å…¥æ‹¼æ¥ä¸ºç»Ÿä¸€çš„ `instruction + input` å­—ç¬¦ä¸²ã€‚

        å‚æ•°
        ----
        - instruction: æŒ‡ä»¤æ–‡æœ¬ã€‚
        - input_: è¾“å…¥æ–‡æœ¬ï¼Œè‹¥ä»¥â€œè¾“å…¥ï¼šâ€å¼€å¤´åˆ™å‰¥ç¦»æ­¤å‰ç¼€ã€‚

        è¿”å›
        ----
        - str: å¤„ç†å¹¶æ‹¼æ¥åçš„æ–‡æœ¬ï¼Œç”±çˆ¶ç±»å®ç°æœ€ç»ˆæ‹¼æ¥ç»†èŠ‚ã€‚

        ç¤ºä¾‹
        ----
        >>> AlpacaZhPreprocessor.concat_inst_input('è¯·ç¿»è¯‘', 'è¾“å…¥ï¼šä½ å¥½')
        'è¯·ç¿»è¯‘\nä½ å¥½'
        """
        if input_ and input_.startswith('è¾“å…¥ï¼š'):  # è‹¥è¾“å…¥ä»¥ä¸­æ–‡å‰ç¼€â€œè¾“å…¥ï¼šâ€å¼€å¤´
            input_ = input_[3:]  # å»é™¤å‰ä¸‰ä¸ªå­—ç¬¦ä»¥å‰¥ç¦»å‰ç¼€
        return super().concat_inst_input(instruction, input_)  # è°ƒç”¨çˆ¶ç±»æ–¹æ³•å®Œæˆæ ‡å‡†æ‹¼æ¥


register_dataset(
    DatasetMeta(  # åˆ›å»ºæ•°æ®é›†å…ƒä¿¡æ¯ï¼Œæè¿°æ•°æ®æ¥æºä¸é¢„å¤„ç†æ–¹å¼
        ms_dataset_id='AI-ModelScope/alpaca-gpt4-data-zh',  # ModelScope å¹³å°çš„æ•°æ®é›†æ ‡è¯†
        hf_dataset_id='llm-wizard/alpaca-gpt4-data-zh',  # HuggingFace Hub çš„æ•°æ®é›†æ ‡è¯†
        preprocess_func=AlpacaZhPreprocessor(),  # ä½¿ç”¨ä¸­æ–‡é€‚é…ç‰ˆ Alpaca é¢„å¤„ç†å™¨
        tags=['chat', 'general', 'ğŸ”¥'],  # æ ‡ç­¾ï¼šå¯¹è¯/é€šç”¨/çƒ­é—¨
    ))  # ç«‹å³æ³¨å†Œåˆ°æ•°æ®é›†æ³¨å†Œè¡¨


class LongAlpacaPreprocessor(AlpacaPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    é¢å‘é•¿æ–‡æœ¬ Alpaca æ ·æœ¬çš„é¢„å¤„ç†å™¨ã€‚å¯¹éƒ¨åˆ†æ ·æœ¬ä¸­ä»¥â€œAnswer: â€ä¸ºå‰ç¼€çš„å“åº”å­—æ®µè¿›è¡Œè§„æ•´ï¼Œ
    å»é™¤è¯¥å‰ç¼€åå›è½åˆ°çˆ¶ç±»é€šç”¨æµç¨‹å¤„ç†ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å°†é•¿æ–‡æœ¬æ ·æœ¬ä¸­çš„å“åº”å­—æ®µè¿›è¡Œå‰ç¼€ä¿®æ­£åï¼Œäº¤ç»™çˆ¶ç±»åšæ ‡å‡†åŒ–å¤„ç†ã€‚

        å‚æ•°
        ----
        - row: åŸå§‹æ ·æœ¬å­—å…¸ï¼Œé¢„æœŸåŒ…å« `response` ç­‰å­—æ®µã€‚

        è¿”å›
        ----
        - Optional[Dict[str, Any]]: è§„èŒƒåŒ–åçš„æ ·æœ¬ï¼›è‹¥æ ·æœ¬æ— æ•ˆå¯è¿”å› Noneã€‚

        ç¤ºä¾‹
        ----
        >>> pre = LongAlpacaPreprocessor()
        >>> pre.preprocess({'response': 'Answer: hello'})['output']
        'hello'
        """
        response = row['response']  # å–å‡ºå“åº”å­—æ®µ
        prefix_prompt = 'Answer: '  # éœ€è¦å‰¥ç¦»çš„å‰ç¼€
        if response and response.startswith(prefix_prompt):  # è‹¥å“åº”ä»¥è¯¥å‰ç¼€å¼€å¤´
            response = response[len(prefix_prompt):].strip()  # å»æ‰å‰ç¼€å¹¶æ¸…ç†é¦–å°¾ç©ºç™½
            row['output'] = response  # å†™å›æ ‡å‡†è¾“å‡ºå­—æ®µä¾›çˆ¶ç±»å¤„ç†
        return super().preprocess(row)  # äº¤ç”±çˆ¶ç±»è¿›è¡Œç»Ÿä¸€æ ·æœ¬æ ¼å¼åŒ–


register_dataset(
    DatasetMeta(  # æ³¨å†Œ LongAlpaca é•¿åºåˆ—é—®ç­”æ•°æ®
        ms_dataset_id='AI-ModelScope/LongAlpaca-12k',  # MS å¹³å°æ ‡è¯†
        hf_dataset_id='Yukang/LongAlpaca-12k',  # HF å¹³å°æ ‡è¯†
        preprocess_func=LongAlpacaPreprocessor(),  # ç»‘å®šå¯¹åº”é¢„å¤„ç†å™¨
        tags=['long-sequence', 'QA'],  # æ ‡ç­¾ï¼šé•¿åºåˆ—/é—®ç­”
    ))  # å®Œæˆæ³¨å†Œ


class RuozhibaPreprocessor(RowPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å¤„ç†â€œè‹¥çŸ¥å§â€ä¸­æ–‡è®ºå›æ•°æ®ï¼š
    - ä¼˜å…ˆä½¿ç”¨ `title` å­—æ®µï¼Œå¦åˆ™å›é€€åˆ° `content`ï¼›
    - è‹¥å­˜åœ¨æ‘˜è¦ `abs` ä¸”ä¸åŒäºæ ‡é¢˜ï¼Œåˆ™æ‹¼æ¥åˆ°æ ‡é¢˜åï¼›
    - é€šè¿‡æ­£åˆ™å»é™¤å‰ç¼€åºå·ç­‰å™ªå£°ï¼Œä»…ä¿ç•™ä¸»è¦å†…å®¹ï¼›
    - ä»¥ assistant å•è½®æ¶ˆæ¯å½¢å¼è¿”å›ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å°†åŸå§‹æ¡ç›®è§„æ•´ä¸ºå•è½® assistant æ¶ˆæ¯ã€‚

        å‚æ•°
        ----
        - row: åŸå§‹æ ·æœ¬ï¼ŒåŒ…å« `title/content/abs` ç­‰å­—æ®µã€‚

        è¿”å›
        ----
        - Optional[Dict[str, Any]]: åŒ…å« `messages` çš„æ ‡å‡†æ ·æœ¬ï¼›æ— å¯ç”¨æ ‡é¢˜æ—¶è¿”å› Noneã€‚

        ç¤ºä¾‹
        ----
        >>> pre = RuozhibaPreprocessor()
        >>> pre.preprocess({'title': '1. æµ‹è¯•æ ‡é¢˜', 'content': 'æ­£æ–‡', 'abs': 'æ‘˜è¦'})['messages'][0]['content']
        'æµ‹è¯•æ ‡é¢˜ï¼Œæ‘˜è¦'
        """
        title = row['title'] if row.get('title', None) is not None else row['content']  # é€‰å–æ ‡é¢˜ï¼Œå¦åˆ™å›é€€å†…å®¹
        abs = row['abs'] if 'abs' in row else None  # è¯»å–æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
        if abs and abs != title:  # è‹¥æ‘˜è¦å­˜åœ¨ä¸”ä¸åŒäºæ ‡é¢˜
            title = title + 'ï¼Œ' + abs  # å°†æ‘˜è¦æ‹¼æ¥åœ¨æ ‡é¢˜åï¼Œä¸°å¯Œä¿¡æ¯

        pattern = r'\d+[\.,\s,\ã€](.+)'  # åŒ¹é…ä»¥åºå·å¼€å¤´çš„æ ‡é¢˜å¹¶æ•è·åç»­ä¸»ä½“
        match = re.search(pattern, title)  # æ‰§è¡Œæ­£åˆ™åŒ¹é…
        if match:  # å‘½ä¸­åˆ™è£å‰ªå‡ºä¸»ä½“éƒ¨åˆ†
            title = match.group(1)  # æå–ç¬¬ä¸€ä¸ªæ•è·ç»„
        if title:  # æ ‡é¢˜éç©ºåˆ™æ„é€ æ¶ˆæ¯
            return {'messages': [{'role': 'assistant', 'content': title}]}  # è¿”å›ä»…å« assistant çš„å•è½®æ¶ˆæ¯


register_dataset(
    DatasetMeta(  # æ³¨å†Œè‹¥çŸ¥å§æ•°æ®é›†
        ms_dataset_id='AI-ModelScope/ruozhiba',  # MS å¹³å°æ•°æ®é›† ID
        subsets=['post-annual', 'title-good', 'title-norm'],  # å¯ç”¨å­é›†åˆ—è¡¨
        preprocess_func=RuozhibaPreprocessor(),  # ç»‘å®šé¢„å¤„ç†å™¨
        tags=['pretrain', 'ğŸ”¥']))  # æ ‡ç­¾ï¼šé¢„è®­ç»ƒ/çƒ­é—¨


class MathTrnPreprocessor(ResponsePreprocessor):
    """
    æ•°å­¦è®­ç»ƒæ•°æ®çš„è½»é‡è§„æ•´ï¼šä¿æŒ `query/response` å­—æ®µå‘½åä¸€è‡´åäº¤ç”±çˆ¶ç±»å¤„ç†ã€‚
    """

    def preprocess(self, row):
        """
        è¯»å–åŸå§‹ `query/response`ï¼Œé‡ç»„åè°ƒç”¨çˆ¶ç±»æ ‡å‡†æµç¨‹ã€‚

        å‚æ•°
        ----
        - row: åŸå§‹æ ·æœ¬ï¼Œå« `query/response`ã€‚

        è¿”å›
        ----
        - Dict[str, Any]: è§„èŒƒåŒ–åçš„æ ·æœ¬ã€‚

        ç¤ºä¾‹
        ----
        >>> MathTrnPreprocessor().preprocess({'query': '1+1=?', 'response': '2'})['response']
        '2'
        """
        query = row['query']  # è¯»å–é¢˜ç›®
        output = row['response']  # è¯»å–ç­”æ¡ˆ
        row = {
            'query': query,  # å†™å›æŸ¥è¯¢
            'response': output,  # å†™å›ç­”æ¡ˆ
        }
        return super().preprocess(row)  # è°ƒç”¨çˆ¶ç±»ç»Ÿä¸€å¤„ç†


register_dataset(
    DatasetMeta(ms_dataset_id='AI-ModelScope/math-trn-format',  # æ³¨å†Œæ•°å­¦è®­ç»ƒæ ¼å¼åŒ–æ•°æ®
                preprocess_func=MathTrnPreprocessor(),  # ç»‘å®šæ•°å­¦é¢„å¤„ç†å™¨
                tags=['math']))  # æ ‡ç­¾ï¼šæ•°å­¦


def _repair_ms_bench(messages: str) -> Optional[List[Dict[str, str]]]:
    """
    ä¿®è¡¥ MS Bench æ¶ˆæ¯ï¼š
    - å­—ç¬¦ä¸²è¾“å…¥å…ˆç”¨ `ast.literal_eval` å®‰å…¨è§£æä¸ºåˆ—è¡¨ï¼›
    - åˆ é™¤é»˜è®¤ system æç¤ºï¼›
    - è¿‡æ»¤åŒ…å«â€œMOSS/role æç¤ºâ€çš„æ ·æœ¬ï¼Œè¿”å› None ä»¥è·³è¿‡ã€‚

    å‚æ•°
    ----
    - messages: æ¶ˆæ¯åˆ—è¡¨æˆ–å…¶å­—ç¬¦ä¸²è¡¨ç¤ºã€‚

    è¿”å›
    ----
    - Optional[List[Dict[str, str]]]: ä¿®è¡¥åçš„æ¶ˆæ¯åˆ—è¡¨ï¼›è‹¥éœ€è·³è¿‡åˆ™è¿”å› Noneã€‚

    ç¤ºä¾‹
    ----
    >>> _repair_ms_bench("[{'from':'user','value':'hi'}]")
    [{'from': 'user', 'value': 'hi'}]
    """
    if isinstance(messages, str):  # è‹¥ä¼ å…¥å­—ç¬¦ä¸²
        messages = ast.literal_eval(messages)  # å®‰å…¨è§£æä¸º Python å­—é¢é‡
    default_system = 'You are a helpful assistant.'  # é»˜è®¤çš„ system æ¨¡æ¿
    messages: List[Dict[str, str]]  # ç±»å‹æç¤ºï¼Œæ ‡æ˜æ¶ˆæ¯åˆ—è¡¨å…ƒç´ ç»“æ„
    if messages[0]['from'] == 'system' and messages[0]['value'] == default_system:  # è‹¥ç¬¬ä¸€æ¡ä¸ºé»˜è®¤ system
        messages.pop(0)  # ç§»é™¤é»˜è®¤ system
    # skip MOSS  # è·³è¿‡åŒ…å« MOSS æˆ–æ˜¾å¼è§’è‰²æç¤ºçš„æ ·æœ¬
    for c in messages:  # éå†æ¯æ¡æ¶ˆæ¯
        value = c['value'].lower()  # å°å†™åŒ–ä¾¿äºåŒ¹é…
        if 'moss' in value or 'human:' in value or 'assistant:' in value or 'user:' in value:  # å‡ºç°è¿™äº›æ ‡è®°åˆ™è·³è¿‡
            return  # è¿”å› None è¡¨ç¤ºä¸¢å¼ƒ
    return messages  # è¿”å›ä¿®è¡¥åçš„æ¶ˆæ¯åˆ—è¡¨


register_dataset(
    DatasetMeta(  # æ³¨å†Œ MS Bench æ•°æ®é›†
        ms_dataset_id='iic/ms_bench',  # æ•°æ®é›† ID
        preprocess_func=MessagesPreprocessor(repair_messages=_repair_ms_bench),  # ä½¿ç”¨æ¶ˆæ¯ä¿®è¡¥å‡½æ•°
        tags=['chat', 'general', 'multi-round', 'ğŸ”¥']))  # æ ‡ç­¾ï¼šå¯¹è¯/é€šç”¨/å¤šè½®/çƒ­é—¨


def _repair_agent_messages(messages: List[Dict[str, str]], use_mini: bool) -> Optional[List[Dict[str, str]]]:
    """
    ä¿®è¡¥ Agent æ¶ˆæ¯ï¼š
    - å½“ use_mini=True æ—¶ï¼Œæ£€æŸ¥ system ä¸­æ’ä»¶åç§°æ˜¯å¦å¤šæ ·ï¼›è‹¥ä¸è¶³åˆ™è·³è¿‡è¯¥æ ·æœ¬ã€‚

    å‚æ•°
    ----
    - messages: æ¶ˆæ¯åˆ—è¡¨ã€‚
    - use_mini: æ˜¯å¦é‡‡ç”¨ mini å­é›†çš„ç­›é€‰é€»è¾‘ã€‚

    è¿”å›
    ----
    - Optional[List[Dict[str, str]]]: é€šè¿‡ç­›é€‰çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œå¦åˆ™è¿”å› Noneã€‚
    """
    if use_mini:  # mini å­é›†éœ€è¦è¾ƒä¸¥æ ¼çš„å¤šæ’ä»¶æ£€éªŒ
        pattern = r'\d\. {"plugin_name": "(.+?)"'  # åŒ¹é…æ’ä»¶åç§°çš„æ¨¡å¼
        if messages[0]['from'] != 'system':  # mini å­é›†è¦æ±‚é¦–æ¡ä¸º system
            return  # ä¸æ»¡è¶³ç›´æ¥è·³è¿‡
        system = messages[0]['value']  # è¯»å– system å†…å®¹
        find_list = re.findall(pattern, system)  # æå–æ’ä»¶åç§°åˆ—è¡¨
        if len(set(find_list)) <= 1:  # æ’ä»¶æ•°é‡ä¸è¶³ 2 ç§
            return  # è·³è¿‡
    return messages  # è¿”å›åŸæ¶ˆæ¯åˆ—è¡¨ï¼ˆé€šè¿‡ç­›é€‰ï¼‰


register_dataset(
    DatasetMeta(  # æ³¨å†Œ MSAgent-Bench æ•°æ®é›†
        ms_dataset_id='damo/MSAgent-Bench',  # æ•°æ®é›† ID
        subsets=[  # å®šä¹‰ä¸¤ä¸ªå­é›†ï¼šé»˜è®¤ä¸ mini
            SubsetDataset(  # é»˜è®¤å­é›†ï¼šä¸è¿‡æ»¤æ’ä»¶å¤šæ ·æ€§
                preprocess_func=MessagesPreprocessor(repair_messages=partial(_repair_agent_messages, use_mini=False))),
            SubsetDataset(  # mini å­é›†ï¼šè¦æ±‚æ’ä»¶å¤šæ ·æ€§
                name='mini',
                preprocess_func=MessagesPreprocessor(repair_messages=partial(_repair_agent_messages, use_mini=True)),
                is_weak_subset=True)
        ],
        split=['train', 'validation'],  # å¯ç”¨åˆ’åˆ†
        tags=['chat', 'agent', 'multi-round']))  # æ ‡ç­¾ï¼šå¯¹è¯/æ™ºèƒ½ä½“/å¤šè½®

advertise_gen_prompt = """Task: Generating advertisements based on keywords.
Keywords: {{QUERY}}
Advertisements:"""  # æ–‡æœ¬ç”Ÿæˆæç¤ºæ¨¡æ¿ï¼šåŸºäºå…³é”®è¯ç”Ÿæˆå¹¿å‘Šæ–‡æ¡ˆ

register_dataset(
    DatasetMeta(  # æ³¨å†Œ AdvertiseGen æ–‡æ¡ˆç”Ÿæˆæ•°æ®
        ms_dataset_id='lvjianjin/AdvertiseGen',  # MS æ•°æ®é›† ID
        hf_dataset_id='shibing624/AdvertiseGen',  # HF æ•°æ®é›† ID
        preprocess_func=TextGenerationPreprocessor(  # ä½¿ç”¨é€šç”¨æ–‡æœ¬ç”Ÿæˆé¢„å¤„ç†å™¨
            prompt=advertise_gen_prompt, columns={  # æŒ‡å®šæç¤ºæ¨¡æ¿ä¸å­—æ®µæ˜ å°„
                'content': 'query',  # æºå­—æ®µ content -> ç»Ÿä¸€å­—æ®µ query
                'summary': 'response'  # æºå­—æ®µ summary -> ç»Ÿä¸€å­—æ®µ response
            }),
        tags=['text-generation', 'ğŸ”¥'],  # æ ‡ç­¾ï¼šæ–‡æœ¬ç”Ÿæˆ/çƒ­é—¨
        split=['train', 'validation'],  # åˆ’åˆ†ï¼šè®­ç»ƒ/éªŒè¯
    ))  # å®Œæˆæ³¨å†Œ


class FireflyPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    é€‚é… Firefly æ•°æ®é›†çš„é¢„å¤„ç†å™¨ï¼šä»…ä¿ç•™ `kind` å±äºç™½åå•é›†åˆçš„æ ·æœ¬ï¼Œå…¶ä½™æ ·æœ¬è·³è¿‡ã€‚
    æœ€ç»ˆè°ƒç”¨çˆ¶ç±» `ResponsePreprocessor` åšæ ‡å‡†åŒ–å¤„ç†ï¼ˆäº§å‡º query/response/messages ç­‰ï¼‰ã€‚
    """
    _firefly_kind_list = {  # Firefly æ•°æ®é›†å…è®¸çš„ä»»åŠ¡ç§ç±»ç™½åå•
        'ProseGeneration', 'MRC', 'JinYongGeneration', 'TextCorrection', 'ClassicalChinese', 'BELLE', 'StoryGeneration',
        'Couplet', 'Cot', 'Dictionary', 'Translation', 'Program', 'SentimentAnalyze', 'OpenQA', 'AncientPoem',
        'TextMatching', 'NLI', 'Summary', 'KeywordRecognition', 'ProductDesc', 'LyricGeneration', 'Composition',
        'MusicComment', 'NER'
    }

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è¿‡æ»¤ä¸åœ¨ç™½åå•ä¸­çš„æ ·æœ¬ï¼Œå¹¶ä½¿ç”¨çˆ¶ç±»å®Œæˆæ ‡å‡†åŒ–ã€‚

        å‚æ•°
        ----
        - row: åŸå§‹æ ·æœ¬ï¼ŒåŒ…å« `kind` å­—æ®µã€‚

        è¿”å›
        ----
        - Optional[Dict[str, Any]]: è§„èŒƒåŒ–æ ·æœ¬ï¼›å½“ `kind` ä¸ç¬¦åˆæ—¶è¿”å› Noneã€‚

        ç¤ºä¾‹
        ----
        >>> FireflyPreprocessor().preprocess({'kind': 'OpenQA', 'query': 'é—®', 'response': 'ç­”'}) is not None
        True
        """
        if row['kind'] not in FireflyPreprocessor._firefly_kind_list:  # è‹¥æ ·æœ¬ç§ç±»ä¸åœ¨ç™½åå•
            return  # è·³è¿‡è¯¥æ ·æœ¬
        return super().preprocess(row)  # äº¤ç”±çˆ¶ç±»è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†


register_dataset(
    DatasetMeta(  # æ³¨å†Œ Firefly è®­ç»ƒæ•°æ®é›†
        ms_dataset_id='AI-ModelScope/firefly-train-1.1M',  # MS å¹³å° ID
        hf_dataset_id='YeungNLP/firefly-train-1.1M',  # HF å¹³å° ID
        preprocess_func=FireflyPreprocessor(),  # ä½¿ç”¨ Firefly é¢„å¤„ç†å™¨
        tags=['chat', 'general'],  # æ ‡ç­¾ï¼šå¯¹è¯/é€šç”¨
    ))  # å®Œæˆæ³¨å†Œ

register_dataset(
    DatasetMeta(  # æ³¨å†Œ CLUE cmnli è‡ªç„¶è¯­è¨€æ¨æ–­æ•°æ®é›†
        ms_dataset_id='modelscope/clue',  # MS æ•°æ®é›† ID
        hf_dataset_id='clue',  # HF æ•°æ®é›† ID
        subsets=['cmnli'],  # ä»…ä½¿ç”¨ cmnli å­é›†
        preprocess_func=ClsGenerationPreprocessor(['neutral', 'entailment', 'contradiction'],  # ç”Ÿæˆå¼åˆ†ç±»é¢„å¤„ç†å™¨
                                                  task='Natural Language Inference',  # ä»»åŠ¡å
                                                  is_pair_seq=True),  # è¾“å…¥ä¸ºå¥å¯¹
        tags=['text-generation', 'classification'],  # æ ‡ç­¾ï¼šç”Ÿæˆ/åˆ†ç±»
        split=['train', 'validation'],  # åˆ’åˆ†ï¼šè®­ç»ƒ/éªŒè¯
    ))  # å®Œæˆæ³¨å†Œ

register_dataset(
    DatasetMeta(  # æ³¨å†Œäº¬ä¸œæƒ…æ„Ÿåˆ†ç±»æ•°æ®é›†
        ms_dataset_id='DAMO_NLP/jd',  # MS æ•°æ®é›† ID
        subsets=[  # ä¸¤ä¸ªå­é›†ï¼šç”Ÿæˆå¼åˆ†ç±»ä¸çº¯åˆ†ç±»
            SubsetDataset(  # ç”Ÿæˆå¼åˆ†ç±»ï¼šè¾“å‡ºä¸ºæƒ…æ„Ÿæ ‡ç­¾æ–‡æœ¬
                'default',  # å­é›†å
                'default',  # æºå­é›†
                preprocess_func=ClsGenerationPreprocessor(['negative', 'positive'],  # æ ‡ç­¾ç©ºé—´
                                                          task='Sentiment Classification',  # ä»»åŠ¡å
                                                          is_pair_seq=False)),  # å•å¥åˆ†ç±»
            SubsetDataset(  # çº¯åˆ†ç±»ï¼šä»…æ„é€  query/label
                'cls',
                'default',
                preprocess_func=ClsPreprocessor(columns={'sentence': 'query'}),  # åˆ—æ˜ å°„ï¼šsentence -> query
            ),
        ],
        tags=['text-generation', 'classification', 'ğŸ”¥'],  # æ ‡ç­¾ï¼šç”Ÿæˆ/åˆ†ç±»/çƒ­é—¨
        split=['train', 'validation'],  # åˆ’åˆ†ï¼šè®­ç»ƒ/éªŒè¯
    ))  # å®Œæˆæ³¨å†Œ


class SyntheticText2SqlPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å°†åˆæˆçš„ NL2SQL æ•°æ®è¡Œæ‹¼æ¥ä¸ºå¸¦æœ‰è¡¨ç»“æ„ä¸æç¤ºè¯­çš„ `query`ï¼Œå¹¶å°†æ¨ç†æ­¥éª¤+æœ€ç»ˆ SQL ç»„åˆä¸º `response`ï¼Œ
    å†äº¤ç»™çˆ¶ç±»è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ„é€  NL2SQL çš„ query/response å¹¶æ‰§è¡Œæ ‡å‡†åŒ–ã€‚

        å‚æ•°
        ----
        - row: åŒ…å« `sql_prompt/sql_context/sql/sql_explanation` çš„åŸå§‹æ ·æœ¬ã€‚

        è¿”å›
        ----
        - Dict[str, Any]: è§„èŒƒåŒ–åçš„æ ·æœ¬ã€‚

        ç¤ºä¾‹
        ----
        >>> pre = SyntheticText2SqlPreprocessor()
        >>> rec = pre.preprocess({'sql_prompt':'Q','sql_context':'T','sql':'S','sql_explanation':'E'})
        >>> 'Sql Table information' in rec['query'] and 'final sql' in rec['response']
        True
        """
        sql_prompt = row['sql_prompt']  # NL æŸ¥è¯¢æç¤º
        sql_context = row['sql_context']  # è¡¨ç»“æ„/ä¸Šä¸‹æ–‡
        sql = row['sql']  # æœ€ç»ˆ SQL
        sql_explanation = row['sql_explanation']  # é€æ­¥æ¨ç†è¯´æ˜
        query = f'Sql Table information:\n{sql_context}\n{sql_prompt}'  # æ„é€ åŒ…å«è¡¨ä¿¡æ¯ä¸æç¤ºçš„æŸ¥è¯¢
        response = f'Let\'s think step by step:\n{sql_explanation}\nSo the final sql is:\n{sql}'  # ç»„åˆè§£é‡Šä¸æœ€ç»ˆ SQL
        return super().preprocess({'query': query, 'response': response})  # äº¤ç»™çˆ¶ç±»æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/synthetic_text_to_sql',
        hf_dataset_id='gretelai/synthetic_text_to_sql',
        preprocess_func=SyntheticText2SqlPreprocessor(),
        tags=['nl2sql', 'en']))


def _repair_toolbench(conversations: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """
    ä¿®è¡¥ ToolBench å¯¹è¯è§’è‰²ï¼šå°†ç¬¬äºŒæ¡æ¶ˆæ¯çš„è§’è‰²ä» caller/conclusion è§„èŒƒä¸º assistantã€‚

    å‚æ•°
    ----
    - conversations: ä¸¤æ¡æ¶ˆæ¯çš„åˆ—è¡¨ã€‚

    è¿”å›
    ----
    - List[Dict[str, str]]: è§’è‰²ä¿®æ­£åçš„æ¶ˆæ¯åˆ—è¡¨ã€‚
    """
    assert len(conversations) == 2  # é¢„æœŸæ°æœ‰ä¸¤æ¡æ¶ˆæ¯
    if conversations[1]['from'] in {'caller', 'conclusion'}:  # è‹¥ç¬¬äºŒæ¡ä¸ºå·¥å…·è°ƒç”¨è€…/ç»“è®º
        conversations[1]['from'] = 'assistant'  # ç»Ÿä¸€æ”¹ä¸º assistant
    return conversations  # è¿”å›ä¿®æ­£ç»“æœ


register_dataset(
    DatasetMeta(
        ms_dataset_id='shenweizhou/alpha-umi-toolbench-processed-v2',
        subsets=['backbone', 'caller', 'planner', 'summarizer'],
        preprocess_func=MessagesPreprocessor(repair_messages=_repair_toolbench),
        tags=['chat', 'agent', 'ğŸ”¥'],
        huge_dataset=True))


class BlossomMathPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å°† Blossom-Math çš„è¾“å‡ºä¸æ ‡å‡†ç­”æ¡ˆåˆå¹¶åˆ° `response` ä¸­ï¼Œä¿æŒåŸå§‹ `query` ä¸å˜ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†è¾“å‡ºä¸ç­”æ¡ˆæ‹¼æ¥ä¸ºå“åº”æ–‡æœ¬ã€‚

        å‚æ•°
        ----
        - row: åŒ…å« `query/output/answer` çš„è®°å½•ã€‚

        è¿”å›
        ----
        - Dict[str, Any]: æ ‡å‡†åŒ–æ ·æœ¬ã€‚
        """
        output, answer = row['output'], row['answer']  # è¯»å–æ¨¡å‹è¾“å‡ºä¸ç­”æ¡ˆ
        return super().preprocess({'query': row['query'], 'response': f'{output}\n\nAnswer: {answer}'})  # æ‹¼æ¥å¹¶æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/blossom-math-v2',
        hf_dataset_id='Azure99/blossom-math-v2',
        preprocess_func=BlossomMathPreprocessor(),
        tags=['chat', 'math', 'ğŸ”¥']))

register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/sql-create-context',
        hf_dataset_id='b-mc2/sql-create-context',
        preprocess_func=AlpacaPreprocessor(columns={
            'question': 'instruction',
            'context': 'input',
            'answer': 'output'
        }),
        tags=['chat', 'sql', 'ğŸ”¥']))


class TigerBotLawPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å°†æ³•åŠ¡åœºæ™¯çš„å¤šå­—æ®µå†…å®¹æ‹¼æ¥ä¸ºä¸€ä¸ªé•¿å“åº”ï¼šç”± `type/title/chapter1-3/response` ç»„æˆï¼Œ
    é€‚åˆç”¨äºç”Ÿæˆå¼/æ‘˜è¦å¼ä»»åŠ¡çš„è®­ç»ƒã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¾æ¬¡æ‹¼æ¥ç±»å‹ã€æ ‡é¢˜ã€ç« èŠ‚ä¸æœ€ç»ˆå“åº”ï¼Œæ„é€ é•¿å“åº”æ–‡æœ¬ã€‚

        å‚æ•°
        ----
        - row: åŒ…å« `type/title/chapter1-3/response` çš„è®°å½•ã€‚

        è¿”å›
        ----
        - Dict[str, Any]: åªè®¾ç½® `response` çš„æ ‡å‡†åŒ–æ ·æœ¬ã€‚
        """
        prompt = """{type}
{title}
"""  # é¡¶éƒ¨æç¤ºæ¨¡æ¿ï¼šç±»å‹ä¸æ ‡é¢˜ä¸¤è¡Œ
        cur_prompt = prompt.format(type=row['type'], title=row['title'])  # å¡«å……ç±»å‹ä¸æ ‡é¢˜
        for i in range(1, 4):  # éå†ä¸‰ä¸ªå¯èƒ½çš„ç« èŠ‚å­—æ®µ
            chapter = row[f'chapter{i}']  # è¯»å–ç« èŠ‚å†…å®¹
            if chapter is not None:  # è‹¥ç« èŠ‚å­˜åœ¨
                cur_prompt += f'{chapter}'  # è¿½åŠ åˆ°å“åº”æ­£æ–‡
        cur_prompt += f'{row["response"]}'  # æœ«å°¾è¿½åŠ åŸå“åº”å†…å®¹
        return super().preprocess({'response': cur_prompt})  # äº¤ç»™çˆ¶ç±»æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/tigerbot-law-plugin',
        hf_dataset_id='TigerResearch/tigerbot-law-plugin',
        preprocess_func=TigerBotLawPreprocessor(),
        tags=['text-generation', 'law', 'pretrained']))

register_dataset(
    DatasetMeta(
        ms_dataset_id='codefuse-ai/CodeExercise-Python-27k',
        preprocess_func=MessagesPreprocessor(columns={'chat_rounds': 'messages'}),
        tags=['chat', 'coding', 'ğŸ”¥']))


class LeetcodePythonPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    è§£æ LeetCode Python é¢˜è§£æ ·æœ¬ï¼š
    - ä» `code_with_problem` åˆ‡åˆ†å‡ºé¢˜ç›®ä¸ä»£ç å—ï¼›
    - å»æ‰é¢˜ç›®å‰ç¼€ `# `ï¼›
    - å°†é¢˜ç›®ä½œä¸º `query`ï¼Œä»£ç ä¸è§£é‡Šåˆå¹¶ä¸º `response`ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        è§£æé¢˜ç›®ä¸ä»£ç ï¼Œæ‹¼æ¥è§£é‡Šæ–‡æœ¬åæ ‡å‡†åŒ–ã€‚

        å‚æ•°
        ----
        - row: å« `code_with_problem/explanation_only` çš„è®°å½•ã€‚

        è¿”å›
        ----
        - Dict[str, Any]: æ ‡å‡†åŒ–æ ·æœ¬ã€‚
        """
        code_with_problem = row['code_with_problem']  # åŒ…å«é¢˜ç›®ä¸ä»£ç çš„æ•´ä½“æ–‡æœ¬
        idx = code_with_problem.find('```python')  # å®šä½ä»£ç å—èµ·å§‹ä½ç½®
        problem = code_with_problem[:idx]  # æå–é¢˜ç›®éƒ¨åˆ†
        if problem.startswith('# '):  # è‹¥é¢˜ç›®å‰æœ‰ Markdown æ³¨é‡Šå‰ç¼€
            problem = problem[2:]  # å»æ‰å‰ç¼€
        code = code_with_problem[idx:].strip()  # æå–ä»£ç å—å¹¶å»æ‰é¦–å°¾ç©ºç™½
        explanation = row['explanation_only']  # è¯»å–æ–‡å­—è§£é‡Š
        return super().preprocess({'query': problem, 'response': f'{code}\n\n{explanation}'})  # æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/leetcode-solutions-python',
        preprocess_func=LeetcodePythonPreprocessor(),
        tags=['chat', 'coding', 'ğŸ”¥']))


class StsbPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    STS-B ç›¸ä¼¼åº¦æ•°æ®é¢„å¤„ç†å™¨ï¼š
    - å°† `(sentence1, sentence2, score)` è½¬æ¢ä¸º `(query, response, label)`ï¼›
    - æ”¯æŒå¯é€‰é˜ˆå€¼ `sim_threshold`ï¼Œä½äºé˜ˆå€¼çš„æ ·æœ¬å¯è¢«ä¸¢å¼ƒã€‚
    """

    def __init__(self, sim_threshold: Optional[float] = None):
        """
        åˆå§‹åŒ–ç›¸ä¼¼åº¦é˜ˆå€¼ã€‚

        å‚æ•°
        ----
        - sim_threshold: è‹¥è®¾ç½®ï¼Œåˆ™åªä¿ç•™å¾—åˆ†ä¸ä½äºè¯¥é˜ˆå€¼çš„æ ·æœ¬ã€‚
        """
        self.sim_threshold = sim_threshold  # ä¿å­˜é˜ˆå€¼é…ç½®
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ 

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ„å»ºæ ‡å‡†å­—æ®µå¹¶æŒ‰éœ€è¿‡æ»¤ä½ç›¸ä¼¼åº¦æ ·æœ¬ã€‚

        å‚æ•°
        ----
        - row: åŒ…å« `sentence1/sentence2/score` çš„è®°å½•ã€‚

        è¿”å›
        ----
        - Dict[str, Any] æˆ– None: é€šè¿‡ç­›é€‰çš„æ ·æœ¬ï¼›è¢«è¿‡æ»¤åˆ™è¿”å› Noneã€‚
        """
        row = {
            'query': row['sentence1'],  # å¥å­ 1 ä½œä¸ºæŸ¥è¯¢
            'response': row['sentence2'],  # å¥å­ 2 ä½œä¸ºå“åº”
            'label': row['score'],  # ç›¸ä¼¼åº¦åˆ†æ•°ä½œä¸ºæ ‡ç­¾
        }
        if self.sim_threshold is None or float(row['label']) >= self.sim_threshold:  # æœªè®¾ç½®é˜ˆå€¼æˆ–åˆ†æ•°è¾¾æ ‡
            return super().preprocess(row)  # æ ‡å‡†åŒ–
        else:
            return None  # è¿‡æ»¤æ‰ä½åˆ†æ ·æœ¬


class StsbGeneratePreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    ç”Ÿæˆå¼ STS-Bï¼šæ„é€ å¸¦æ¨¡æ¿çš„ `query`ï¼Œå°†æµ®ç‚¹åˆ†æ•°æ ¼å¼åŒ–ä¸ºä¸€ä½å°æ•°çš„å­—ç¬¦ä¸²ä½œä¸º `response`ã€‚
    """
    prompt = """Task: Based on the given two sentences, provide a similarity score between 0.0 and 1.0.
Sentence 1: {text1}
Sentence 2: {text2}
Similarity score: """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        æ„é€ é—®å¥ä¸åˆ†æ•°å­—ç¬¦ä¸²ï¼Œå¹¶äº¤ç”±çˆ¶ç±»æ ‡å‡†åŒ–ã€‚
        """
        return super().preprocess({
            'query': self.prompt.format(text1=row['sentence1'], text2=row['sentence2']),  # æ¨¡æ¿åŒ–æŸ¥è¯¢
            'response': f"{row['score']:.1f}"  # ä¸€ä½å°æ•°æ ¼å¼çš„åˆ†æ•°
        })
        return super().preprocess({})


class StsbRegressionPreprocessor(StsbGeneratePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å›å½’å¼ STS-Bï¼šquery ä¸ `StsbGeneratePreprocessor` ä¸€è‡´ï¼Œä½†å°†æ•°å€¼åˆ†æ•°ä½œä¸º `label`ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å¤ç”¨çˆ¶ç±»æ¨¡æ¿æ„é€  queryï¼Œå¹¶è¾“å‡º labelã€‚
        """
        return super(StsbGeneratePreprocessor, self).preprocess({
            'query': self.prompt.format(text1=row['sentence1'], text2=row['sentence2']),  # æ¨¡æ¿åŒ–æŸ¥è¯¢
            'label': row['score']  # ä½¿ç”¨å›å½’æ ‡ç­¾
        })


register_dataset(
    DatasetMeta(
        ms_dataset_id='sentence-transformers/stsb',
        hf_dataset_id='sentence-transformers/stsb',
        subsets=[
            SubsetDataset('default', preprocess_func=StsbPreprocessor()),  # embedding
            SubsetDataset('positive', preprocess_func=StsbPreprocessor(sim_threshold=0.75)),  # infonce
            SubsetDataset('generate', preprocess_func=StsbGeneratePreprocessor()),
            SubsetDataset('reg', preprocess_func=StsbRegressionPreprocessor()),
        ],
        tags=['similarity', 'ğŸ”¥']))


class MTEBRerankPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å°† Reranking ä»»åŠ¡ä¸­çš„ä¸€ä¸ªæŸ¥è¯¢ä¸å¤šä¸ªæ­£/è´Ÿæ ·æœ¬å±•å¼€ä¸ºå¤šæ¡æ ·æœ¬ï¼š
    - æ¯ä¸ª positive å˜æˆä¸€æ¡æ ·æœ¬ï¼Œå…¶ `rejected_response` ä¸ºå…¨éƒ¨ negativesï¼›
    - äº¤ç”±çˆ¶ç±»æ ‡å‡†åŒ–åè¿”å›ä¸€ä¸ªåˆ—è¡¨ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        å±•å¼€æ­£è´Ÿæ ·æœ¬å¯¹ï¼Œç”Ÿæˆå¤šæ¡æ ·æœ¬ã€‚
        """
        query = row['query']  # æŸ¥è¯¢æ–‡æœ¬
        positives = row['positive'] if isinstance(row['positive'], list) else [row['positive']]  # è§„èŒƒæ­£æ ·æœ¬ä¸ºåˆ—è¡¨
        negatives = row['negative'] if isinstance(row['negative'], list) else [row['negative']]  # è§„èŒƒè´Ÿæ ·æœ¬ä¸ºåˆ—è¡¨

        expanded_rows = []  # å­˜æ”¾å±•å¼€åçš„æ ·æœ¬
        for positive in positives:  # éå†æ¯ä¸ªæ­£æ ·æœ¬
            expanded_row = {'query': query, 'response': positive, 'rejected_response': negatives}  # æ„é€ ä¸€æ¡æ ·æœ¬
            expanded_rows.append(super().preprocess(expanded_row))  # æ ‡å‡†åŒ–å¹¶åŠ å…¥ç»“æœ

        return expanded_rows  # è¿”å›å±•å¼€åçš„æ ·æœ¬åˆ—è¡¨


register_dataset(
    DatasetMeta(
        ms_dataset_id='MTEB/scidocs-reranking',
        hf_dataset_id='mteb/scidocs-reranking',
        split=['validation', 'test'],
        preprocess_func=MTEBRerankPreprocessor(),
        tags=['rerank', 'ğŸ”¥']))

register_dataset(
    DatasetMeta(
        ms_dataset_id='MTEB/stackoverflowdupquestions-reranking',
        hf_dataset_id='mteb/stackoverflowdupquestions-reranking',
        split=['train', 'test'],
        preprocess_func=MTEBRerankPreprocessor(),
        tags=['rerank', 'ğŸ”¥']))


def _repair_conversations_agent_instruct(s: str) -> List[Dict[str, Any]]:
    """
    ä¿®è¡¥ AgentInstruct é£æ ¼çš„ä¼šè¯å­—ç¬¦ä¸²ï¼š
    - ç»Ÿä¸€åœ¨ `}{` ä¹‹é—´æ’å…¥é€—å·ï¼Œä¾¿äºå®‰å…¨è§£æä¸ºåˆ—è¡¨ï¼›
    - ä½¿ç”¨ `ast.literal_eval` å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º Python å¯¹è±¡ã€‚
    """
    s = s.replace('}\n {', '},\n {')  # åœ¨åˆ†éš”å¤„æ’å…¥é€—å·
    if isinstance(s, str):  # è‹¥ä»ä¸ºå­—ç¬¦ä¸²
        s = ast.literal_eval(s)  # å®‰å…¨è§£æ
    return s  # è¿”å›è§£æåçš„å¯¹è±¡


register_dataset(
    DatasetMeta(
        ms_dataset_id='huangjintao/AgentInstruct_copy',
        subsets=['alfworld', 'db', 'kg', 'mind2web', 'os', 'webshop'],
        preprocess_func=MessagesPreprocessor(repair_messages=_repair_conversations_agent_instruct),
        tags=['chat', 'agent', 'multi-round']))


class MultiRoleAgentPreprocessor(RowPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å°†å¤šè§’è‰²å¯¹è¯æ ·æœ¬è§„æ•´ä¸ºæ ‡å‡†ä¸‰æ®µå¼æ¶ˆæ¯ï¼šsystemï¼ˆè§„åˆ™+å†å²ï¼‰ã€userï¼ˆæœ€åä¸€è½®ç”¨æˆ·è¾“å…¥ï¼‰ã€
    assistantï¼ˆæœ€åä¸€è½®å›å¤ï¼‰ã€‚å½“æ— æ³•æŠ½å– user/assistant æ—¶è¿”å› Noneã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å°†å¤šè§’è‰²å¯¹è¯æŠ˜å ä¸º system/user/assistant ä¸‰æ®µç»“æ„ã€‚
        """
        conv = row['conversations']  # åŸå§‹å¤šè½®å¯¹è¯åˆ—è¡¨
        res_prompt = '\n\nã€æ³¨æ„äº‹é¡¹ã€‘\n1. è¿™æ˜¯èŠå¤©å®¤ï¼Œä¸è¦å‘é€ç§ä¿¡ç»™ä»»ä½•äºº\n2. ä»…ä»£è¡¨ä½ ä¸ªäººè¯´è¯,ä¸è¦æ‰®æ¼”å…¶ä»–äººï¼Œåªæ ¹æ®å¯¹è¯å†å²è¿›è¡Œå›å¤\n3. é•¿è¯çŸ­è¯´ï¼Œä¸è¦è¯´å¤ªå¤šè¯ï¼Œä¸è¦è¶…è¿‡50å­— '  # è§„åˆ™æç¤º
        history_prompt = '\n\nã€chat historyã€‘'  # å†å²æ ‡é¢˜
        conv_prompt = '\n {name}:{content}'  # å†å²é¡¹æ¨¡æ¿
        query, response = '', conv[-1]['value']  # åˆå§‹åŒ–å½“å‰ç”¨æˆ·æé—®ä¸åŠ©æ‰‹å›å¤
        system = conv[0]['value'] if conv[0]['from'] == 'system' else ''  # è¯»å–æˆ–ç½®ç©º system
        if conv[0]['from'] == 'user':  # é¦–æ¡å³ä¸ºç”¨æˆ·æé—®
            query = conv[0]['value']  # ç›´æ¥ä½œä¸º query
        elif 'next_speakers:' not in system:  # éç”¨æˆ·å¼€å¤´ä¸” system ä¸­ä¸å«ä¸‹ä¸€è¯´è¯äººæç¤º
            if 'ã€æ³¨æ„äº‹é¡¹ã€‘' not in system and system:  # è‹¥å·²æœ‰ system ä½†æœªåŒ…å«æ³¨æ„äº‹é¡¹
                system += res_prompt  # è¿½åŠ æ³¨æ„äº‹é¡¹
            system += history_prompt  # è¿½åŠ å†å²æ ‡é¢˜
            system += ''.join([conv_prompt.format(name=c['from'], content=c['value']) for c in conv[1:-1]])  # æ‹¼æ¥å†å²æ‘˜è¦

        if not query or not response:  # è‹¥ç¼ºå°‘å¿…è¦å­—æ®µ
            return  # è¿”å› None è·³è¿‡

        return {  # è¿”å›æ ‡å‡†ä¸‰æ®µå¼æ¶ˆæ¯
            'messages': [{
                'role': 'system',
                'content': system
            }, {
                'role': 'user',
                'content': query
            }, {
                'role': 'assistant',
                'content': response
            }],
        }


register_dataset(
    DatasetMeta(
        ms_dataset_id='iic/MSAgent-MultiRole',
        preprocess_func=MultiRoleAgentPreprocessor(),
        tags=['chat', 'agent', 'multi-round', 'role-play', 'multi-agent']))

register_dataset(DatasetMeta(ms_dataset_id='swift/ToolBench', tags=['chat', 'agent', 'multi-round']))  # æ³¨å†Œ ToolBench æ•°æ®å ä½å…ƒä¿¡æ¯

register_dataset(
    DatasetMeta(
        ms_dataset_id='tastelikefeet/competition_math',
        subsets=[
            SubsetDataset(
                name='default',
                subset='default',
                split=['train', 'test'],
            ),
        ],
        tags=['qa', 'math']))

register_dataset(DatasetMeta(ms_dataset_id='modelscope/gsm8k', subsets=['main'], split=['train'], tags=['qa', 'math']))  # æ³¨å†Œ GSM8K ä¸»å­é›†

register_dataset(
    DatasetMeta(ms_dataset_id='modelscope/MathR', subsets=['default', 'clean'], split=['train'], tags=['qa', 'math']))

register_dataset(
    DatasetMeta(ms_dataset_id='modelscope/MathR-32B-Distill', subsets=['data'], split=['train'], tags=['qa', 'math']))


class CoundownTaskPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å€’è®¡æ—¶ç®—æœ¯ä»»åŠ¡æ•°æ®é¢„å¤„ç†å™¨ï¼š
    - åŸºäºç»™å®šæ•°å­—ä¸ç›®æ ‡å€¼æ„é€ æ ‡å‡†åŒ– `query`ï¼›
    - è¦æ±‚æ¨¡å‹åœ¨ <think>/<answer> æ ‡ç­¾ä¸­å±•ç¤ºè¿‡ç¨‹ä¸ç­”æ¡ˆï¼›
    - å°† `target` ç•™å­˜åœ¨æ ·æœ¬ä¸­ä»¥ä¾›ä¸‹æ¸¸è¯„ä¼°ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ„é€ å¸¦æ€ç»´è¿‡ç¨‹ä¸ç­”æ¡ˆæ ‡ç­¾çš„æŸ¥è¯¢ï¼Œå¹¶æ ‡å‡†åŒ–æ ·æœ¬ã€‚
        """
        numbers = row['nums']  # å¯ç”¨æ•°å­—åˆ—è¡¨
        target = row.pop('response', None)  # ç›®æ ‡å€¼ä¿å­˜åœ¨ response å­—æ®µä¸­ï¼Œå–å‡ºåç§»è‡³ target
        query = (f'Using the numbers {numbers}, create an equation that equals {target}.\n'
                 'You can use basic arithmetic operations (+, -, *, /) and each number can only be used once.\n'
                 'Show your work in <think> </think> tags. And return the final equation and answer '
                 'in <answer> </answer> tags, for example <answer> (1 + 2) / 3 * 4 = 4 </answer>.')  # æ„é€ æŸ¥è¯¢æç¤º
        row.update({'target': target, 'query': query})  # å†™å›ç›®æ ‡ä¸æŸ¥è¯¢
        return super().preprocess(row)  # æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='zouxuhong/Countdown-Tasks-3to4',
        subsets=['default'],
        preprocess_func=CoundownTaskPreprocessor(),
        tags=['math']))


class HC3Preprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    HC3 ç”Ÿæˆå¼åˆ†ç±»ï¼š
    - å¯¹æ¯æ¡æ ·æœ¬ç”Ÿæˆä¸¤æ¡è®°å½•ï¼ˆHuman ä¸ ChatGPT å„ä¸€ï¼‰ï¼›
    - query ä¸ºæ¨¡æ¿åŒ–é—®é¢˜ä¸ä¸€ä¸ªå€™é€‰å›ç­”ï¼Œresponse ä¸ºå¯¹åº”ç±»åˆ«åã€‚
    """
    prompt = """Classification Task: Are the following responses from a human or from ChatGPT?
Question: {question}
Answer: {answer}
Category: Human, ChatGPT
Output:"""

    def preprocess(self, row):
        """
        ç”Ÿæˆä¸¤æ¡æ ·æœ¬ç”¨äºåˆ†ç±»è®­ç»ƒã€‚
        """
        rows = []  # ä¿å­˜å±•å¼€åçš„æ ·æœ¬
        for response in ['Human', 'ChatGPT']:  # éå†ä¸¤ä¸ªç±»åˆ«
            query = self.prompt.format(
                question=row['query'], answer=self.random_state.choice(row[f'{response.lower()}_answers']))  # éšæœºæŠ½å–ä¸€ä¸ªè¯¥ç±»ç­”æ¡ˆ
            rows.append(super().preprocess({'query': query, 'response': response}))  # æ ‡æ³¨ç±»åˆ«åä¸ºå“åº”
        return rows  # è¿”å›æ ·æœ¬åˆ—è¡¨


class HC3ClsPreprocessor(HC3Preprocessor):
    """
    ç±»è¯´æ˜
    -----
    HC3 çº¯åˆ†ç±»ï¼šä¸ `HC3Preprocessor` ç›¸ä¼¼ï¼Œä½†å°†ç±»åˆ«ä»¥ `label` æ•°å­—å½¢å¼ç»™å‡ºï¼ˆHuman=0, ChatGPT=1ï¼‰ã€‚
    """

    def preprocess(self, row):
        """
        ç”Ÿæˆä¸¤æ¡æ ·æœ¬å¹¶è¾“å‡ºæ•°å€¼æ ‡ç­¾ã€‚
        """
        rows = []  # ä¿å­˜æ ·æœ¬
        for i, response in enumerate(['Human', 'ChatGPT']):  # Human->0, ChatGPT->1
            query = self.prompt.format(
                question=row['query'], answer=self.random_state.choice(row[f'{response.lower()}_answers']))  # éšæœºå€™é€‰
            rows.append(ResponsePreprocessor.preprocess(self, {'query': query, 'label': i}))  # æ ‡å‡†åŒ–
        return rows  # è¿”å›


hc3_subset_names = ['baike', 'open_qa', 'nlpcc_dbqa', 'finance', 'medicine', 'law', 'psychology']
hc3_subsets: List[SubsetDataset] = []
for hc3_subset_name in hc3_subset_names:
    hc3_subsets.append(
        SubsetDataset(
            name=hc3_subset_name,
            subset=hc3_subset_name,
            preprocess_func=HC3Preprocessor(),
        ))
    hc3_subsets.append(
        SubsetDataset(
            name=f'{hc3_subset_name}_cls',
            subset=hc3_subset_name,
            preprocess_func=HC3ClsPreprocessor(),
        ))

register_dataset(
    DatasetMeta(  # æ³¨å†Œ HC3 ä¸­æ–‡æ•°æ®é›†
        ms_dataset_id='simpleai/HC3-Chinese',  # MS ID
        hf_dataset_id='Hello-SimpleAI/HC3-Chinese',  # HF ID
        subsets=hc3_subsets,  # ä½¿ç”¨ä¸Šæ–‡æ„é€ çš„å­é›†åˆ—è¡¨
        tags=['text-generation', 'classification', 'ğŸ”¥']))  # æ ‡ç­¾ï¼šç”Ÿæˆ/åˆ†ç±»/çƒ­é—¨

hc3_subset_names = ['finance', 'medicine']
hc3_subsets: List[SubsetDataset] = []
for hc3_subset_name in hc3_subset_names:
    hc3_subsets.append(
        SubsetDataset(
            name=hc3_subset_name,
            subset=hc3_subset_name,
            preprocess_func=HC3Preprocessor(),
        ))
    hc3_subsets.append(
        SubsetDataset(
            name=f'{hc3_subset_name}_cls',
            subset=hc3_subset_name,
            preprocess_func=HC3ClsPreprocessor(),
        ))

register_dataset(
    DatasetMeta(  # æ³¨å†Œ HC3 è‹±æ–‡æ•°æ®é›†
        ms_dataset_id='simpleai/HC3',  # MS ID
        hf_dataset_id='Hello-SimpleAI/HC3',  # HF ID
        subsets=hc3_subsets,  # å­é›†æ²¿ç”¨
        preprocess_func=HC3Preprocessor(),  # ç»‘å®šç”Ÿæˆå¼åˆ†ç±»é¢„å¤„ç†å™¨
        tags=['text-generation', 'classification', 'ğŸ”¥']))  # æ ‡ç­¾


class DureaderPreprocessor(RowPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å°† DuReader QGï¼ˆé—®é¢˜ç”Ÿæˆï¼‰æ ·æœ¬è½¬æ¢ä¸ºä¸¤æ®µå¼æ¶ˆæ¯ï¼š
    - user: åŸºäº `context/answer` æ„é€ çš„æé—®æç¤ºï¼›
    - assistant: å¯¹åº”çš„ç›®æ ‡é—®é¢˜ `text2`ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä» `text1` ä¸­å‰¥ç¦»ç­”æ¡ˆä¸ä¸Šä¸‹æ–‡ï¼Œæ„é€ é—®é¢˜ç”Ÿæˆæç¤ºï¼Œå¹¶ä¸ `text2` ç»„æˆé—®ç­”å¯¹ã€‚
        """
        prompt = """Task: Question Generation
Context: {context}
Answer: {answer}
Question:"""  # é—®é¢˜ç”Ÿæˆä»»åŠ¡æç¤ºæ¨¡æ¿
        answer, context = row['text1'].split('[SEP]')  # å°† text1 æŒ‰åˆ†éš”ç¬¦æ‹†æˆç­”æ¡ˆä¸ä¸Šä¸‹æ–‡
        return {
            'messages': [{
                'role': 'user',
                'content': prompt.format(context=context, answer=answer)  # ç”¨æˆ·ç»™å‡ºä¸Šä¸‹æ–‡ä¸ç­”æ¡ˆï¼Œè¯·æ±‚ç”Ÿæˆé—®é¢˜
            }, {
                'role': 'assistant',
                'content': row['text2']  # ç›®æ ‡é—®é¢˜æ–‡æœ¬
            }]
        }


register_dataset(
    DatasetMeta(
        ms_dataset_id='modelscope/DuReader_robust-QG',
        preprocess_func=DureaderPreprocessor(),
        split=['train', 'validation', 'test'],
        tags=['text-generation', 'ğŸ”¥']))


class HHRLHFPreprocessor(RowPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å¤„ç† HH-RLHF æ•°æ®ï¼š
    - å°† `chosen/rejected` ä¸­çš„å¯¹è¯ç‰‡æ®µæŒ‰ `Human/Assistant` æ ‡è®°æ‹†åˆ†ä¸ºè½®æ¬¡ï¼›
    - äº§å‡º `messages` ä¸ `rejected_messages`ï¼Œç”¨äºåå¥½å»ºæ¨¡ï¼ˆDPO/ORPO ç­‰ï¼‰ã€‚
    """

    @staticmethod
    def _to_messages(data):
        """
        å°†äº¤æ›¿çš„ç”¨æˆ·/åŠ©æ‰‹æ–‡æœ¬æ•°ç»„æ‰“åŒ…ä¸ºæ¶ˆæ¯åˆ—è¡¨ã€‚
        """
        messages = []  # æ”¶é›†æ¶ˆæ¯
        for query, response in zip(data[::2], data[1::2]):  # ä»¥æ­¥é•¿ 2 æˆå¯¹éå†
            messages.append({'role': 'user', 'content': query})  # ç”¨æˆ·æ¶ˆæ¯
            messages.append({'role': 'assistant', 'content': response})  # åŠ©æ‰‹æ¶ˆæ¯
        return messages  # è¿”å›æ¶ˆæ¯åºåˆ—

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        æŒ‰åˆ†éš”ç¬¦æ‹†åˆ† chosen/rejectedï¼Œå¯¹é½é¦–é¡¹å¹¶è½¬ä¸ºæ¶ˆæ¯åºåˆ—ã€‚
        """
        chosen = row['chosen'].strip()  # é€‰ä¸­ç­”å¤æ–‡æœ¬
        rejected = row['rejected'].strip()  # è¢«æ‹’ç»ç­”å¤æ–‡æœ¬
        parts_chosen = [s.strip() for s in re.split('\n\nHuman:|\n\nAssistant:|\n\nHum:', chosen)]  # æ‹†åˆ†è½®æ¬¡
        parts_rejected = [s.strip() for s in re.split('\n\nHuman:|\n\nAssistant:|\n\nHum:', rejected)]  # æ‹†åˆ†è½®æ¬¡
        if parts_chosen[0].startswith('Human:'):  # è‹¥é¦–é¡¹ä»å¸¦æœ‰å‰ç¼€
            assert parts_rejected[0].startswith('Human:')  # ä¸¤è€…åº”å¯¹é½
            parts_chosen[0] = parts_chosen[0][6:].strip()  # å»æ‰ 'Human:'
            parts_rejected[0] = parts_rejected[0][6:].strip()  # å»æ‰ 'Human:'
        row['messages'] = self._to_messages(parts_chosen)  # æ„é€ æ­£æ ·æœ¬æ¶ˆæ¯
        row['rejected_messages'] = self._to_messages(parts_rejected)  # æ„é€ è´Ÿæ ·æœ¬æ¶ˆæ¯
        return row  # è¿”å›åŒ…å«ä¸¤å¥—æ¶ˆæ¯çš„è®°å½•


# TODO meta file broken
register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/hh-rlhf',
        subsets=['helpful-base', 'helpful-online', 'helpful-rejection-sampled'],
        preprocess_func=HHRLHFPreprocessor(),
        split=['train', 'test'],
        tags=['rlhf', 'dpo'],
        huge_dataset=True))


class XlamFunctionCallingPreprocessor(RowPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    è§£æå‡½æ•°è°ƒç”¨é£æ ¼æ ·æœ¬ï¼š
    - `query` ä½œä¸ºç”¨æˆ·æ¶ˆæ¯ï¼›
    - å°† `answers` è§£æä¸º JSON åˆ—è¡¨ï¼Œé€æ¡ä»¥ `tool_call` è§’è‰²è¿½åŠ ï¼›
    - æºå¸¦ `tools` æè¿°ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ„é€ ç”¨æˆ·æ¶ˆæ¯å¹¶å°†è§£æåçš„å·¥å…·è°ƒç”¨ä½œä¸º `tool_call` è¿½åŠ ã€‚
        """
        messages = [{'role': 'user', 'content': row['query']}]  # ç”¨æˆ·æ¶ˆæ¯
        response = row['answers']  # å·¥å…·è°ƒç”¨çš„ JSON å­—ç¬¦ä¸²
        response = json.loads(response)  # è§£æä¸ºåˆ—è¡¨
        messages += [{'role': 'tool_call', 'content': json.dumps(content)} for content in response]  # é€æ¡åŠ å…¥æ¶ˆæ¯
        return {'messages': messages, 'tools': row['tools']}  # è¿”å›æ¶ˆæ¯ä¸å·¥å…·åˆ—è¡¨


class XlamFunctionCallingGRPOPreprocessor(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    ä¸º GRPO è®­ç»ƒå‡†å¤‡æ•°æ®ï¼š
    - éšæœºé€‰æ‹©ä¸€ä¸ªå·¥å…·è°ƒç”¨ç­”æ¡ˆï¼Œæ ¼å¼åŒ–ä¸º `Action/Action Input` ç»“æ„ï¼›
    - åŒæ—¶ä¿ç•™ `solution` ä¸ `tools` å­—æ®µã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        éšæœºé‡‡æ ·ä¸€ä¸ªå‡½æ•°è°ƒç”¨ç­”æ¡ˆï¼Œæ ¼å¼åŒ–ä¸ºå“åº”æ–‡æœ¬å¹¶æ ‡å‡†åŒ–ã€‚
        """
        query = row['query']  # ç”¨æˆ·æŸ¥è¯¢
        answers = row['response']  # å€™é€‰å·¥å…·è°ƒç”¨ç­”æ¡ˆï¼ˆJSON å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
        if isinstance(answers, str):  # è‹¥ä¸ºå­—ç¬¦ä¸²
            answers = json.loads(answers)  # è§£æä¸ºåˆ—è¡¨
        answer = np.random.choice(answers)  # éšæœºé€‰å–ä¸€ä¸ªç­”æ¡ˆ
        name = answer['name']  # å·¥å…·å
        args = json.dumps(answer['arguments'])  # å‚æ•°åºåˆ—åŒ–
        response = f'Action: {name}\nAction Input: {args}'  # æ ¼å¼åŒ–å“åº”
        row = {'query': query, 'response': response, 'solution': response, 'tools': row['tools']}  # ç»„è£…è®°å½•
        return super().preprocess(row)  # æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='LLM-Research/xlam-function-calling-60k',
        hf_dataset_id='Salesforce/xlam-function-calling-60k',
        subsets=[
            SubsetDataset('default', 'dataset', preprocess_func=XlamFunctionCallingPreprocessor()),
            SubsetDataset('grpo', 'dataset', preprocess_func=XlamFunctionCallingGRPOPreprocessor())
        ],
        tags=['agent', 'grpo', 'ğŸ”¥']))


class HHRLHFCNPreprocessor(MessagesPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å¤„ç†ä¸­æ–‡ HH-RLHF å˜ä½“ï¼š
    - å°† `chosen` è¿½åŠ åˆ° `messages` æœ«å°¾ï¼›
    - å°† `rejected.text` ä½œä¸º `rejected_response`ï¼›
    - äº¤ç”±çˆ¶ç±»è¿›è¡Œå­—æ®µæ˜ å°„ä¸æ ‡å‡†åŒ–ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒæ•´å­—æ®µåè°ƒç”¨çˆ¶ç±»é¢„å¤„ç†ã€‚
        """
        row['messages'].append(row.pop('chosen'))  # å°† chosen é™„åŠ åˆ°æ¶ˆæ¯æœ«å°¾
        row['rejected_response'] = row['rejected']['text']  # æå–è¢«æ‹’ç»æ–‡æœ¬
        return super().preprocess(row)  # æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/hh_rlhf_cn',
        subsets=['hh_rlhf', 'harmless_base_cn', 'harmless_base_en', 'helpful_base_cn', 'helpful_base_en'],
        preprocess_func=HHRLHFCNPreprocessor(columns={'context': 'messages'}, content_key='text'),
        split=['train', 'test'],
        tags=['rlhf', 'dpo', 'ğŸ”¥']))


def repair_conversations(s: Union[str, Any]) -> Any:
    """
    é€šç”¨å¯¹è¯ä¿®è¡¥ï¼šå°†è¡Œé—´ç¼ºé€—å·çš„ JSON ç‰‡æ®µè§„èŒƒåŒ–åè§£æä¸º Python å¯¹è±¡ã€‚

    å‚æ•°
    ----
    - s: åŸå§‹å­—ç¬¦ä¸²æˆ–å·²è§£æå¯¹è±¡ã€‚

    è¿”å›
    ----
    - Any: è§£æåçš„å¯¹è±¡æˆ–åŸå¯¹è±¡ã€‚
    """
    if isinstance(s, str):  # ä»…å¤„ç†å­—ç¬¦ä¸²è¾“å…¥
        s = s.replace('}\n {', '},{')  # å„ç±»ç¼ºé€—å·åœºæ™¯ä¿®è¡¥
        s = s.replace('}\n{', '},{')
        s = s.replace('}{', '},{')
        s = s.replace('}\n  {', '},{')
        return ast.literal_eval(s)  # å®‰å…¨è§£æä¸º Python å¯¹è±¡
    return s  # éå­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/lmsys-chat-1m',
        hf_dataset_id='lmsys/lmsys-chat-1m',
        preprocess_func=MessagesPreprocessor(repair_messages=repair_conversations),
        tags=['chat', 'em']))


class EmojiPreprocessr(ResponsePreprocessor):
    """
    ç±»è¯´æ˜
    -----
    æ¸…æ´—æ ·æœ¬ä¸­å¸¸è§çš„ä¸å¯è§ emoji å˜ä½“é€‰æ‹©å™¨å­—ç¬¦ï¼ˆå¦‚ 'ï¸'ï¼‰ï¼Œä»¥é™ä½è®­ç»ƒæ—¶çš„å™ªå£°ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        å»é™¤ query/response/rejected_response ä¸­çš„ä¸å¯è§å­—ç¬¦åæ ‡å‡†åŒ–ã€‚
        """
        # Remove dirty characters  # æ¸…é™¤ä¸å¯è§å­—ç¬¦
        row['query'] = row['query'].replace('ï¸', '')  # æ¸…ç† query
        row['response'] = row['response'].replace('ï¸', '')  # æ¸…ç† response
        row['rejected_response'] = row['rejected_response'].replace('ï¸', '')  # æ¸…ç† rejected_response
        return super().preprocess(row)  # æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='hjh0119/shareAI-Llama3-DPO-zh-en-emoji',
        hf_dataset_id='shareAI/DPO-zh-en-emoji',
        preprocess_func=EmojiPreprocessr(columns={
            'answer_zh': 'response',
            'answer_en': 'rejected_response'
        }),
        tags=['rlhf', 'dpo']))

register_dataset(
    DatasetMeta(ms_dataset_id='AI-ModelScope/ultrafeedback-binarized-preferences-cleaned-kto', tags=['rlhf', 'kto']))

register_dataset(
    DatasetMeta(
        ms_dataset_id='OmniData/Zhihu-KOL-More-Than-100-Upvotes',
        hf_dataset_id='bzb2023/Zhihu-KOL-More-Than-100-Upvotes',
        tags=['zhihu', 'qa']))

register_dataset(
    DatasetMeta(
        ms_dataset_id='OmniData/Zhihu-KOL',
        hf_dataset_id='wangrui6/Zhihu-KOL',
        huge_dataset=True,
        tags=['zhihu', 'qa'],
    ))


class GuanacoPreprocessor(RowPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    è§£æ Guanaco æ•°æ®é›†ï¼š
    - ä» `instruction` ä¸­æŒ‰å¤šç§é”®ååˆ†å‰²å‡ºå†å²è½®æ¬¡ï¼ˆUser/Assistant æ··æ‚å¤§å°å†™/ä¸­è‹±æ–‡å˜ä½“ï¼‰ï¼›
    - æ¸…æ´— `input` çš„ `User:` å‰ç¼€ï¼›
    - æ„é€ å¤šè½® `messages` å¹¶åœ¨æœ«å°¾è¿½åŠ å½“å‰ `input/output`ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å°† instruction/input/output è½¬ä¸ºå¤šè½® messagesã€‚
        """
        instruction = row['instruction']  # æŒ‡ä»¤æ–‡æœ¬ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«å†å²å¤šè½®å¯¹è¯
        input = row['input']  # å½“å‰ç”¨æˆ·è¾“å…¥
        output = row['output']  # å½“å‰åŠ©æ‰‹å›å¤
        history = []  # æš‚å­˜å†å²è½®æ¬¡ [user, assistant]
        if instruction:  # å­˜åœ¨å†å²åˆ™è§£æ
            parts = split_str_parts_by(
                instruction, ['User:', 'Userï¼š', 'Assistantï¼š', 'Assistant:', 'Asssistent:', 'Assistent:', 'Assistenz:'])  # æŒ‰å¤šè¯­è¨€é”®åˆ‡åˆ†
            for idx, part in enumerate(parts):  # æšä¸¾åˆ†æ®µ
                if idx % 2 == 0:  # å¶æ•°æ®µåº”ä¸º user
                    if 'user' not in part['key'].lower():  # é˜²å¾¡æ€§æ£€æŸ¥
                        return  # ç»“æ„å¼‚å¸¸ï¼Œè·³è¿‡
                    history.append([part['content'], None])  # æš‚å­˜ user å†…å®¹
                else:  # å¥‡æ•°æ®µåº”ä¸º assistant
                    if 'assist' not in part['key'].lower() and 'asssist' not in part['key'].lower():  # å„ç§æ‹¼å†™
                        return  # ç»“æ„å¼‚å¸¸ï¼Œè·³è¿‡
                    history[-1][-1] = part['content']  # å¡«å…… assistant å†…å®¹
        if input.startswith('User:'):  # æ¸…ç†å½“å‰è¾“å…¥å‰ç¼€
            input = input[len('User:'):].strip()  # å»é™¤ 'User:'
        if any([not h[0] or not h[1] for h in history]):  # å†å²ä¸­è‹¥å­˜åœ¨ç©ºè½®æ¬¡
            return  # è·³è¿‡è¯¥æ ·æœ¬

        messages = []  # æ„é€ æ ‡å‡†æ¶ˆæ¯åºåˆ—
        for h in history:  # é€è½®æ·»åŠ å†å²
            messages.append({'role': 'user', 'content': h[0]})  # ç”¨æˆ·å‘è¨€
            messages.append({'role': 'assistant', 'content': h[1]})  # åŠ©æ‰‹å›å¤
        messages.append({'role': 'user', 'content': input})  # å½“å‰ç”¨æˆ·è¾“å…¥
        messages.append({'role': 'assistant', 'content': output})  # å½“å‰åŠ©æ‰‹å›å¤
        return {
            'messages': messages,  # è¿”å›ç»Ÿä¸€æ ¼å¼
        }


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/GuanacoDataset',
        hf_dataset_id='JosephusCheung/GuanacoDataset',
        preprocess_func=GuanacoPreprocessor(),
        tags=['chat', 'zh']))


class FunctionCallChatmlPreprocessor(MessagesPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    å¤„ç† Function-Calling ChatML æ•°æ®ï¼š
    - è‹¥å­˜åœ¨ `function_description`ï¼Œæ‹†åˆ†ä¸º `tools`ï¼›
    - è‹¥æ¶ˆæ¯é¦–æ¡ä¸º systemï¼Œåˆ™ç§»é™¤ï¼›
    - å…¶ä½™äº¤ç”±çˆ¶ç±»å¤„ç†åˆ—æ˜ å°„ä¸æ ‡å‡†åŒ–ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        åœ¨çˆ¶ç±»æ ‡å‡†åŒ–åŸºç¡€ä¸Šï¼Œè¡¥é½ tools å¹¶ç§»é™¤é¦–æ¡ systemã€‚
        """
        res = super().preprocess(row)  # æ ‡å‡†åŒ–å­—æ®µ

        if res['function_description']:  # è‹¥å­˜åœ¨å‡½æ•°æè¿°
            res['tools'] = res['function_description'].split('\n\n')  # æ‹†åˆ†ä¸ºå·¥å…·åˆ—è¡¨
        messages = res['messages']  # å–å‡ºæ¶ˆæ¯
        if messages[0]['role'] == 'system':  # è‹¥é¦–æ¡ä¸º system
            messages.pop(0)  # ç§»é™¤ä¹‹
        return res  # è¿”å›å¤„ç†ç»“æœ


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/function-calling-chatml',
        hf_dataset_id='Locutusque/function-calling-chatml',
        preprocess_func=FunctionCallChatmlPreprocessor(),
        tags=['agent', 'en', 'sft', 'ğŸ”¥']))


class Dolly15kPreprocessor(RowPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    é€‚é… Databricks Dolly 15k æ•°æ®ï¼š
    - å°† `context`ï¼ˆå¯é€‰ï¼‰ä¸ `instruction` æ‹¼æ¥ä¸ºç”¨æˆ·ä¾§ `query`ï¼›
    - å°† `response` ç”¨ä½œåŠ©æ‰‹å›å¤ï¼›
    - è¾“å‡ºæ ‡å‡†åŒ–çš„ä¸¤æ®µå¼æ¶ˆæ¯ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        æ„é€  query å¹¶è¿”å›æ ‡å‡†æ¶ˆæ¯ç»“æ„ã€‚

        å‚æ•°
        ----
        - row: è¾“å…¥è®°å½•ï¼ŒåŒ…å« `instruction/context/response`ã€‚

        è¿”å›
        ----
        - Optional[Dict[str, Any]]: æ ‡å‡†åŒ–æ ·æœ¬ã€‚
        """
        instruction = row['instruction']  # æŒ‡ä»¤æ–‡æœ¬
        context = row['context']  # ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        response = row['response']  # å‚è€ƒç­”æ¡ˆ/å›å¤
        query = ''  # åˆå§‹åŒ– query
        if context:  # è‹¥å­˜åœ¨ä¸Šä¸‹æ–‡
            query = 'Here gives some useful information:\n'  # å‰ç¼€è¯´æ˜
            query += context  # è¿½åŠ ä¸Šä¸‹æ–‡
            query += '\n'  # æ¢è¡Œåˆ†éš”
        query += instruction  # æœ€åè¿½åŠ æŒ‡ä»¤
        return {
            'messages': [{
                'role': 'user',
                'content': query  # ç”¨æˆ·ä¾§åˆæˆçš„æŸ¥è¯¢
            }, {
                'role': 'assistant',
                'content': response  # åŠ©æ‰‹ä¾§ç›®æ ‡å›å¤
            }],
        }


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/databricks-dolly-15k',
        hf_dataset_id='databricks/databricks-dolly-15k',
        preprocess_func=Dolly15kPreprocessor(),
        tags=['multi-task', 'en', 'quality']))


class OrpoDPOMix40kPreprocessor(MessagesPreprocessor):
    """
    ç±»è¯´æ˜
    -----
    é’ˆå¯¹ ORPO/DPO æ··åˆæ•°æ®ï¼šè¿‡æ»¤æ¥æºä¸º `toxic-dpo-v0.2` çš„æ ·æœ¬ï¼Œå…¶ä½™æŒ‰çˆ¶ç±»é€»è¾‘æ ‡å‡†åŒ–ã€‚
    """

    def preprocess(self, row: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è¿‡æ»¤éƒ¨åˆ†æ¥æºå¹¶å§”æ‰˜çˆ¶ç±»å¤„ç†ã€‚
        """
        if row['source'] == 'toxic-dpo-v0.2':  # å‘½ä¸­éœ€è¿‡æ»¤çš„æ•°æ®æ¥æº
            return  # ä¸¢å¼ƒè¯¥æ ·æœ¬
        return super().preprocess(row)  # å…¶ä»–æ ·æœ¬æ ‡å‡†åŒ–


register_dataset(
    DatasetMeta(
        ms_dataset_id='AI-ModelScope/orpo-dpo-mix-40k',
        hf_dataset_id='mlabonne/orpo-dpo-mix-40k',
        preprocess_func=OrpoDPOMix40kPreprocessor(columns={
            'chosen': 'messages',
            'rejected': 'rejected_messages'
        }),
        tags=['dpo', 'orpo', 'en', 'quality']))

register_dataset(
    DatasetMeta(
        ms_dataset_id='swift/sharegpt',
        subsets=['common-zh', 'unknow-zh', 'common-en'],
        tags=['chat', 'general', 'multi-round']))


class SelfCognitionPreprocessor(ResponsePreprocessor):

    def __init__(self, *args, query_suffix: str = '', response_prefix: str = '', **kwargs):
        self.query_suffix = query_suffix
        self.response_prefix = response_prefix
        self.name: Optional[Tuple[str, str]] = None
        self.author: Optional[Tuple[str, str]] = None
        super().__init__(*args, **kwargs)

    def set_name_author(self, name, author):
        self.name = name
        self.author = author

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        for key in ['name', 'author']:
            val = getattr(self, key)
            if val is None:
                continue
            val = val[0] if row['tag'] == 'zh' else val[1]
            if val is None:
                continue
            placeholder = '{{' + key.upper() + '}}'
            row['query'] = row['query'].replace(placeholder, val)
            row['response'] = row['response'].replace(placeholder, val)

        row['query'] = row['query'] + self.query_suffix
        row['response'] = self.response_prefix + row['response']
        return super().preprocess(row)


register_dataset(
    DatasetMeta(
        ms_dataset_id='swift/self-cognition',
        hf_dataset_id='modelscope/self-cognition',
        subsets=[
            SubsetDataset(preprocess_func=SelfCognitionPreprocessor()),
            SubsetDataset(
                'qwen3',
                preprocess_func=SelfCognitionPreprocessor(
                    query_suffix=' /no_think', response_prefix='<think>\n\n</think>\n\n')),
            SubsetDataset(
                'empty_think', preprocess_func=SelfCognitionPreprocessor(response_prefix='<think>\n\n</think>\n\n')),
        ],
        dataset_name='self-cognition',
        tags=['chat', 'self-cognition', 'ğŸ”¥']))
