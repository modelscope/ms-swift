# è‡ªå®šä¹‰ä¸æ‹“å±•
## ç›®å½•
- [è‡ªå®šä¹‰æ•°æ®é›†](#è‡ªå®šä¹‰æ•°æ®é›†)
- [è‡ªå®šä¹‰æ¨¡å‹](#è‡ªå®šä¹‰æ¨¡å‹)
- [è‡ªå®šä¹‰å¯¹è¯æ¨¡æ¿](#è‡ªå®šä¹‰å¯¹è¯æ¨¡æ¿)

## è‡ªå®šä¹‰æ•°æ®é›†
æˆ‘ä»¬æ”¯æŒä¸‰ç§**è‡ªå®šä¹‰æ•°æ®é›†**çš„æ–¹æ³•.

1. ã€æ¨èã€‘**å‘½ä»¤è¡Œå‚æ•°**çš„å½¢å¼: **æ›´åŠ æ–¹ä¾¿æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†**, æ”¯æŒå››ç§æ•°æ®é›†æ ¼å¼ï¼ˆå³ä½¿ç”¨`SmartPreprocessor`ï¼‰, æ”¯æŒ`dataset_id`å’Œ`dataset_path`.
2. æ·»åŠ æ•°æ®é›†åˆ°`dataset_info.json`ä¸­, æ¯”ç¬¬ä¸€ç§æ–¹å¼æ›´çµæ´», æ”¯æŒå¯¹æ•°æ®é›†ä½¿ç”¨ä¸¤ç§é¢„å¤„ç†å™¨å¹¶æŒ‡å®šå…¶å‚æ•°: `RenameColumnsPreprocessor`, `ConversationsPreprocessor`ï¼ˆé»˜è®¤ä½¿ç”¨`SmartPreprocessor`ï¼‰. æ”¯æŒç›´æ¥ä¿®æ”¹swiftå†…ç½®çš„`dataset_info.json`, æˆ–è€…é€šè¿‡`--dataset_info_path xxx.json`çš„æ–¹å¼ä¼ å…¥å¤–ç½®çš„jsonæ–‡ä»¶ï¼ˆæ–¹ä¾¿pip installè€Œégit cloneçš„ç”¨æˆ·æ‹“å±•æ•°æ®é›†ï¼‰.
3. **æ³¨å†Œæ•°æ®é›†**çš„æ–¹å¼: æ¯”ç¬¬1ã€2ç§æ–¹å¼æ›´åŠ çµæ´», æ”¯æŒä½¿ç”¨å‡½æ•°å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†. æ–¹æ³•1ã€2åœ¨å®ç°ä¸Šå€ŸåŠ©äº†æ–¹æ³•3. å¯ä»¥ç›´æ¥ä¿®æ”¹æºç è¿›è¡Œæ‹“å±•, æˆ–è€…é€šè¿‡`--custom_register_path xxx.py`çš„æ–¹å¼ä¼ å…¥, è„šæœ¬ä¼šå¯¹pyæ–‡ä»¶è¿›è¡Œè§£æï¼ˆæ–¹ä¾¿pip installçš„ç”¨æˆ·ï¼‰.

### ğŸ“Œ ã€æ¨èã€‘å‘½ä»¤è¡Œå‚æ•°çš„å½¢å¼
æ”¯æŒç›´æ¥ä¼ å…¥è¡Œè‡ªå®šä¹‰çš„**dataset_id**(å…¼å®¹MSå’ŒHF)å’Œ**dataset_path**, ä»¥åŠåŒæ—¶ä¼ å…¥å¤šä¸ªè‡ªå®šä¹‰æ•°æ®é›†ä»¥åŠå¯¹åº”é‡‡æ ·æ•°, è„šæœ¬ä¼šè¿›è¡Œè‡ªåŠ¨çš„é¢„å¤„ç†å’Œæ‹¼æ¥. å¦‚æœä¼ å…¥çš„æ˜¯`dataset_id`, é»˜è®¤ä¼šä½¿ç”¨dataset\_idä¸­çš„'default'å­æ•°æ®é›†, å¹¶è®¾ç½®splitä¸º'train'. å¦‚æœè¯¥dataset\_idå·²ç»æ³¨å†Œ, åˆ™ä¼šä½¿ç”¨æ³¨å†Œæ—¶ä¼ å…¥çš„subsetsã€splitä»¥åŠé¢„å¤„ç†å‡½æ•°. å¦‚æœä¼ å…¥çš„æ˜¯`dataset_path`, åˆ™å¯ä»¥æŒ‡å®šä¸ºç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„, å…¶ä¸­ç›¸å¯¹è·¯å¾„ä¸ºç›¸å¯¹äºå½“å‰è¿è¡Œç›®å½•.

```bash
--dataset {dataset_id} {dataset_path}

# æ•°æ®é›†æ··åˆ: ä»¥ä¸‹å–dataset_idä¸­subset1å’Œsubset2å­æ•°æ®é›†å¹¶é‡‡æ ·20000æ¡
--dataset {dataset_name}#20000 {dataset_id}:{subset1}/{subset2}#20000 {dataset_path}#10000
```

è„šæœ¬æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åŒ…å«`csv`, `json`, `jsonl`æ ¼å¼. ä½ éœ€è¦å°†ä¼ å…¥çš„æ–‡ä»¶ç¬¦åˆä»¥ä¸‹æ•°æ®é›†æ ¼å¼ï¼ˆåªåˆ—å‡ºäº†ä¸€éƒ¨åˆ†ï¼‰. ä»¥ä¸‹æ ¼å¼éƒ½æ”¯æŒsystem (éœ€è¦æ³¨æ„çš„æ˜¯, csvå¦‚æœæŒ‡å®šäº†systemå­—æ®µ, åˆ™æ— æ³•è®¾ç½®ä¸º`None`, åªèƒ½æŒ‡å®šä¸ºç©ºå­—ç¬¦ä¸². jsonå’Œjsonlæ²¡æœ‰è¿™ä¸ªé™åˆ¶). `json`, `jsonl`æ ¼å¼çš„æ–‡ä»¶æ”¯æŒå¤šè½®å¯¹è¯ (`csv`ä¸æ”¯æŒ).

**æ ¼å¼1:**

é¢„è®­ç»ƒ:

```csv
response
11111
aaaaa
AAAAA
```

```jsonl
{"response": "11111"}
{"response": "aaaaa"}
{"response": "AAAAA"}
```

å•è½®å¯¹è¯:

```csv
system,query,response
00000,11111,22222
00001,aaaaa,bbbbb
00002,AAAAA,BBBBB
```

```jsonl
{"system": "00000", "query": "11111", "response": "22222"}
{"query": "aaaaa", "response": "bbbbb"}
{"query": "AAAAA", "response": "BBBBB"}
```

å¤šè½®å¯¹è¯:

```jsonl
{"system": "00000", "query": "55555", "response": "66666"}
{"query": "eeeee", "response": "fffff", "history": []}
{"query": "EEEEE", "response": "FFFFF", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]]}
```

```json
[{"system": "00000", "query": "55555", "response": "66666"},
{"query": "eeeee", "response": "fffff", "history": []},
{"query": "EEEEE", "response": "FFFFF", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]]}]
```

**æ ¼å¼2:**

```jsonl
{"conversations": [{"from": "system", "value": "00000"}, {"from": "user", "value": "11111"}, {"from": "assistant", "value": "22222"}]}
{"conversations": [{"from": "user", "value": "aaaaa"}, {"from": "assistant", "value": "bbbbb"}, {"from": "user", "value": "ccccc"}, {"from": "assistant", "value": "ddddd"}]}
{"conversations": [{"from": "user", "value": "AAAAA"}, {"from": "assistant", "value": "BBBBB"}, {"from": "user", "value": "CCCCC"}, {"from": "assistant", "value": "DDDDD"}]}
```

**æ ¼å¼3:**

```jsonl
{"messages": [{"role": "system", "content": "00000"}, {"role": "user", "content": "11111"}, {"role": "assistant", "content": "22222"}]}
{"messages": [{"role": "user", "content": "aaaaa"}, {"role": "assistant", "content": "bbbbb"}, {"role": "user", "content": "ccccc"}, {"role": "assistant", "content": "ddddd"}]}
{"messages": [{"role": "user", "content": "AAAAA"}, {"role": "assistant", "content": "BBBBB"}, {"role": "user", "content": "CCCCC"}, {"role": "assistant", "content": "DDDDD"}]}
```

**æ ¼å¼4:**

```csv
system,instruction,input,output
00000,11111,22222,33333
00001,aaaaa,bbbbb,ccccc
00002,AAAAA,BBBBB,CCCCC
```

**å¼ºåŒ–å­¦ä¹ ï¼ˆDPO/ORPOï¼‰**

```jsonl
{"query": "11111", "response": "22222", "rejected_response": "33333", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]]}
{"query": "aaaaa", "response": "bbbbb", "rejected_response": "ccccc", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]]}
{"query": "AAAAA", "response": "BBBBB", "rejected_response": "CCCCC", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]]}
```

### æ·»åŠ dataset_info.json
å¯ä»¥å‚è€ƒ[swiftå†…ç½®çš„dataset_info.json](https://github.com/modelscope/swift/blob/main/swift/llm/data/dataset_info.json)è¿›è¡Œæ•°æ®é›†æ‹“å±•. ä½ å¯ä»¥ç›´æ¥åœ¨å†…ç½®çš„dataset_info.jsonä¸­æ·»åŠ , ä¹Ÿå¯ä»¥é€šè¿‡`--custom_dataset_info 1.json`ä¼ å…¥å¤–ç½®çš„dataset_info.jsonçš„è·¯å¾„ã€jsonå­—ç¬¦ä¸²æˆ–è€…å­—å…¸.

æ·»åŠ dataset\_id:
```python
# MS
# ä½¿ç”¨: `--dataset <dataset_name>`
"<dataset_name>": {
    "dataset_id": "xxx/xxx"
}

# HF
# ä½¿ç”¨: `--dataset HF::<dataset_name>` æˆ–è€… ç›´æ¥ä½¿ç”¨`USE_HF`ç¯å¢ƒå˜é‡.
"<dataset_name>": {
    "hf_dataset_id": "xxx/xxx"
}
```

æ·»åŠ dataset\_path:
```python
# å¯ä»¥æŒ‡å®šç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„. ç›¸å¯¹è·¯å¾„ç›¸å¯¹äºdataset_info.jsonæ–‡ä»¶æ‰€åœ¨ç›®å½•.
# ä½¿ç”¨: `--dataset <dataset_name>`
"<dataset_name>": {
    "dataset_path": "xxx"
}
```

æ”¯æŒä»¥ä¸‹å‚æ•°:
- dataset\_id: æ•°æ®é›†å¯¹åº”çš„ModelScopeçš„dataset\_id, é»˜è®¤ä¸º`None`. æœ€ç®€çš„è®¾ç½®å¿…é¡»æŒ‡å®š`dataset_id`ã€`hf_dataset_id`å’Œ`dataset_path`ä¸­çš„ä¸€ä¸ª.
- subsets: å­æ•°æ®é›†çš„åå­—åˆ—è¡¨, é»˜è®¤ä¸º`[]`, å³ä½¿ç”¨'default'å­æ•°æ®é›†.
- split: é»˜è®¤ä¸º`['train']`, é€šå¸¸ä¸éœ€è¦ä¿®æ”¹.
- hf\_dataset\_id: æ•°æ®é›†å¯¹åº”çš„HuggingFaceçš„datasset\_id, é»˜è®¤ä¸º`None`.
- dataset\_path: ç”¨äºæŒ‡å®šæ•°æ®é›†çš„æœ¬åœ°è·¯å¾„, e.g. 1.jsonlç­‰, é»˜è®¤ä¸º`None`. å¯ä»¥ä¼ å…¥ç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„. å¦‚æœä½¿ç”¨ç›¸å¯¹è·¯å¾„, åˆ™ç›¸å¯¹äº`dataset_info.json`æ–‡ä»¶æ‰€åœ¨ç›®å½•. å¦‚æœè®¾ç½®äº†dataset\_path, é‚£ä¹ˆdataset\_id, subsets, hf\_dataset\_idå‚æ•°å¤±æ•ˆ.
- columns: é»˜è®¤ä½¿ç”¨çš„é¢„å¤„ç†å™¨ä¸º`SmartPreprocessor`, æŒ‡å®šæ­¤å‚æ•°åˆ™æŒ‡å®šä¸º`RenameColumnsPreprocessor`, ä½ éœ€è¦renameæ•°æ®é›†ä¸­çš„åˆ—å¹¶è½¬æ¢ä¸ºä¸Šè¿°**æ ¼å¼1**çš„æ ·å¼.
- conversations: æŒ‡å®šæ­¤å‚æ•°åˆ™æŒ‡å®šé¢„å¤„ç†å™¨ä¸º`ConversationsPreprocessor`  ('columns'çš„ä¼˜å…ˆçº§é«˜äº'conversations').
- remove\_useless\_columns: æŒ‡å®šæ˜¯å¦ç§»é™¤æ— ç”¨çš„åˆ— (åŒ…æ‹¬: 'query', 'response', 'rejected\_response', 'system', 'history', 'images'), é»˜è®¤ä¸º`True`, é€šå¸¸ä¸éœ€è¦è®¾ç½®.
- tags: ç”¨äºæ³¨é‡Šæ•°æ®é›†, é»˜è®¤ä¸º`[]`, é€šå¸¸ä¸éœ€è¦è®¾ç½®.

å¦‚æœ`dataset_info.json`ä¸­å‚æ•°æ— æ³•æ»¡è¶³æ‚¨çš„è¦æ±‚, ä¾‹å¦‚ä½ éœ€è¦æ·»åŠ è‡ªå®šä¹‰çš„promptã€éœ€è¦å¯¹æ•°æ®é›†æå‰è¿›è¡Œæ¸…æ´—æˆ–è€…è¿›è¡Œå¤æ‚çš„æ•°æ®é›†è·å–ä¸é¢„å¤„ç†, åˆ™å¯ä»¥ä½¿ç”¨æ³¨å†Œæ•°æ®é›†çš„æ–¹å¼, ä½¿ç”¨å‡½æ•°çš„æ–¹å¼æ¥è¿›è¡Œæ•°æ®è·å–ä¸é¢„å¤„ç†.


### æ³¨å†Œæ•°æ®é›†çš„æ–¹å¼

ä»¥ä¸‹æ˜¯ä¸€ä¸ª**æ³¨å†Œæ•°æ®é›†**çš„æ¡ˆä¾‹. å®Œæ•´çš„pyæ–‡ä»¶å¯ä»¥æŸ¥çœ‹[custom.py](https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/custom.py), shè„šæœ¬å¯ä»¥æŸ¥çœ‹[custom](https://github.com/modelscope/swift/tree/main/examples/pytorch/llm/scripts/custom). ä½ å¯ä»¥é€šè¿‡æŒ‡å®š`--custom_register_path xxx.py`å¯¹æ³¨å†Œçš„å†…å®¹è¿›è¡Œè§£æ.

```python
from typing import Optional, Tuple

from datasets import Dataset as HfDataset
from modelscope import MsDataset

from swift.llm import get_dataset, register_dataset, get_dataset_from_repo
from swift.utils import get_logger

logger = get_logger()


class CustomDatasetName:
    stsb_en = 'stsb-en'

def _preprocess_stsb(dataset: HfDataset) -> HfDataset:
    prompt = """Task: Based on the given two sentences, provide a similarity score between 0.0 and 5.0.
Sentence 1: {text1}
Sentence 2: {text2}
Similarity score: """
    query = []
    response = []
    for d in dataset:
        query.append(prompt.format(text1=d['text1'], text2=d['text2']))
        response.append(f"{d['label']:.1f}")
    return HfDataset.from_dict({'query': query, 'response': response})


register_dataset(CustomDatasetName.stsb_en, 'huangjintao/stsb', None, _preprocess_stsb, get_dataset_from_repo)


if __name__ == '__main__':
    # test dataset
    train_dataset, val_dataset = get_dataset([CustomDatasetName.stsb_en],
                                             check_dataset_strategy='warning')
    print(f'train_dataset: {train_dataset}')
    print(f'val_dataset: {val_dataset}')

```

`register_dataset`ä¼šåœ¨`DATASET_MAPPING`ä¸­æ³¨å†Œæ•°æ®é›†, è¯¥å‡½æ•°çš„å‚æ•°å«ä¹‰å¦‚ä¸‹:

- `dataset_name`: å¿…å¡«é¡¹, è¡¨ç¤ºæ•°æ®é›†çš„åå­—, ä¹Ÿæ˜¯æ•°æ®é›†çš„å”¯ä¸€id.
- `dataset_id_or_path`: å¿…å¡«é¡¹. è¡¨ç¤ºæ•°æ®é›†åœ¨ModelScope Hubä¸Šçš„`dataset_id`æˆ–è€…æœ¬åœ°çš„`dataset_dir`.
- `subsets`: æ•°æ®é›†çš„å­æ•°æ®é›†åˆ—è¡¨, é»˜è®¤ä¸º`[]`.
- `preprocess_func`: é¢„å¤„ç†å‡½æ•°.
- `get_function`: é»˜è®¤å€¼ä¸º`None`. è·å–æ•°æ®é›†çš„å‡½æ•°. å¦‚æœä¼ å…¥None, åˆ™ä½¿ç”¨ä¿®é¥°å™¨æ–¹æ¡ˆè¿›è¡Œæ•°æ®é›†æ³¨å†Œ. å¦‚æœä¼ å…¥ä¸€ä¸ªå‡½æ•°, åˆ™ä½¿ç”¨æ­£å¸¸æ–¹æ¡ˆè¿›è¡Œæ³¨å†Œ.
  > `get_function`éœ€è¦è¿”å›`HfDataset`æˆ–`Tuple[HfDataset, Optional[HfDataset]]`. å¦‚æœåªè¿”å›ä¸€ä¸ªæ•°æ®é›†, åˆ™è¯¥æ•°æ®é›†ä¸ºtrain\_dataset. å¦‚æœè¿”å›ä¸¤ä¸ªæ•°æ®é›†, åˆ™åˆ†åˆ«ä½œä¸ºtrain\_datasetå’Œval\_dataset. `get_dataset`å‡½æ•°æ”¯æŒè·å–å¤šä¸ªæ•°æ®é›†, ä¾‹å¦‚:`get_dataset(['dataset1', 'dataset2'])`. æˆ‘ä»¬ä¼šå°†å„ä¸ªå­æ•°æ®é›†çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†éƒ¨åˆ†åˆ†åˆ«è¿›è¡Œæ‹¼æ¥, æœ€ç»ˆè¿”å›åˆå¹¶åçš„è®­ç»ƒé›†å’ŒéªŒè¯é›†.

  > å‡½æ•°è¿”å›çš„`HfDataset`éœ€è¦ç¬¦åˆä¸€å®šçš„è§„èŒƒ. å¦‚æœä½ è¦è¿›è¡Œ**é¢„è®­ç»ƒ**, é‚£ä¹ˆåªéœ€è¦åŒ…å«`response`å­—æ®µ, å…·ä½“å¯ä»¥å‚è€ƒ`'tigerbot-law-zh'`æ•°æ®é›†. å¦‚æœæ˜¯**æŒ‡ä»¤å¾®è°ƒ(å•è½®å¯¹è¯)**çš„æƒ…å†µä¸‹, éœ€åŒ…å«`query`, `response`å­—æ®µ, åˆ†åˆ«ä»£è¡¨æŒ‡ä»¤å¾®è°ƒçš„ç”¨æˆ·è¯¢é—®å’ŒAIåŠ©æ‰‹çš„å›ç­”, å…·ä½“å¯ä»¥å‚è€ƒ`'alpaca-zh'`æ•°æ®é›†. å¦‚æœæ˜¯**å¤šè½®å¯¹è¯**, åˆ™éœ€è¦é¢å¤–åŠ ä¸Š`history`å­—æ®µ, ä»£è¡¨å¯¹è¯çš„å†å²ä¿¡æ¯, å…·ä½“å¯ä»¥å‚è€ƒ`'damo-agent-mini-zh'`æ•°æ®é›†. å¦‚æœæ¯ä¸ªæ•°æ®é›†æ ·ä¾‹å…·æœ‰ä¸åŒçš„`system`, åˆ™éœ€è¦é¢å¤–åŠ ä¸Šsystemå­—æ®µ, å…·ä½“ä½ ä¹Ÿå¯ä»¥å‚è€ƒ`'damo-agent-mini-zh'`æ•°æ®é›†.

- `**kwargs`: å…¶ä»–ç”¨äºæ³¨é‡Šæ•°æ®é›†çš„å‚æ•°. è¯¥å‚æ•°ä¸€èˆ¬ä¸éœ€è¦è®¾ç½®.


## è‡ªå®šä¹‰æ¨¡å‹
ä»¥ä¸‹æ˜¯ä¸€ä¸ª**è‡ªå®šä¹‰æ¨¡å‹**çš„æ¡ˆä¾‹. å®Œæ•´çš„pyæ–‡ä»¶å¯ä»¥æŸ¥çœ‹[custom.py](https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/custom.py), shè„šæœ¬å¯ä»¥æŸ¥çœ‹[custom](https://github.com/modelscope/swift/tree/main/examples/pytorch/llm/scripts/custom). ä½ å¯ä»¥é€šè¿‡æŒ‡å®š`--custom_register_path xxx.py`å¯¹æ³¨å†Œçš„å†…å®¹è¿›è¡Œè§£æ.

```python
from typing import Any, Dict

from modelscope import AutoConfig, AutoModelForCausalLM, AutoTokenizer

from torch import dtype as Dtype
from transformers.utils.versions import require_version

from swift.llm import LoRATM, TemplateType, get_model_tokenizer, register_model
from swift.utils import get_logger

logger = get_logger()


class CustomModelType:
    tigerbot_7b = 'tigerbot-7b'
    tigerbot_13b = 'tigerbot-13b'
    tigerbot_13b_chat = 'tigerbot-13b-chat'


class CustomTemplateType:
    tigerbot = 'tigerbot'


@register_model(CustomModelType.tigerbot_7b,
                'TigerResearch/tigerbot-7b-base-v3', LoRATM.llama2,
                TemplateType.default_generation)
@register_model(CustomModelType.tigerbot_13b,
                'TigerResearch/tigerbot-13b-base-v2', LoRATM.llama2,
                TemplateType.default_generation)
@register_model(CustomModelType.tigerbot_13b_chat,
                'TigerResearch/tigerbot-13b-chat-v4', LoRATM.llama2,
                CustomTemplateType.tigerbot)
def get_tigerbot_model_tokenizer(model_dir: str,
                                 torch_dtype: Dtype,
                                 model_kwargs: Dict[str, Any],
                                 load_model: bool = True,
                                 **kwargs):
    use_flash_attn = kwargs.pop('use_flash_attn', False)
    if use_flash_attn:
        require_version('transformers>=4.34')
        logger.info('Setting use_flash_attention_2: True')
        model_kwargs['use_flash_attention_2'] = True
    model_config = AutoConfig.from_pretrained(
        model_dir, trust_remote_code=True)
    model_config.pretraining_tp = 1
    model_config.torch_dtype = torch_dtype
    logger.info(f'model_config: {model_config}')
    tokenizer = AutoTokenizer.from_pretrained(
        model_dir, trust_remote_code=True)
    model = None
    if load_model:
        model = AutoModelForCausalLM.from_pretrained(
            model_dir,
            config=model_config,
            torch_dtype=torch_dtype,
            trust_remote_code=True,
            **model_kwargs)
    return model, tokenizer


if __name__ == '__main__':
    # test model base
    model, tokenizer = get_model_tokenizer(
        CustomModelType.tigerbot_7b, use_flash_attn=False)
    print(model.__class__.__name__)
    # test model chat
    model, tokenizer = get_model_tokenizer(
        CustomModelType.tigerbot_13b_chat, use_flash_attn=False)
    print(model.__class__.__name__)
```

`register_model`ä¼šåœ¨`MODEL_MAPPING`ä¸­æ³¨å†Œæ¨¡å‹, è¯¥å‡½æ•°çš„å‚æ•°å«ä¹‰å¦‚ä¸‹:

- `model_type`: å¿…å¡«é¡¹. è¡¨ç¤ºæ¨¡å‹çš„åå­—, ä¹Ÿæ˜¯å”¯ä¸€çš„id.
- `model_id_or_path`: å¿…å¡«é¡¹. è¡¨ç¤ºæ¨¡å‹åœ¨ModelScope Hubä¸­çš„`model_id`, æˆ–è€…æ˜¯æœ¬åœ°çš„æ¨¡å‹ç›®å½•`model_dir`.
- `lora_target_modules`: é»˜è®¤ä¸º`None`. è¡¨ç¤ºåœ¨shè„šæœ¬ä¸­æŒ‡å®š`--lora_target_modules DEFAULT`æˆ–`--lora_target_modules AUTO`æˆ–æœªæŒ‡å®š`--lora_target_modules`æƒ…å†µä¸‹é»˜è®¤ä½¿ç”¨çš„lora_target_modules.
- `template`: é»˜è®¤ä¸º`TemplateType.default`. è¡¨ç¤ºåœ¨shè„šæœ¬ä¸­æŒ‡å®š`--template_type AUTO`æˆ–æœªæŒ‡å®š`--template_type`æƒ…å†µä¸‹é»˜è®¤ä½¿ç”¨çš„å¯¹è¯æ¨¡æ¿.
- `get_function`: é»˜è®¤å€¼ä¸º`None`. è·å–modelå’Œtokenizerçš„å‡½æ•°. å¦‚æœä¼ å…¥None, åˆ™ä½¿ç”¨ä¿®é¥°å™¨æ–¹æ¡ˆè¿›è¡Œæ¨¡å‹æ³¨å†Œ. å¦‚æœä¼ å…¥ä¸€ä¸ªå‡½æ•°, åˆ™ä½¿ç”¨æ­£å¸¸æ–¹æ¡ˆè¿›è¡Œæ³¨å†Œ.
- `requires`: é»˜è®¤ä¸º`[]`. è¡¨ç¤ºæ¨¡å‹æ‰€éœ€è¦çš„åŒºåˆ«äºå…¶ä»–æ¨¡å‹çš„ä¾èµ–. è¯¥å‚æ•°ä¸€èˆ¬ä¸éœ€è¦è®¾ç½®.
- `torch_dtype`: é»˜è®¤ä¸º`None`. è¡¨ç¤ºæ¨¡å‹æ‰€æ¨èä½¿ç”¨çš„torch_dtype. è¯¥å‚æ•°ä¸€èˆ¬ä¸éœ€è¦è®¾ç½®.
- `revision`: é»˜è®¤ä¸º`None`. ç”¨äºæŒ‡å®šæ¨¡å‹çš„ç‰ˆæœ¬å·. å¦‚æœ`model_id_or_path`æ˜¯æœ¬åœ°çš„æ¨¡å‹ç›®å½•, åˆ™è¯¥å‚æ•°å¤±æ•ˆ. è¯¥å‚æ•°ä¸€èˆ¬ä¸éœ€è¦è®¾ç½®.
- `ignore_file_pattern`: é»˜è®¤ä¸º`None`. è¡¨ç¤ºä¸‹è½½çš„æ—¶å€™éœ€è¦å¿½ç•¥çš„æ–‡ä»¶åçš„æ­£åˆ™pattern, è¯¥å‚æ•°ä¼šä¼ é€’ç»™`snapshot_download`. ä¾‹å¦‚`r'.+\.bin$'`, `r'.+\.savetensors$'`ç­‰. è¯¥å‚æ•°ä¸€èˆ¬ä¸éœ€è¦è®¾ç½®.
- `**kwargs`: å…¶ä»–ç”¨äºæ³¨é‡Šæ¨¡å‹èƒ½åŠ›çš„å‚æ•°. è¯¥å‚æ•°ä¸€èˆ¬ä¸éœ€è¦è®¾ç½®.


## è‡ªå®šä¹‰å¯¹è¯æ¨¡æ¿
ä»¥ä¸‹æ˜¯ä¸€ä¸ª**è‡ªå®šä¹‰æ¨¡å‹**çš„æ¡ˆä¾‹. å®Œæ•´çš„pyæ–‡ä»¶å¯ä»¥æŸ¥çœ‹[custom.py](https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/custom.py), shè„šæœ¬å¯ä»¥æŸ¥çœ‹[custom](https://github.com/modelscope/swift/tree/main/examples/pytorch/llm/scripts/custom).

```python
from swift.llm import (Template, ModelType, dataset_map,
                       get_model_tokenizer, get_template, get_dataset,
                       print_example, register_template, DatasetName)
from swift.utils import get_logger

logger = get_logger()


class CustomTemplateType:
    tigerbot = 'tigerbot'


# Ref: https://github.com/TigerResearch/TigerBot/blob/main/infer.py
register_template(
    CustomTemplateType.tigerbot,
    Template(['{{SYSTEM}}'], ['\n\n### Instruction:\n{{QUERY}}\n\n### Response:\n'], [],
             [['eos_token_id']]))

if __name__ == '__main__':
    # test template
    train_dataset, _ = get_dataset(DatasetName.blossom_math_zh)
    _, tokenizer = get_model_tokenizer(ModelType.qwen_7b_chat, load_model=False)
    template = get_template(CustomTemplateType.tigerbot, tokenizer)
    train_dataset = dataset_map(train_dataset, template.encode)
    print_example(train_dataset[0], tokenizer)
```

`register_template`ä¼šåœ¨`TEMPLATE_MAPPING`ä¸­æ³¨å†Œå¯¹è¯æ¨¡æ¿, è¯¥å‡½æ•°çš„å‚æ•°å«ä¹‰å¦‚ä¸‹:

- `template_type`: å¿…å¡«é¡¹, è¡¨ç¤ºå¯¹è¯æ¨¡æ¿çš„åå­—, ä¹Ÿæ˜¯templateçš„å”¯ä¸€id.
- `template`: å¿…å¡«é¡¹, éœ€è¦ä¼ å…¥ä¸€ä¸ª`Template`. åˆå§‹åŒ–`Template`éœ€è¦ä¼ å…¥ä»¥ä¸‹å‚æ•°: `prefix`, `prompt`, `chat_sep`, `suffix`, `default_system`.

æ¨¡æ¿åˆå§‹åŒ–å‡½æ•°ä¼šæ ¹æ®è¿™å››ä¸ªå†…å®¹, è·å–å®Œæ•´çš„chat template. å…¶ä¸­è¿™å››ä¸ªé…ç½®å†…å®¹çš„å«ä¹‰å¦‚ä¸‹.

- `prefix`: è¡¨ç¤ºå¯¹è¯æ¨¡æ¿ä¸­çš„å‰ç¼€éƒ¨åˆ†, ä¸€èˆ¬ä¸ºsysteméƒ¨åˆ†, å‰ç¼€token, bos tokenç­‰å†…å®¹. æˆ‘ä»¬ä½¿ç”¨`{{SYSTEM}}`ä½œä¸ºsystemçš„å ä½ç¬¦. å¦‚æœ`{{SYSTEM}}`æ²¡æœ‰åœ¨prefixä¸­å­˜åœ¨, åˆ™è¯¥Templateä¸æ”¯æŒsystem, e.g. `damo-agent-mini-zh`æ•°æ®é›†.
- `prompt`: è¡¨ç¤ºå¯¹è¯æ¨¡æ¿ä¸­çš„ä¸€è½®å¯¹è¯. æˆ‘ä»¬ä½¿ç”¨`{{QUERY}}`ä½œä¸ºæ¯è½®å¯¹è¯ä¸­, humanè¯¢é—®éƒ¨åˆ†çš„å ä½ç¬¦, `{{ROUND0}}`åˆ™è¡¨ç¤ºæœ¬æ¬¡å¯¹è¯æ˜¯ç¬¬å‡ è½®çš„å ä½ç¬¦, ä»0å¼€å§‹è®¡æ•°, `{{ROUND1}}`ä»1å¼€å§‹è®¡æ•°. AIåŠ©æ‰‹çš„å›å¤éƒ¨åˆ†ä¼šæ‹¼æ¥åœ¨`prompt`çš„åé¢, å› æ­¤æˆ‘ä»¬æ²¡æœ‰è®¾è®¡å…¶å ä½ç¬¦. æˆ‘ä»¬åªä¼šå¯¹AIåŠ©æ‰‹çš„å›å¤éƒ¨åˆ†è®¡ç®—æŸå¤±.
- `chat_sep`: å¦‚æœéœ€è¦è¿›è¡Œå¤šè½®å¯¹è¯, `chat_sep`ä¼šä½œä¸ºæ¯è½®å¯¹è¯ä¹‹é—´çš„åˆ†éš”ç¬¦, ä¾‹å¦‚: æ¢è¡Œç­‰. å¦‚æœè®¾ç½®ä¸ºNone, åˆ™è¯¥Templateä¸æ”¯æŒå¤šè½®å¯¹è¯.
- `suffix`: ä½œä¸ºå¯¹è¯æ¨¡æ¿çš„åç¼€éƒ¨åˆ†, ä¸€èˆ¬ä¸ºeos token. ä¼šæ‹¼æ¥åœ¨æœ€åä¸€è½®çš„å¯¹è¯åé¢.
- `default_system`: é»˜è®¤çš„system.
