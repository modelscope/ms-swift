
# Megatron-SWIFTè®­ç»ƒ

SWIFTå¼•å…¥äº†Megatronçš„å¹¶è¡ŒæŠ€æœ¯æ¥åŠ é€Ÿå¤§æ¨¡å‹çš„è®­ç»ƒï¼ŒåŒ…æ‹¬æ•°æ®å¹¶è¡Œã€å¼ é‡å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œã€åºåˆ—å¹¶è¡Œï¼Œä¸Šä¸‹æ–‡å¹¶è¡Œï¼Œä¸“å®¶å¹¶è¡Œã€‚æ”¯æŒQwen3ã€[Qwen3-MoE](https://github.com/modelscope/ms-swift/blob/main/examples/train/megatron/qwen3_moe.sh)ã€Qwen2.5ã€Llama3ã€Deepseek-R1è’¸é¦ç³»ç­‰æ¨¡å‹çš„é¢„è®­ç»ƒå’Œå¾®è°ƒã€‚å®Œæ•´æ”¯æŒçš„æ¨¡å‹å¯ä»¥å‚è€ƒ[æ”¯æŒçš„æ¨¡å‹ä¸æ•°æ®é›†æ–‡æ¡£](./æ”¯æŒçš„æ¨¡å‹å’Œæ•°æ®é›†.md)ã€‚

## ç¯å¢ƒå‡†å¤‡
ä½¿ç”¨Megatron-SWIFTï¼Œé™¤äº†å®‰è£…swiftä¾èµ–å¤–ï¼Œè¿˜éœ€è¦å®‰è£…ä»¥ä¸‹å†…å®¹ï¼š

```shell
# æ¨ètorchç‰ˆæœ¬ï¼š2.5 / 2.6
pip install pybind11
# transformer_engine
# è‹¥å‡ºç°å®‰è£…é”™è¯¯ï¼Œå¯ä»¥å‚è€ƒè¯¥issueè§£å†³: https://github.com/modelscope/ms-swift/issues/3793
pip install git+https://github.com/NVIDIA/TransformerEngine.git@release_v2.3

# apex
git clone https://github.com/NVIDIA/apex
cd apex
# https://github.com/modelscope/ms-swift/issues/4176
git checkout e13873debc4699d39c6861074b9a3b2a02327f92
pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings "--build-option=--cpp_ext" --config-settings "--build-option=--cuda_ext" ./

# megatron-core
pip install git+https://github.com/NVIDIA/Megatron-LM.git@core_r0.12.0
```

æˆ–è€…ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨é•œåƒï¼š
```
modelscope-registry.cn-hangzhou.cr.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda12.4.0-py310-torch2.6.0-vllm0.8.5.post1-modelscope1.27.1-swift3.5.3
modelscope-registry.cn-beijing.cr.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda12.4.0-py310-torch2.6.0-vllm0.8.5.post1-modelscope1.27.1-swift3.5.3
modelscope-registry.us-west-1.cr.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda12.4.0-py310-torch2.6.0-vllm0.8.5.post1-modelscope1.27.1-swift3.5.3
```

ä¾èµ–åº“Megatron-LMä¸­çš„è®­ç»ƒæ¨¡å—å°†ç”±swiftè¿›è¡Œgit cloneå¹¶å®‰è£…ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡`MEGATRON_LM_PATH`æŒ‡å‘å·²ç»ä¸‹è½½å¥½çš„repoè·¯å¾„ï¼ˆæ–­ç½‘ç¯å¢ƒï¼Œ[core_r0.12.0åˆ†æ”¯](https://github.com/NVIDIA/Megatron-LM/tree/core_r0.12.0)ï¼‰ã€‚


## å¿«é€Ÿå…¥é—¨æ¡ˆä¾‹

è¿™é‡Œä»‹ç»ä½¿ç”¨2å¡80GiB A100å¯¹Qwen2.5-7B-Instructæ¨¡å‹è¿›è¡Œè‡ªæˆ‘è®¤çŸ¥å¾®è°ƒçš„å¿«é€Ÿå…¥é—¨æ¡ˆä¾‹ï¼Œä»¥ä¸‹æœ€ä½³å®è·µå¯ä»¥åœ¨10åˆ†é’Ÿå†…å®Œæˆã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å°†HFæ ¼å¼çš„æƒé‡è½¬ä¸ºMegatronæ ¼å¼ï¼š
- è‹¥å‡ºç°OOMï¼Œå°†`CUDA_VISIBLE_DEVICES=0`åˆ é™¤å³å¯ã€‚
- "ms-swift>=3.6"æ¨èå¢åŠ `--test_convert_precision true`å‚æ•°æµ‹è¯•è½¬æ¢ç²¾åº¦ã€‚
```shell
CUDA_VISIBLE_DEVICES=0 \
swift export \
    --model Qwen/Qwen2.5-7B-Instruct \
    --to_mcore true \
    --torch_dtype bfloat16 \
    --output_dir Qwen2.5-7B-Instruct-mcore
```

ç„¶åï¼Œä½¿ç”¨ä»¥ä¸‹è„šæœ¬è¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒæ‰€éœ€æ˜¾å­˜èµ„æºä¸º2*80GiBï¼š
- è‹¥ä½¿ç”¨å¤šæœºè®­ç»ƒï¼Œå»ºè®®å…±äº«ç£ç›˜ï¼Œå¹¶å°†`--save`æŒ‡å®šä¸ºç›¸åŒçš„è·¯å¾„ã€‚
```shell
PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' \
NPROC_PER_NODE=2 \
CUDA_VISIBLE_DEVICES=0,1 \
megatron sft \
    --load Qwen2.5-7B-Instruct-mcore \
    --dataset 'AI-ModelScope/alpaca-gpt4-data-zh#500' \
              'AI-ModelScope/alpaca-gpt4-data-en#500' \
              'swift/self-cognition#500' \
    --tensor_model_parallel_size 2 \
    --sequence_parallel true \
    --micro_batch_size 16 \
    --global_batch_size 16 \
    --recompute_granularity full \
    --recompute_method uniform \
    --recompute_num_layers 1 \
    --finetune true \
    --cross_entropy_loss_fusion true \
    --lr 1e-5 \
    --lr_warmup_fraction 0.05 \
    --min_lr 1e-6 \
    --max_epochs 1 \
    --save megatron_output/Qwen2.5-7B-Instruct \
    --save_interval 100 \
    --max_length 2048 \
    --system 'You are a helpful assistant.' \
    --num_workers 4 \
    --no_save_optim true \
    --no_save_rng true \
    --dataset_num_proc 4 \
    --model_author swift \
    --model_name swift-robot
```

æœ€åï¼Œå°†Megatronæ ¼å¼æƒé‡è½¬ä¸ºHFæ ¼å¼ï¼š
- æ³¨æ„ï¼š`--mcore_model`è¯·æŒ‡å‘`iter_xxx`çš„ä¸Šçº§ç›®å½•ã€‚é»˜è®¤ä¼šä½¿ç”¨`latest_checkpointed_iteration.txt`ä¸­å¯¹åº”çš„checkpointã€‚
- è‹¥å‡ºç°OOMï¼Œå°†`CUDA_VISIBLE_DEVICES=0`åˆ é™¤å³å¯ã€‚
- "ms-swift>=3.6"æ¨èå¢åŠ `--test_convert_precision true`å‚æ•°æµ‹è¯•è½¬æ¢ç²¾åº¦ã€‚
```shell
CUDA_VISIBLE_DEVICES=0 \
swift export \
    --mcore_model megatron_output/Qwen2.5-7B-Instruct/vx-xxx \
    --to_hf true \
    --torch_dtype bfloat16 \
    --output_dir megatron_output/Qwen2.5-7B-Instruct/vx-xxx-hf
```

æˆ‘ä»¬å¯¹ç”Ÿæˆçš„HFæ ¼å¼æƒé‡è¿›è¡Œæ¨ç†ï¼š
```shell
CUDA_VISIBLE_DEVICES=0 \
swift infer \
    --model megatron_output/Qwen2.5-7B-Instruct/vx-xxx-hf \
    --stream true \
    --temperature 0 \
    --max_new_tokens 2048
```

æ¨ç†ç»“æœå¦‚ä¸‹ï¼š
```
<<< who are you?
I am a language model developed by swift, you can call me swift-robot. How can I assist you?
```

- è‹¥è¦è¿›è¡Œé¢„è®­ç»ƒï¼Œä½ å¯ä»¥ä½¿ç”¨`megatron pt`æ›¿ä»£`megatron sft`ï¼Œè¿™å°†ä¼šä½¿ç”¨ç”Ÿæˆå¼çš„templateè¿›è¡Œè®­ç»ƒã€‚
- **æ›´å¤šæ¡ˆä¾‹**ï¼šåŒ…æ‹¬packingã€å¤šæœºã€32Kä¸Šä¸‹æ–‡ã€DPOã€MoEæ¨¡å‹ã€é¢„è®­ç»ƒï¼Œå¯ä»¥æŸ¥çœ‹[è¿™é‡Œ](https://github.com/modelscope/ms-swift/tree/main/examples/train/megatron)ã€‚
- è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼å’Œms-swiftç›¸åŒï¼Œå‚è€ƒ[è‡ªå®šä¹‰æ•°æ®é›†æ–‡æ¡£](../Customization/è‡ªå®šä¹‰æ•°æ®é›†.md)ã€‚

## Benchmark

ä½¿ç”¨`megatron sft`å’Œ`swift sft`åœ¨å•æœºå…«å¡A800ç¯å¢ƒä¸‹è¿›è¡ŒDense/MoEæ¨¡å‹å…¨å‚æ•°è®­ç»ƒçš„é€Ÿåº¦å¯¹æ¯”å¦‚ä¸‹ï¼Œå¯¹åº”è„šæœ¬å‚è€ƒ[è¿™é‡Œ](https://github.com/modelscope/ms-swift/tree/main/examples/train/megatron/benchmark)ã€‚

**Dense** Qwen2.5-14B:

|          | Megatron-LM | Deepspeed-ZeRO2 | Deepspeed-ZeRO3 |
| -------- | ----------- | ---------- | ---------- |
| è®­ç»ƒé€Ÿåº¦ |      9.04s/it       |  10.32s/it   | 10.56s/it |
| æ˜¾å­˜å ç”¨ | 8\*64GB     |  8\*80GB   | 8\*58GB |

**MoE** Qwen1.5-MoE-A2.7B:

|          | Megatron-LM | Deepspeed-ZeRO2 | Deepspeed-ZeRO3 |
| -------- | ----------- | ---------- | ---------- |
| è®­ç»ƒé€Ÿåº¦ |      2.93s/it       |  6.02s/it   | 24.30s/it |
| æ˜¾å­˜å ç”¨ | 8\*66GB     |  8\*72GB   | 8\*50GB |


## å‘½ä»¤è¡Œå‚æ•°

### Megatronå‚æ•°


**è®­ç»ƒå‚æ•°**:
- ğŸ”¥micro_batch_size: æ¯ä¸ªdeviceçš„æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤ä¸º1ã€‚
- ğŸ”¥global_batch_size: æ€»æ‰¹æ¬¡å¤§å°ï¼Œç­‰ä»·äº`micro_batch_size*æ•°æ®å¹¶è¡Œå¤§å°*æ¢¯åº¦ç´¯åŠ æ­¥æ•°`ã€‚é»˜è®¤ä¸º16ã€‚
- ğŸ”¥recompute_granularity: é‡æ–°è®¡ç®—æ¿€æ´»çš„ç²’åº¦ï¼Œå¯é€‰é¡¹ä¸º'full', 'selective'ã€‚å…¶ä¸­fullä»£è¡¨é‡æ–°è®¡ç®—æ•´ä¸ªtransformer layerï¼Œselectiveä»£è¡¨åªè®¡ç®—transformer layerä¸­çš„æ ¸å¿ƒæ³¨æ„åŠ›éƒ¨åˆ†ã€‚é€šå¸¸'selective'æ˜¯æ¨èçš„ã€‚é»˜è®¤ä¸º'selective'ã€‚
- ğŸ”¥recompute_method: è¯¥å‚æ•°éœ€å°†recompute_granularityè®¾ç½®ä¸º'full'æ‰ç”Ÿæ•ˆï¼Œå¯é€‰é¡¹ä¸º'uniform', 'block'ã€‚é»˜è®¤ä¸ºNoneã€‚
- ğŸ”¥recompute_num_layers: è¯¥å‚æ•°éœ€å°†recompute_granularityè®¾ç½®ä¸º'full'æ‰ç”Ÿæ•ˆï¼Œé»˜è®¤ä¸ºNoneã€‚è‹¥`recompute_method`è®¾ç½®ä¸ºuniformï¼Œè¯¥å‚æ•°å«ä¹‰ä¸ºæ¯ä¸ªå‡åŒ€åˆ’åˆ†çš„é‡æ–°è®¡ç®—å•å…ƒçš„transformer layersæ•°é‡ã€‚ä¾‹å¦‚ä½ å¯ä»¥æŒ‡å®šä¸º`--recompute_granularity full --recompute_method uniform --recompute_num_layers 4`ã€‚recompute_num_layersè¶Šå¤§ï¼Œæ˜¾å­˜å ç”¨è¶Šå°ï¼Œè®¡ç®—æˆæœ¬è¶Šå¤§ã€‚é»˜è®¤ä¸ºNoneã€‚
- recompute_modules: é€‰é¡¹åŒ…æ‹¬"core_attn", "moe_act", "layernorm", "mla_up_proj", "mlp", "moe" ï¼Œé»˜è®¤å€¼ä¸ºï¼Œ["core_attn"]ã€‚ä¾‹å¦‚åœ¨MoEè®­ç»ƒæ—¶ï¼Œä½ å¯ä»¥é€šè¿‡æŒ‡å®š`--recompute_granularity selective --recompute_modules core_attn moe`é™ä½æ˜¾å­˜ã€‚å…¶ä¸­"core_attn"ã€"mlp" å’Œ "moe" ä½¿ç”¨å¸¸è§„æ£€æŸ¥ç‚¹ï¼Œ"moe_act"ã€"layernorm" å’Œ "mla_up_proj" ä½¿ç”¨è¾“å‡ºä¸¢å¼ƒæ£€æŸ¥ç‚¹ã€‚
  - "core_attn"ï¼šé‡æ–°è®¡ç®— Transformer å±‚ä¸­çš„æ ¸å¿ƒæ³¨æ„åŠ›éƒ¨åˆ†ã€‚
  - "mlp"ï¼šé‡æ–°è®¡ç®—å¯†é›†çš„ MLP å±‚ã€‚
  - "moe"ï¼šé‡æ–°è®¡ç®— MoE å±‚ã€‚
  - "moe_act"ï¼šé‡æ–°è®¡ç®— MoE ä¸­çš„ MLP æ¿€æ´»å‡½æ•°éƒ¨åˆ†ã€‚
  - "layernorm"ï¼šé‡æ–°è®¡ç®— input_layernorm å’Œ pre_mlp_layernormã€‚
  - "mla_up_proj"ï¼šé‡æ–°è®¡ç®— MLA ä¸ŠæŠ•å½±å’Œ RoPE åº”ç”¨éƒ¨åˆ†ã€‚
- deterministic_mode: ç¡®å®šæ€§æ¨¡å¼ï¼Œè¿™ä¼šå¯¼è‡´è®­ç»ƒé€Ÿåº¦ä¸‹é™ï¼Œé»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥train_iters: è®­ç»ƒçš„æ€»è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸ºNoneã€‚
- ğŸ”¥log_interval: logçš„æ—¶é—´é—´éš”ï¼ˆå•ä½ï¼šitersï¼‰ï¼Œé»˜è®¤ä¸º5ã€‚
- tensorboard_dir: tensorboardæ—¥å¿—å†™å…¥çš„ç›®å½•ã€‚é»˜è®¤Noneï¼Œå³å­˜å‚¨åœ¨`f'{save}/runs'`ç›®å½•ä¸‹ã€‚
- no_masked_softmax_fusion: é»˜è®¤ä¸ºFalseã€‚ç”¨äºç¦ç”¨query_key_valueçš„scaling, masking, and softmaxèåˆã€‚
- no_bias_dropout_fusion: é»˜è®¤ä¸ºFalseã€‚ç”¨äºç¦ç”¨biaså’Œdropoutçš„èåˆã€‚
- no_bias_swiglu_fusion: é»˜è®¤ä¸ºFalseã€‚æŒ‡å®š`--no_bias_dropout_fusion true`ï¼Œç”¨äºç¦æ­¢biaså’Œswigluèåˆã€‚
- no_rope_fusion: é»˜è®¤ä¸ºFalseã€‚æŒ‡å®š`--no_rope_fusion true`ç”¨äºç¦æ­¢ropeèåˆã€‚
- no_gradient_accumulation_fusion: é»˜è®¤ä¸ºFalseã€‚æŒ‡å®š`--no_gradient_accumulation_fusion true`ç”¨äºç¦ç”¨æ¢¯åº¦ç´¯åŠ èåˆã€‚
- ğŸ”¥cross_entropy_loss_fusion: å¯åŠ¨äº¤å‰ç†µæŸå¤±è®¡ç®—èåˆã€‚é»˜è®¤ä¸ºFalseã€‚
- cross_entropy_fusion_impl: äº¤å‰ç†µæŸå¤±èåˆçš„å®ç°ã€‚å¯é€‰ä¸º'native'å’Œ'te'ã€‚é»˜è®¤ä¸º'native'ã€‚
- calculate_per_token_loss: æ ¹æ®å…¨å±€æ‰¹æ¬¡ä¸­çš„éå¡«å……tokenæ•°é‡æ¥å¯¹äº¤å‰ç†µæŸå¤±è¿›è¡Œç¼©æ”¾ã€‚é»˜è®¤ä¸ºTrueã€‚
- ğŸ”¥attention_backend: ä½¿ç”¨çš„æ³¨æ„åŠ›åç«¯ (flashã€fusedã€unfusedã€localã€auto)ã€‚é»˜è®¤ä¸º autoã€‚
- optimizer: ä¼˜åŒ–å™¨ç±»å‹ï¼Œå¯é€‰ä¸º'adam'ã€'sgd'ã€‚é»˜è®¤ä¸ºadamã€‚
- ğŸ”¥optimizer_cpu_offload: å°†ä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ° CPUã€‚é»˜è®¤ä¸ºFalseã€‚
- optimizer_offload_fraction: å¸è½½åˆ° CPU çš„ä¼˜åŒ–å™¨çŠ¶æ€æ‰€å æ¯”ä¾‹ã€‚é»˜è®¤ä¸º1.ã€‚
- use_precision_aware_optimizer: ä½¿ç”¨ TransformerEngine ä¸­çš„ç²¾åº¦æ„ŸçŸ¥ä¼˜åŒ–å™¨ï¼Œè¯¥ä¼˜åŒ–å™¨å…è®¸å°†ä¸»å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€è®¾ç½®ä¸ºè¾ƒä½ç²¾åº¦ï¼Œä¾‹å¦‚ fp16 å’Œ fp8ã€‚
- main_grads_dtype: å¯ç”¨ use_precision_aware_optimizer æ—¶ä¸»æ¢¯åº¦çš„ dtypeã€‚å¯é€‰ä¸º'fp32', 'bf16'ã€‚é»˜è®¤ä¸º'fp32'ã€‚
- main_params_dtype: å¯ç”¨ use_precision_aware_optimizer æ—¶ä¸»å‚æ•°çš„ dtypeã€‚å¯é€‰ä¸º'fp32', 'fp16'ã€‚é»˜è®¤ä¸º'fp32'ã€‚
- exp_avg_dtype: å¯ç”¨ use_precision_aware_optimizer æ—¶ï¼Œadam ä¼˜åŒ–å™¨ä¸­ exp_avgï¼ˆå³ä¸€é˜¶çŸ©ï¼‰çš„ dtypeã€‚è¯¥ dtype ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†ä¼˜åŒ–å™¨çŠ¶æ€å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œä½†ä¸ä¼šå½±å“å†…æ ¸è®¡ç®—æ—¶çš„ç²¾åº¦ã€‚å¯é€‰ä¸º'fp32', 'fp16', 'bf16', 'fp8'ã€‚é»˜è®¤ä¸º'fp32'ã€‚
- exp_avg_sq_dtype: å¯ç”¨ use_precision_aware_optimizer æ—¶ï¼Œadam ä¼˜åŒ–å™¨ä¸­ exp_avg_sqï¼ˆå³äºŒé˜¶çŸ©ï¼‰çš„ dtypeã€‚è¯¥ dtype ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†ä¼˜åŒ–å™¨çŠ¶æ€å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œä½†ä¸ä¼šå½±å“å†…æ ¸è®¡ç®—çš„ç²¾åº¦ã€‚å¯é€‰ä¸º'fp32', 'fp16', 'bf16', 'fp8'ã€‚é»˜è®¤ä¸º'fp32'ã€‚
- dataloader_type: é»˜è®¤ä¸º'cyclic'ï¼Œå¯é€‰ä¸º'single', 'cyclic', 'external'ã€‚è‹¥å¼€å¯`--streaming`ï¼Œåˆ™è®¾ç½®ä¸º`external`ã€‚
- manual_gc: ç¦ç”¨é»˜è®¤åƒåœ¾å›æ”¶å™¨ï¼Œæ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶ã€‚é»˜è®¤ä¸ºFalseã€‚
- manual_gc_interval: è§¦å‘åƒåœ¾å›æ”¶çš„é—´éš”ã€‚é»˜è®¤ä¸º0ã€‚
- seed: pythonã€numpyã€pytorchå’Œcudaçš„éšæœºç§å­ï¼Œé»˜è®¤ä¸º42ã€‚
- ğŸ”¥num_workers: dataloderçš„workersæ•°é‡ï¼Œé»˜è®¤ä¸º4ã€‚
  - æ³¨æ„ï¼šè‹¥è®¾ç½®`--streaming true`ï¼Œåˆ™è®¾ç½®ä¸º1ã€‚
- seq_length: é»˜è®¤ä¸ºNoneï¼Œå³è®¾ç½®ä¸º`max_length`ã€‚å¯¹æ•°æ®é›†é•¿åº¦è¿›è¡Œé™åˆ¶è¯·ä½¿ç”¨åŸºæœ¬å‚æ•°ä¸­çš„`--max_length`æ§åˆ¶ï¼Œæ— éœ€è®¾ç½®æ­¤å‚æ•°ã€‚
- use_cpu_initialization: åœ¨cpuä¸Šåˆå§‹åŒ–æƒé‡ï¼Œé»˜è®¤ä¸ºFalseã€‚åœ¨è¿›è¡ŒHFå’ŒMCoreæƒé‡è½¬æ¢æ—¶ä¼šè¢«ä½¿ç”¨ã€‚
- no_create_attention_mask_in_dataloader: åœ¨dataloaderä¸­ä¸åˆ›å»ºattention maskï¼Œé»˜è®¤ä¸ºTrueã€‚
- extra_megatron_kwargs: ä¼ å…¥megatronçš„å…¶ä»–å‚æ•°ï¼Œä½¿ç”¨jsonä¼ é€’ã€‚é»˜è®¤ä¸ºNoneã€‚

**å­¦ä¹ ç‡å‚æ•°**:
- ğŸ”¥lr: åˆå§‹å­¦ä¹ ç‡ï¼Œæœ€ç»ˆä¼šæ ¹æ®å­¦ä¹ ç‡é¢„çƒ­ç­–ç•¥å’Œè¡°å‡ç­–ç•¥å†³å®šæ¯ä¸ªè¿­ä»£çš„å­¦ä¹ ç‡ï¼Œé»˜è®¤ä¸º1e-5ã€‚
- lr_decay_style: å­¦ä¹ ç‡è¡°å‡ç­–ç•¥ï¼Œé»˜è®¤ä¸º'cosine'ã€‚é€šå¸¸è®¾ç½®ä¸º'cosine', 'linear', 'constant'ã€‚
- ğŸ”¥lr_decay_iters: å­¦ä¹ ç‡è¡°å‡çš„è¿­ä»£æ¬¡æ•°ã€‚é»˜è®¤ä¸ºNoneï¼Œåˆ™è®¾ç½®ä¸º`--train_iters`ã€‚
- lr_warmup_iters: çº¿æ€§å­¦ä¹ ç‡é¢„çƒ­çš„è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸º0ã€‚
- ğŸ”¥lr_warmup_fraction: çº¿æ€§å­¦ä¹ ç‡é¢„çƒ­é˜¶æ®µæ‰€å æ¯”ä¾‹ï¼Œé»˜è®¤ä¸ºNoneã€‚
- ğŸ”¥min_lr: å­¦ä¹ ç‡çš„æœ€å°å€¼ï¼Œå°†ä½äºæ”¹é˜ˆå€¼çš„å­¦ä¹ ç‡è£å‰ªä¸ºè¯¥å€¼ï¼Œé»˜è®¤ä¸º0ã€‚

**æ­£åˆ™åŒ–å‚æ•°**:
- ğŸ”¥weight_decay: é»˜è®¤ä¸º0.1ã€‚
- ğŸ”¥clip_grad: l2æ¢¯åº¦è£å‰ªï¼Œé»˜è®¤ä¸º1.0ã€‚
- adam_beta1: é»˜è®¤0.9ã€‚
- adam_beta2: é»˜è®¤0.95ã€‚
- adam_eps: é»˜è®¤1e-8ã€‚
- sgd_momentum: é»˜è®¤ä¸º0.9ã€‚

**checkpointå‚æ•°**:
- ğŸ”¥save: checkpointçš„è¾“å‡ºç›®å½•ï¼Œé»˜è®¤Noneã€‚åœ¨è®­ç»ƒä¸­ï¼Œè‹¥æœªè®¾ç½®è¯¥å‚æ•°ï¼Œåˆ™é»˜è®¤ä¸º`f'megatron_output/{model_suffix}'`ï¼Œä¾‹å¦‚`'megatron_output/Qwen2.5-7B-Instruct'`ã€‚
  - æ³¨æ„ï¼šè‹¥åœ¨å¤šæœºè®­ç»ƒæ—¶ï¼Œè¯·ç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹çš„ä¿å­˜è·¯å¾„æŒ‡å‘ç›¸åŒä½ç½®ã€‚å¦åˆ™ä½ éœ€è¦åœ¨è®­ç»ƒåæ‰‹åŠ¨é›†ä¸­è¿™äº›æƒé‡ã€‚
- ğŸ”¥save_interval: checkpointä¿å­˜çš„é—´éš”ï¼ˆstepsï¼‰ï¼Œé»˜è®¤ä¸º500ã€‚
  - æ³¨æ„ï¼šè®­ç»ƒç»“æŸæ—¶ä¸€å®šä¼šä¿å­˜æƒé‡ã€‚
- ğŸ”¥no_save_optim: ä¸ä¿å­˜optimizerï¼Œé»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥no_save_rng: ä¸ä¿å­˜rngï¼Œé»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥load: åŠ è½½çš„checkpointç›®å½•ï¼Œé»˜è®¤Noneã€‚
- ğŸ”¥no_load_optim: ä¸è½½å…¥optimizerï¼Œé»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥no_load_rng: ä¸è½½å…¥rngï¼Œé»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥finetune: å°†æ¨¡å‹åŠ è½½å¹¶å¾®è°ƒã€‚ä¸åŠ è½½æ£€æŸ¥ç‚¹çš„ä¼˜åŒ–å™¨å’Œéšæœºç§å­çŠ¶æ€ï¼Œå¹¶å°†è¿­ä»£æ•°è®¾ç½®ä¸º0ã€‚é»˜è®¤ä¸ºFalseã€‚
  - æ³¨æ„ï¼šæ–­ç‚¹ç»­è®­`--load`ï¼Œè‹¥è®¾ç½®`--finetune true`ï¼Œå°†ä¸ä¼šè·³è¿‡æ•°æ®é›†ï¼›è‹¥ä¸è®¾ç½®ï¼Œå°†è·³è¿‡ä¹‹å‰è®­ç»ƒçš„æ•°æ®é›†æ•°é‡ã€‚
  - æµå¼æ•°æ®é›†`--streaming`ï¼Œæš‚ä¸æ”¯æŒè·³è¿‡æ•°æ®é›†ã€‚
- ckpt_format: checkpointçš„æ ¼å¼ã€‚å¯é€‰ä¸º'torch', 'torch_dist', 'zarr'ã€‚é»˜è®¤ä¸º'torch_dist'ã€‚
- no_initialization: ä¸å¯¹æƒé‡è¿›è¡Œåˆå§‹åŒ–ï¼Œé»˜è®¤ä¸ºTrueã€‚
- auto_detect_ckpt_format: è‡ªåŠ¨æ£€æµ‹ckpt formatä¸ºlegacyè¿˜æ˜¯distributedæ ¼å¼ã€‚é»˜è®¤ä¸ºTrueã€‚
- exit_on_missing_checkpoint: å¦‚æœè®¾ç½®äº†`â€“-load`ï¼Œä½†æ‰¾ä¸åˆ°æ£€æŸ¥ç‚¹ï¼Œåˆ™ç›´æ¥é€€å‡ºï¼Œè€Œä¸æ˜¯åˆå§‹åŒ–ã€‚é»˜è®¤ä¸ºTrueã€‚

**åˆ†å¸ƒå¼å‚æ•°**:
- distributed_backend: åˆ†å¸ƒå¼åç«¯ï¼Œå¯é€‰ä¸º'nccl', 'gloo'ã€‚é»˜è®¤ä¸ºncclã€‚
- ğŸ”¥use_distributed_optimizer: ä½¿ç”¨åˆ†å¸ƒå¼ä¼˜åŒ–å™¨ã€‚é»˜è®¤ä¸ºTrueã€‚
- ğŸ”¥tensor_model_parallel_size: tpæ•°ï¼Œé»˜è®¤ä¸º1ã€‚
- ğŸ”¥pipeline_model_parallel_size: ppæ•°ï¼Œé»˜è®¤ä¸º1ã€‚
- ğŸ”¥decoder_first_pipeline_num_layers: decoderç¬¬ä¸€ä¸ªæµæ°´çº¿é˜¶æ®µæ‰€åŒ…å«çš„Transformerå±‚æ•°ã€‚é»˜è®¤ä¸º Noneï¼Œè¡¨ç¤ºå°†Transformerå±‚æ•°å¹³å‡åˆ†é…åˆ°æ‰€æœ‰æµæ°´çº¿é˜¶æ®µã€‚
- ğŸ”¥decoder_last_pipeline_num_layers: decoderæœ€åä¸€ä¸ªæµæ°´çº¿é˜¶æ®µæ‰€åŒ…å«çš„Transformerå±‚æ•°ã€‚é»˜è®¤ä¸º Noneï¼Œè¡¨ç¤ºå°†Transformerå±‚æ•°å¹³å‡åˆ†é…åˆ°æ‰€æœ‰æµæ°´çº¿é˜¶æ®µã€‚
- ğŸ”¥sequence_parallel: å¯åŠ¨åºåˆ—å¹¶è¡Œçš„ä¼˜åŒ–å™¨ã€‚é»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥context_parallel_size: cpæ•°ï¼Œé»˜è®¤ä¸º1ã€‚
- tp_comm_overlap: å¯ç”¨å¼ é‡å¹¶è¡Œé€šä¿¡ä¸GEMMï¼ˆé€šç”¨çŸ©é˜µä¹˜æ³•ï¼‰å†…æ ¸çš„é‡å ï¼ˆé™ä½é€šä¿¡è€—æ—¶ï¼‰ã€‚é»˜è®¤ä¸ºFalseã€‚
- overlap_grad_reduce: å¯ç”¨DDPä¸­grad reduceæ“ä½œçš„é‡å ï¼ˆé™ä½DPé€šä¿¡è€—æ—¶ï¼‰ã€‚é»˜è®¤ä¸ºFalseã€‚
- overlap_param_gather: å¯ç”¨åˆ†å¸ƒå¼ä¼˜åŒ–å™¨ä¸­å‚æ•°all-gatherçš„é‡å ï¼ˆé™ä½DPé€šä¿¡è€—æ—¶ï¼‰ã€‚é»˜è®¤ä¸ºFalseã€‚
- distributed_timeout_minutes: torch.distributedçš„timeoutæ—¶é—´ï¼ˆå•ä½ä¸ºåˆ†é’Ÿï¼‰ï¼Œè¯¥å‚æ•°å¤±æ•ˆï¼Œä½¿ç”¨[åŸºç¡€å‚æ•°](./å‘½ä»¤è¡Œå‚æ•°.md#åŸºæœ¬å‚æ•°)ä¸­çš„ddp_timeoutæ§åˆ¶ï¼Œé»˜è®¤ä¸º300000åˆ†é’Ÿã€‚

**æ—¥å¿—å‚æ•°**:
- log_params_norm: è®°å½•å‚æ•°çš„normã€‚é»˜è®¤ä¸ºFalseã€‚
- log_throughput: è®°å½•æ¯ä¸ªGPUçš„ååé‡ã€‚é»˜è®¤ä¸ºFalseã€‚
  - æ³¨æ„ï¼šåœ¨épackingæƒ…å†µä¸‹ï¼Œlog_throughputå¹¶ä¸å‡†ç¡®ï¼Œå› ä¸º`seq_length`å¹¶ä¸ç­‰äºçœŸå®åºåˆ—é•¿åº¦ã€‚
- tensorboard_log_interval: è®°å½•åˆ°tensorboardçš„é—´éš”ï¼ˆstepsï¼‰ï¼Œé»˜è®¤ä¸º1ã€‚
- tensorboard_queue_size: é˜Ÿåˆ—é•¿åº¦ï¼ˆä¸ç£ç›˜IOç›¸å…³ï¼‰ï¼Œç±»ä¼¼äºå†™å…¥çš„é—´éš”ã€‚é»˜è®¤ä¸º50ã€‚
- log_timers_to_tensorboard: è®°å½•timersåˆ°tensorboardã€‚é»˜è®¤ä¸ºTrueã€‚
- no_log_learning_rate_to_tensorboard: ä¸è®°å½•å­¦ä¹ ç‡åˆ°tensorboardã€‚é»˜è®¤ä¸ºFalseã€‚
- log_validation_ppl_to_tensorboard: å°†éªŒè¯å›°æƒ‘åº¦å†™å…¥tensorboardã€‚é»˜è®¤ä¸ºTrueã€‚
- log_memory_to_tensorboard: å°†å†…å­˜æ—¥å¿—å†™å…¥tensorboardã€‚é»˜è®¤ä¸ºTrueã€‚
- logging_level: æ—¥å¿—çº§åˆ«ã€‚é»˜è®¤ä¸ºNoneã€‚
- wandb_project: wandb é¡¹ç›®åç§°ã€‚é»˜è®¤ä¸º''ï¼Œå³å¿½ç•¥wandbã€‚
- wandb_exp_name: wandb å®éªŒåç§°ã€‚é»˜è®¤ä¸º''ã€‚
- wandb_save_dir: æœ¬åœ°ä¿å­˜ wandb ç»“æœçš„è·¯å¾„ã€‚é»˜è®¤ä¸º''ã€‚

**è¯„ä¼°å‚æ•°**:
- ğŸ”¥eval_iters: è¯„ä¼°çš„è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸º-1ï¼Œæ ¹æ®éªŒè¯æ•°æ®é›†çš„æ•°é‡è®¾ç½®åˆé€‚çš„å€¼ã€‚
  - æ³¨æ„ï¼šè‹¥ä½¿ç”¨æµå¼æ•°æ®é›†ï¼Œè¯¥å€¼éœ€è¦æ‰‹åŠ¨è®¾ç½®ã€‚
- ğŸ”¥eval_interval: è¯„ä¼°çš„é—´éš”ï¼ˆstepsï¼‰ï¼Œå³æ¯è®­ç»ƒå¤šå°‘stepsè¿›è¡Œè¯„ä¼°ï¼Œé»˜è®¤ä¸ºNoneï¼Œå³è®¾ç½®ä¸ºsave_intervalã€‚

**fp8å‚æ•°**:
- fp8_format: ç”¨äºå‰å‘å’Œåå‘ä¼ æ’­ä¸­FP8å¼ é‡çš„FP8æ ¼å¼æ–¹æ¡ˆã€‚å¯é€‰ä¸º'e4m3'ï¼Œ'hybrid'ã€‚é»˜è®¤ä¸ºNoneã€‚
- fp8_recipe: ç”¨äºå‰å‘å’Œåå‘ä¼ æ’­ä¸­ FP8 å¼ é‡çš„ FP8 ç®—æ³•æ–¹æ¡ˆã€‚å¯é€‰ä¸º'tensorwise', 'delayed', 'mxfp8', 'blockwise'ã€‚é»˜è®¤ä¸º'delayed'ã€‚
- fp8_amax_history_len: æ¯ä¸ªå¼ é‡è®°å½• amax å†å²çš„æ­¥æ•°ã€‚é»˜è®¤ä¸º1024ã€‚
- fp8_amax_compute_algo: ç”¨äºæ ¹æ®å†å²è®°å½•è®¡ç®— amax çš„ç®—æ³•ã€‚å¯é€‰ä¸º'most_recent','max'ã€‚é»˜è®¤ä¸º'max'ã€‚
- fp8_param_gather: ä¿æŒè®¡ç®—å‚æ•°ä¸º fp8ï¼ˆä¸ä½¿ç”¨ä»»ä½•å…¶ä»–ä¸­é—´æ•°æ®ç±»å‹ï¼‰ï¼Œå¹¶åœ¨ fp8 æ ¼å¼ä¸‹æ‰§è¡Œå‚æ•°çš„ all-gather æ“ä½œã€‚é»˜è®¤ä¸ºFalseã€‚

**æ··åˆç²¾åº¦å‚æ•°**:
- fp16: fp16æ¨¡å¼ã€‚é»˜è®¤ä¸ºNoneï¼Œä¼šæ ¹æ®æ¨¡å‹çš„torch_dtypeè¿›è¡Œè®¾ç½®ã€‚torch_dtypeé»˜è®¤è¯»å–config.jsonã€‚
- bf16: bf16æ¨¡å¼ã€‚é»˜è®¤ä¸ºNoneï¼Œä¼šæ ¹æ®æ¨¡å‹çš„torch_dtypeè¿›è¡Œè®¾ç½®ã€‚
- apply_query_key_layer_scaling: å°†`Q * K^T` ç¼©æ”¾ä¸º `1 / å±‚æ•°`ï¼ˆä¾‹å¦‚ï¼šç¬¬layer_numå±‚åˆ™é™¤ä»¥layer_numï¼‰ã€‚è¿™å¯¹fp16è®­ç»ƒå¾ˆæœ‰å¸®åŠ©ã€‚é»˜è®¤ä¸ºNoneï¼Œå³è‹¥ä½¿ç”¨`--fp16`ï¼Œåˆ™è®¾ç½®ä¸ºTrueã€‚
- attention_softmax_in_fp32: åœ¨attention_maskå’Œsoftmaxä¸­ä½¿ç”¨fp32è¿›è¡Œè®¡ç®—ã€‚é»˜è®¤ä¸ºTrueã€‚

**æ¨¡å‹å‚æ•°**: ï¼ˆä»¥ä¸‹å‚æ•°é€šå¸¸ä¸éœ€è¦è¿›è¡Œè®¾ç½®ï¼Œä¼šæ ¹æ®HFæ¨¡å‹çš„config.jsonè¿›è¡Œé…ç½®ï¼Œç”¨æˆ·æ— éœ€å…³å¿ƒï¼‰
- num_layers: transformer layersçš„å±‚æ•°ï¼Œé»˜è®¤ä¸ºNoneã€‚
- hidden_size: transformer hidden sizeï¼Œé»˜è®¤ä¸ºNoneã€‚
- ffn_hidden_size: transformer FFNå±‚çš„hidden sizeã€‚é»˜è®¤ä¸ºNoneï¼Œè®¾ç½®ä¸º`4*hidden_size`ã€‚
- num_attention_heads: transformer attention headsçš„ä¸ªæ•°ï¼Œé»˜è®¤ä¸ºNoneã€‚
- group_query_attention: é»˜è®¤ä¸ºNoneã€‚è‹¥`num_query_groups>1`ï¼Œgroup_query_attentionè®¾ç½®ä¸ºTrueï¼Œå¦åˆ™ä¸ºFalseã€‚
- num_query_groups: é»˜è®¤ä¸º1ã€‚
- max_position_embeddings: ä½ç½®ç¼–ç çš„æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ä¸ºNoneã€‚
- position_embedding_type: ä½ç½®ç¼–ç çš„ç±»å‹ï¼Œå¯é€‰ä¸º'learned_absolute'ã€'rope'ã€'mrope'ã€'relative'å’Œ'none'ï¼Œé»˜è®¤ä¸º'rope'ã€‚
- rotary_base: é»˜è®¤ä¸º10000ã€‚
- rotary_percent: é»˜è®¤ä¸º1.ã€‚
- normalization: å¯é€‰ä¸º'LayerNorm', 'RMSNorm'ï¼Œé»˜è®¤ä¸ºRMSNormã€‚
- norm_epsilon: é»˜è®¤ä¸º1e-5ã€‚
- swiglu: ä½¿ç”¨swigluæ›¿ä»£é»˜è®¤çš„geluã€‚é»˜è®¤ä¸ºTrueã€‚
- untie_embeddings_and_output_weights: è§£å¼€embeddingå’Œè¾“å‡ºæƒé‡çš„ç»‘å®šï¼Œé»˜è®¤ä¸ºTrueã€‚
- disable_bias_linear: ç¦ç”¨linearå±‚çš„biasã€‚é»˜è®¤ä¸ºTrueã€‚
- add_qkv_bias: ä»…åœ¨QKVçš„linearä¸­å¢åŠ biasï¼Œé»˜è®¤ä¸ºTrueã€‚
- attention_dropout: é»˜è®¤ä¸º0.ã€‚
- hidden_dropout: é»˜è®¤ä¸º0.ã€‚
- kv_channels: é»˜è®¤ä¸ºNoneï¼Œè®¾ç½®ä¸º`args.hidden_size // args.num_attention_heads`ã€‚
- qk_layernorm: æ˜¯å¦å¯¹Qå’ŒKè¿›è¡Œå±‚å½’ä¸€åŒ–ã€‚
- transformer_impl: ä½¿ç”¨å“ªç§transformerå®ç°ï¼Œå¯é€‰é¡¹ä¸º'local'å’Œ'transformer_engine'ã€‚é»˜è®¤ä¸ºtransformer_engineã€‚
- padded_vocab_size: å®Œæ•´è¯è¡¨å¤§å°ï¼Œé»˜è®¤ä¸ºNoneã€‚
- rope_scaling: rope_scalingç›¸å…³å‚æ•°ï¼Œé»˜è®¤ä¸ºNoneã€‚æ ¼å¼å‚è€ƒ[llama3.1 config.json](https://modelscope.cn/models/LLM-Research/Meta-Llama-3.1-8B-Instruct/file/view/master?fileName=config.json&status=1)ï¼Œä¼ å…¥jsonå­—ç¬¦ä¸²ã€‚


**MoEå‚æ•°**:
- num_experts: MoEçš„ä¸“å®¶æ•°ï¼Œé»˜è®¤ä¸ºNoneã€‚è‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- moe_layer_freq: MoE å±‚ä¸ Dense å±‚ä¹‹é—´çš„åˆ†å¸ƒé¢‘ç‡ã€‚é»˜è®¤ä¸ºNoneã€‚ä»config.jsonä¸­è¯»å–ã€‚
- moe_ffn_hidden_siz: æ¯ä¸ªä¸“å®¶çš„å‰é¦ˆç½‘ç»œï¼ˆffnï¼‰çš„éšè—å±‚å¤§å°ã€‚é»˜è®¤ä¸ºNoneï¼Œè‡ªåŠ¨ä»config.jsonè¯»å–ã€‚è‹¥æœªè¯»å–åˆ°ä¸”`num_experts`ä¸ä¸ºNoneï¼Œåˆ™è®¾ç½®ä¸ºffn_hidden_sizeã€‚
- moe_shared_expert_intermediate_size: å…±äº«ä¸“å®¶çš„æ€»FFNéšè—å±‚å¤§å°ã€‚å¦‚æœæœ‰å¤šä¸ªå…±äº«ä¸“å®¶ï¼Œå®ƒåº”ç­‰äº `num_shared_experts * ffn_size_of_each_shared_expert`ã€‚ é»˜è®¤ä¸ºNoneã€‚è‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- moe_router_topk: æ¯ä¸ªtokenè·¯ç”±åˆ°çš„ä¸“å®¶æ•°é‡ã€‚é»˜è®¤ä¸ºNoneã€‚è‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- moe_router_pre_softmax: ä¸ºMoEå¯ç”¨é¢„softmaxè·¯ç”±ï¼Œè¿™æ„å‘³ç€softmaxä¼šåœ¨top-ké€‰æ‹©ä¹‹å‰è¿›è¡Œã€‚é»˜è®¤ä¸ºNoneã€‚è‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- ğŸ”¥moe_router_dtype: ç”¨äºè·¯ç”±è®¡ç®—å’Œä¸“å®¶è¾“å‡ºåŠ æƒå¹³å‡çš„æ•°æ®ç±»å‹ã€‚å¯é€‰ä¸º'none', 'fp32'ã€'fp64'ï¼Œè¿™å¢å¼ºäº†æ•°å€¼ç¨³å®šæ€§ï¼Œå°¤å…¶æ˜¯åœ¨ä¸“å®¶æ•°é‡è¾ƒå¤šæ—¶ã€‚ä¸`moe_permute_fusion`ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œæ€§èƒ½å½±å“å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚é»˜è®¤ä¸º'fp32'ã€‚'none'ä»£è¡¨ä¸æ”¹å˜æ•°æ®ç±»å‹ã€‚
- moe_router_score_function: MoE TopK è·¯ç”±çš„è¯„åˆ†å‡½æ•°ã€‚å¯ä»¥ä¸º "softmax" æˆ– "sigmoid"ã€‚é»˜è®¤ä¸ºNoneï¼Œä»config.jsonä¸­è¯»å–ã€‚
- moe_router_bias_update_rate: åœ¨æ— è¾…åŠ©æŸå¤±è´Ÿè½½å‡è¡¡ç­–ç•¥ä¸­ï¼Œä¸“å®¶åç½®çš„æ›´æ–°é€Ÿç‡ã€‚ä¸“å®¶åç½®æ ¹æ®æ¯ä¸ªä¸“å®¶åœ¨å…¨å±€æ‰¹æ¬¡ä¸­è¢«åˆ†é…çš„ token æ•°é‡è¿›è¡Œæ›´æ–°ï¼Œå¯¹äºåˆ†é…åˆ°çš„ token è¾ƒå°‘çš„ä¸“å®¶ï¼Œåç½®ä¼šå¢åŠ ï¼›å¯¹äºåˆ†é…åˆ°çš„ token è¾ƒå¤šçš„ä¸“å®¶ï¼Œåç½®ä¼šå‡å°‘ã€‚é»˜è®¤å€¼ 1e-3ï¼Œä¸ DeepSeekV3 ä¸­ä½¿ç”¨çš„å€¼ç›¸åŒã€‚
- moe_router_enable_expert_bias: åœ¨æ— è¾…åŠ©æŸå¤±è´Ÿè½½å‡è¡¡ç­–ç•¥ä¸­ï¼Œå¸¦æœ‰åŠ¨æ€ä¸“å®¶åç½®çš„ TopK è·¯ç”±ã€‚è·¯ç”±å†³ç­–åŸºäºè·¯ç”±åˆ†æ•°ä¸ä¸“å®¶åç½®ä¹‹å’Œã€‚è¯¦æƒ…è¯·å‚è§ï¼šhttps://arxiv.org/abs/2408.15664ã€‚é»˜è®¤ä¸ºNoneï¼Œè‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- moe_router_topk_scaling_factor: é»˜è®¤ä¸ºNoneã€‚ä»config.jsonä¸­è¯»å–ã€‚
- moe_router_load_balancing_type: ç¡®å®šè·¯ç”±å™¨çš„è´Ÿè½½å‡è¡¡ç­–ç•¥ã€‚å¯é€‰é¡¹ä¸º"aux_loss"ã€"seq_aux_loss"ã€"sinkhorn"ã€"none"ã€‚é»˜è®¤å€¼ä¸º Noneã€‚ä»config.jsonä¸­è¯»å–ã€‚
- ğŸ”¥expert_model_parallel_size: ä¸“å®¶å¹¶è¡Œæ•°ï¼Œé»˜è®¤ä¸º1ã€‚
- moe_token_dispatcher_type: è¦ä½¿ç”¨çš„tokenåˆ†å‘å™¨ç±»å‹ã€‚å¯é€‰é€‰é¡¹åŒ…æ‹¬ 'allgather'ã€'alltoall'ã€'flex'å’Œ'alltoall_seq'ã€‚é»˜è®¤å€¼ä¸º'alltoall'ã€‚
- moe_enable_deepep: å®éªŒæ€§åŠŸèƒ½ï¼Œå¯ç”¨DeepSeek/DeepEPä»¥å®ç° MoE æ¨¡å‹ä¸­çš„é«˜æ•ˆä»¤ç‰Œåˆ†å‘ä¸ç»„åˆã€‚ä»…åœ¨è®¾ç½®`--moe_token_dispatcher_type flex`ä½¿ç”¨çµæ´»ä»¤ç‰Œåˆ†å‘å™¨æ—¶ç”Ÿæ•ˆã€‚
- ğŸ”¥moe_grouped_gemm: å½“æ¯ä¸ªrankåŒ…å«å¤šä¸ªä¸“å®¶æ—¶ï¼Œé€šè¿‡åœ¨å¤šä¸ªæµä¸­å¯åŠ¨å¤šä¸ªæœ¬åœ° GEMM å†…æ ¸ï¼Œåˆ©ç”¨ TransformerEngineä¸­çš„GroupedLinearæé«˜åˆ©ç”¨ç‡å’Œæ€§èƒ½ã€‚é»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥moe_permute_fusion: åœ¨ä»¤ç‰Œåˆ†å‘è¿‡ç¨‹ä¸­èåˆä»¤ç‰Œé‡æ’æ“ä½œã€‚é»˜è®¤ä¸ºFalseã€‚
- ğŸ”¥moe_aux_loss_coeff: è¾…åŠ©æŸå¤±çš„ç¼©æ”¾ç³»æ•°ï¼šå»ºè®®çš„åˆå§‹å€¼ä¸º 1e-2ã€‚é»˜è®¤ä¸ºNoneã€‚è‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- moe_z_loss_coeff: z-loss çš„ç¼©æ”¾ç³»æ•°ã€‚é»˜è®¤ä¸ºNoneã€‚
- moe_expert_capacity_factor: æ¯ä¸ªä¸“å®¶çš„å®¹é‡å› å­ï¼ŒNoneè¡¨ç¤ºä¸ä¼šä¸¢å¼ƒä»»ä½•tokenã€‚é»˜è®¤ä¸ºNoneã€‚è‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- ğŸ”¥moe_shared_expert_overlap: å¯ç”¨å…±äº«ä¸“å®¶è®¡ç®—ä¸è°ƒåº¦å™¨é€šä¿¡ä¹‹é—´çš„é‡å ã€‚å¦‚æœä¸å¯ç”¨æ­¤é€‰é¡¹ï¼Œå…±äº«ä¸“å®¶å°†åœ¨è·¯ç”±ä¸“å®¶ä¹‹åæ‰§è¡Œã€‚ä»…åœ¨è®¾ç½®äº†`moe_shared_expert_intermediate_size`æ—¶æœ‰æ•ˆã€‚é»˜è®¤ä¸ºFalseã€‚
- moe_token_drop_policy: å¯é€‰ä¸º'probs', 'position'ã€‚é»˜è®¤ä¸º'probs'ã€‚

**mlaå‚æ•°**
- multi_latent_attention: æ˜¯å¦ä½¿ç”¨MLAã€‚é»˜è®¤ä¸ºFalseã€‚
- q_lora_rank: Query å¼ é‡ä½ç§©è¡¨ç¤ºçš„rankå€¼ã€‚é»˜è®¤ä¸ºNoneï¼Œè‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- kv_lora_rank: Key å’Œ Value å¼ é‡ä½ç§©è¡¨ç¤ºçš„ç§©ï¼ˆrankï¼‰å€¼ã€‚é»˜è®¤ä¸ºNoneï¼Œè‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- qk_head_dim: QK æŠ•å½±ä¸­ head çš„ç»´åº¦ã€‚ `q_head_dim = qk_head_dim + qk_pos_emb_head_dim`ã€‚é»˜è®¤ä¸ºNoneï¼Œè‡ªåŠ¨ä»config.jsonè¯»å–ã€‚
- qk_pos_emb_head_dim: QK æŠ•å½±ä¸­ä½ç½®åµŒå…¥çš„ç»´åº¦ã€‚é»˜è®¤ä¸ºNoneï¼Œè‡ªåŠ¨ä»config.jsonè¯»å–ã€‚

**DPOå‚æ•°**:
- ref_load: ref_modelçš„åŠ è½½è·¯å¾„ã€‚é»˜è®¤ä¸ºNoneï¼Œå³è®¾ç½®ä¸º`load`ã€‚
- beta: å«ä¹‰ä¸[TRL](https://huggingface.co/docs/trl/main/en/dpo_trainer#trl.DPOConfig)ç›¸åŒã€‚æ§åˆ¶ä¸å‚è€ƒæ¨¡å‹åå·®ç¨‹åº¦çš„å‚æ•°ã€‚betaå€¼è¶Šé«˜ï¼Œè¡¨ç¤ºä¸å‚è€ƒæ¨¡å‹çš„åå·®è¶Šå°ã€‚å¯¹äº IPO æŸå¤±å‡½æ•° (loss_type="ipo")ï¼Œbetaæ˜¯[è®ºæ–‡](https://huggingface.co/papers/2310.12036)ä¸­æ‰€æŒ‡çš„æ­£åˆ™åŒ–å‚æ•°ã€‚é»˜è®¤ä¸º0.1ã€‚
- rpo_alpha: æ¥è‡ª[RPO è®ºæ–‡](https://huggingface.co/papers/2404.19733)ä¸­çš„å‚æ•°ï¼Œç”¨äºæ§åˆ¶æŸå¤±å‡½æ•°ä¸­NLLé¡¹çš„æƒé‡ï¼ˆå³SFTæŸå¤±ï¼‰ã€‚`loss = dpo_loss + rpo_alpha * nll_loss`ã€‚é»˜è®¤ä¸º1ã€‚
- reference_free: æ˜¯å¦å¿½ç•¥æä¾›çš„å‚è€ƒæ¨¡å‹ï¼Œå¹¶éšå¼åœ°ä½¿ç”¨ä¸€ä¸ªå¯¹æ‰€æœ‰å“åº”èµ‹äºˆç›¸ç­‰æ¦‚ç‡çš„å‚è€ƒæ¨¡å‹ã€‚é»˜è®¤ä¸ºFalseã€‚
- label_smoothing: é»˜è®¤ä¸º0.ã€‚
- f_divergence_type: é»˜è®¤ä¸º`reverse_kl`ã€‚å¯é€‰å€¼å‚è€ƒ[TRLæ–‡æ¡£](https://huggingface.co/docs/trl/main/en/dpo_trainer)ã€‚
- loss_type: é»˜è®¤ä¸º'sigmoid'ã€‚å¯é€‰å€¼å‚è€ƒ[TRLæ–‡æ¡£](https://huggingface.co/docs/trl/main/en/dpo_trainer)ã€‚


### è®­ç»ƒå‚æ•°

Megatronè®­ç»ƒå‚æ•°ç»§æ‰¿è‡ªMegatronå‚æ•°å’ŒåŸºæœ¬å‚æ•°ã€‚åŸºæœ¬å‚æ•°çš„å†…å®¹å¯ä»¥å‚è€ƒ[è¿™é‡Œ](./å‘½ä»¤è¡Œå‚æ•°.md#åŸºæœ¬å‚æ•°)ã€‚æ­¤å¤–è¿˜åŒ…æ‹¬ä»¥ä¸‹å‚æ•°ï¼š

- add_version: åœ¨`save`ä¸Šé¢å¤–å¢åŠ ç›®å½•`'<ç‰ˆæœ¬å·>-<æ—¶é—´æˆ³>'`é˜²æ­¢æƒé‡è¦†ç›–ï¼Œé»˜è®¤ä¸ºTrueã€‚
- ğŸ”¥packing: æ˜¯å¦ä½¿ç”¨åºåˆ—packingï¼Œé»˜è®¤ä¸ºFalseã€‚å½“å‰æ”¯æŒ`megatron pt/sft`ã€‚
- ğŸ”¥packing_cache: æŒ‡å®š packing ç¼“å­˜ç›®å½•ã€‚é»˜è®¤å€¼ä¸º`None`ï¼Œè¡¨ç¤ºç¼“å­˜å°†å­˜å‚¨åœ¨ç¯å¢ƒå˜é‡ `$MODELSCOPE_CACHE`æ‰€æŒ‡å®šçš„è·¯å¾„ä¸‹ã€‚åœ¨è·¨èŠ‚ç‚¹ä½¿ç”¨ packing åŠŸèƒ½æ—¶ï¼Œéœ€ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹çš„ packing ç¼“å­˜è·¯å¾„å…±äº«ä¸”ä¸€è‡´ã€‚ä½ å¯ä»¥é€šè¿‡è®¾ç½®`MODELSCOPE_CACHE`ç¯å¢ƒå˜é‡ï¼Œæˆ–åœ¨å‘½ä»¤è¡Œä¸­æ·»åŠ  `--packing_cache <shared_path>`å‚æ•°æ¥å®ç°è¿™ä¸€è¦æ±‚ã€‚
- ğŸ”¥streaming: æµå¼è¯»å–å¹¶å¤„ç†æ•°æ®é›†ï¼Œé»˜è®¤Falseã€‚é€šå¸¸åœ¨å¤„ç†å¤§å‹æ•°æ®é›†æ—¶ï¼Œè®¾ç½®ä¸ºTrueã€‚æ›´å¤šæµå¼çš„å‚æ•°æŸ¥çœ‹å‘½ä»¤è¡Œå‚æ•°æ–‡æ¡£ã€‚
- lazy_tokenize: é»˜è®¤ä¸ºFalseã€‚è‹¥è¯¥å‚æ•°è®¾ç½®ä¸ºFalseï¼Œåˆ™åœ¨è®­ç»ƒä¹‹å‰å¯¹æ‰€æœ‰çš„æ•°æ®é›†æ ·æœ¬è¿›è¡Œtokenizeï¼ˆè¿™å¯ä»¥é¿å…åœ¨è®­ç»ƒä¸­å‡ºç°æŠ¥é”™ï¼‰ï¼›è®¾ç½®ä¸ºTrueï¼Œåˆ™åœ¨è®­ç»ƒä¸­å¯¹æ•°æ®é›†è¿›è¡Œtokenizeï¼ˆè¿™å¯ä»¥èŠ‚çº¦å†…å­˜ï¼‰ã€‚
- max_epochs: è®­ç»ƒåˆ°`max_epochs`æ—¶å¼ºåˆ¶é€€å‡ºè®­ç»ƒï¼Œå¹¶å¯¹æƒé‡è¿›è¡ŒéªŒè¯å’Œä¿å­˜ã€‚è¯¥å‚æ•°åœ¨ä½¿ç”¨æµå¼æ•°æ®é›†æ—¶å¾ˆæœ‰ç”¨ã€‚é»˜è®¤ä¸ºNoneã€‚
  - æ³¨æ„ï¼šå¦‚æœä½ ä½¿ç”¨éæµå¼æ•°æ®é›†ï¼Œè¯¥å‚æ•°ä¼šä¸ºä½ è‡ªåŠ¨è®¡ç®—train_itersï¼Œä½ ä¸éœ€è¦æ‰‹åŠ¨ä¼ å…¥`train_iters`ã€‚


### RLHFå‚æ•°
é™¤äº†ç»§æ‰¿è®­ç»ƒå‚æ•°å¤–ï¼Œè¿˜æ”¯æŒä»¥ä¸‹å‚æ•°ï¼š
- rlhf_type: é»˜è®¤ä¸º'dpo'ã€‚ç›®å‰å¯é€‰æ‹©ä¸º'dpo'ã€‚
- loss_scale: è¦†ç›–[åŸºæœ¬å‚æ•°](./å‘½ä»¤è¡Œå‚æ•°.md)ä¸­çš„loss_scaleã€‚é»˜è®¤ä¸º'last_round'ã€‚
- calculate_per_token_loss: è¦†ç›–Megatronå‚æ•°ï¼Œé»˜è®¤ä¸ºFalseã€‚
